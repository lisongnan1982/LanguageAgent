<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Chat - AI èŠå¤©</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        body { font-family: 'Inter', 'PingFang SC', sans-serif; }

        /* é˜²æ­¢ç§»åŠ¨ç«¯é¡µé¢æ•´ä½“æ»šåŠ¨ï¼ˆæ©¡çš®ç­‹æ•ˆæœï¼‰ */
        html, body {
            overflow: hidden;
            position: fixed;
            width: 100%;
            height: 100%;
            height: 100dvh;
            touch-action: none; /* ç¦æ­¢é¡µé¢çº§è§¦æ‘¸æ»šåŠ¨ */
            overscroll-behavior: none; /* ç¦æ­¢è¿‡åº¦æ»šåŠ¨ */
        }

        /* å…è®¸ç‰¹å®šå¯æ»šåŠ¨åŒºåŸŸæ­£å¸¸æ»šåŠ¨ */
        .allow-scroll {
            touch-action: pan-y; /* å…è®¸å‚ç›´æ»šåŠ¨ */
            overscroll-behavior: contain; /* æ»šåŠ¨åˆ°è¾¹ç•Œæ—¶ä¸è§¦å‘çˆ¶çº§æ»šåŠ¨ */
            -webkit-overflow-scrolling: touch; /* iOS å¹³æ»‘æ»šåŠ¨ */
        }

        /* ä½¿ç”¨ dvh æ”¯æŒç§»åŠ¨ç«¯åŠ¨æ€è§†å£ï¼Œå›é€€åˆ° vh */
        .chat-container { height: calc(100dvh - 180px); height: calc(100vh - 180px); }
        .scrollbar-hide::-webkit-scrollbar { display: none; }
        .scrollbar-hide { -ms-overflow-style: none; scrollbar-width: none; }
        .message-content p { margin-bottom: 0.5rem; }
        .message-content p:last-child { margin-bottom: 0; }
        .role-card.active { border-color: #3b82f6; background-color: #eff6ff; }

        /* ç§»åŠ¨ç«¯ä¾§è¾¹æ æŠ½å±‰æ ·å¼ */
        .mobile-sidebar {
            position: fixed;
            top: 0;
            left: 0;
            width: 85%;
            max-width: 320px;
            height: 100%;
            height: 100dvh;
            background: white;
            z-index: 100;
            transform: translateX(-100%);
            transition: transform 0.3s ease-in-out;
            box-shadow: 2px 0 10px rgba(0,0,0,0.1);
        }
        .mobile-sidebar.open { transform: translateX(0); }
        .mobile-overlay {
            position: fixed;
            inset: 0;
            background: rgba(0,0,0,0.5);
            z-index: 99;
            opacity: 0;
            visibility: hidden;
            transition: opacity 0.3s, visibility 0.3s;
        }
        .mobile-overlay.open { opacity: 1; visibility: visible; }

        /* ç§»åŠ¨ç«¯è§’è‰²å¡ç‰‡åˆ é™¤æŒ‰é’®å§‹ç»ˆå¯è§ */
        @media (max-width: 768px) {
            .role-card .delete-btn { opacity: 1 !important; }
            /* ç§»åŠ¨ç«¯è¾“å…¥æ¡†å›ºå®šåœ¨åº•éƒ¨ */
            .input-area-mobile-fixed {
                position: fixed;
                bottom: 0;
                left: 0;
                right: 0;
                background: white;
                border-top: 1px solid #e5e7eb;
                z-index: 50;
            }
            /* main å®¹å™¨éœ€è¦ä¸ºå›ºå®šè¾“å…¥æ¡†ç•™å‡ºåº•éƒ¨ç©ºé—´ */
            .main-with-fixed-input { padding-bottom: 80px; }
            /* èŠå¤©æ¶ˆæ¯åŒºåŸŸåº•éƒ¨å†…è¾¹è·ï¼Œç¡®ä¿æœ€åæ¶ˆæ¯ä¸è¢«å›ºå®šè¾“å…¥æ¡†é®æŒ¡ */
            #chatMessages.chat-messages-mobile-fixed { padding-bottom: 80px !important; }
            /* å¢å¤§æ¶ˆæ¯æ°”æ³¡çš„æ’­æ”¾æŒ‰é’®è§¦æ‘¸åŒºåŸŸ */
            .tts-btn {
                width: 44px;
                height: 44px;
                display: flex;
                align-items: center;
                justify-content: center;
            }
        }

        /* å®‰å…¨åŒºåŸŸé€‚é… (iPhone åˆ˜æµ·å±ç­‰) */
        @supports (padding: env(safe-area-inset-bottom)) {
            .input-area { padding-bottom: calc(1rem + env(safe-area-inset-bottom)); }
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-900">
    <!-- ç§»åŠ¨ç«¯é®ç½©å±‚ -->
    <div id="mobileOverlay" class="mobile-overlay md:hidden"></div>

    <!-- ç§»åŠ¨ç«¯ä¾§è¾¹æ æŠ½å±‰ -->
    <aside id="mobileSidebar" class="mobile-sidebar md:hidden p-4 flex flex-col">
        <div class="flex justify-between items-center mb-4">
            <h2 class="font-semibold text-gray-700 text-lg">è§’è‰²é€‰æ‹©</h2>
            <button id="closeSidebarBtn" class="p-2 text-gray-500 hover:text-gray-700">
                <i class="fas fa-times text-xl"></i>
            </button>
        </div>
        <button id="addRoleBtnMobile" class="w-full mb-4 py-3 px-4 bg-blue-50 text-blue-600 rounded-xl flex items-center justify-center gap-2 active:bg-blue-100">
            <i class="fas fa-plus"></i> åˆ›å»ºæ–°è§’è‰²
        </button>
        <div id="roleListMobile" class="flex-1 flex flex-col gap-3 overflow-y-auto scrollbar-hide allow-scroll">
            <!-- Mobile Roles will be injected here -->
        </div>
    </aside>

    <div class="max-w-6xl mx-auto h-screen h-[100dvh] flex flex-col p-2 md:p-4">
        <!-- Header -->
        <header class="flex justify-between items-center mb-4 md:mb-6 px-2 md:px-4">
            <!-- ç§»åŠ¨ç«¯èœå•æŒ‰é’® -->
            <button id="menuBtn" class="md:hidden p-2 -ml-1 rounded-lg hover:bg-gray-200 transition-colors">
                <i class="fas fa-bars text-xl text-gray-600"></i>
            </button>
            <h1 class="text-xl md:text-2xl font-bold text-blue-600"><i class="fas fa-mask mr-2"></i>AI Chat</h1>
            <button id="settingsBtn" class="p-2 rounded-full hover:bg-gray-200 transition-colors">
                <i class="fas fa-cog text-xl text-gray-600"></i>
            </button>
        </header>

        <div class="flex flex-1 gap-4 md:gap-6 overflow-hidden">
            <!-- Sidebar: Roles (æ¡Œé¢ç«¯) -->
            <aside class="hidden md:flex w-1/4 flex-col gap-4 overflow-y-auto pr-2 scrollbar-hide allow-scroll">
                <div class="flex justify-between items-center">
                    <h2 class="font-semibold text-gray-700">è§’è‰²é€‰æ‹©</h2>
                    <button id="addRoleBtn" class="text-sm text-blue-600 hover:text-blue-800"><i class="fas fa-plus mr-1"></i>åˆ›å»º</button>
                </div>
                <div id="roleList" class="flex flex-col gap-3">
                    <!-- Roles will be injected here -->
                </div>
            </aside>

            <!-- Main Chat Area -->
            <main id="mainChatArea" class="flex-1 flex flex-col bg-white rounded-2xl shadow-sm border border-gray-200 overflow-hidden">
                <!-- Chat Header - ä½¿ç”¨ sticky ç¡®ä¿é¡¶éƒ¨å›ºå®šï¼Œä¸ä¼šéšæ¶ˆæ¯æ»šåŠ¨æ¶ˆå¤± -->
                <div id="activeRoleHeader" class="p-3 md:p-4 border-b border-gray-100 bg-gray-50 flex items-center gap-2 md:gap-3 sticky top-0 z-10 flex-shrink-0">
                    <!-- ç§»åŠ¨ç«¯ç‚¹å‡»å¤´åƒå¯æ‰“å¼€è§’è‰²åˆ—è¡¨ -->
                    <div id="roleAvatarBtn" class="w-10 h-10 md:w-10 md:h-10 rounded-full bg-blue-100 flex items-center justify-center text-blue-600 font-bold cursor-pointer md:cursor-default active:scale-95 transition-transform">
                        ?
                    </div>
                    <div class="flex-1 min-w-0">
                        <h3 class="font-bold text-gray-800 truncate" id="activeRoleName">è¯·é€‰æ‹©è§’è‰²</h3>
                        <p class="text-xs text-gray-500 truncate" id="activeRoleDesc">å¼€å§‹æ‚¨çš„å¯¹è¯</p>
                    </div>
                    <button id="playAllBtn" class="p-2 md:p-2 min-w-[44px] min-h-[44px] flex items-center justify-center text-gray-400 hover:text-green-500 active:text-green-600 transition-colors hidden" title="è¿ç»­æ’­æ”¾æ‰€æœ‰å·²ç¼“å­˜éŸ³é¢‘" style="display: none !important;">
                        <i class="fas fa-play-circle text-xl"></i>
                    </button>
                    <button id="voiceChatBtn" class="p-2 md:p-2 min-w-[44px] min-h-[44px] flex items-center justify-center text-gray-400 hover:text-purple-500 active:text-purple-600 transition-colors hidden" title="è¯­éŸ³å¯¹è¯">
                        <i class="fas fa-phone text-lg"></i>
                    </button>
                    <button id="downloadAllBtn" class="p-2 md:p-2 min-w-[44px] min-h-[44px] flex items-center justify-center text-gray-400 hover:text-blue-500 active:text-blue-600 transition-colors hidden" title="åˆå¹¶ä¸‹è½½æ‰€æœ‰å·²ç¼“å­˜éŸ³é¢‘">
                        <i class="fas fa-download text-lg"></i>
                    </button>
                    <button id="compressHistoryBtn" class="p-2 md:p-2 min-w-[44px] min-h-[44px] flex items-center justify-center text-gray-400 hover:text-purple-500 active:text-purple-600 transition-colors hidden" title="å‹ç¼©å¯¹è¯å†å²ï¼ˆå‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼‰">
                        <i class="fas fa-compress-alt text-lg"></i>
                    </button>
                    <button id="clearChatBtn" class="p-2 md:p-2 min-w-[44px] min-h-[44px] flex items-center justify-center text-gray-400 hover:text-red-500 active:text-red-600 transition-colors hidden" title="æ¸…ç©ºå½“å‰å¯¹è¯">
                        <i class="fas fa-trash-alt text-lg"></i>
                    </button>
                </div>

                <!-- Messages -->
                <div id="chatMessages" class="flex-1 overflow-y-auto p-4 md:p-6 flex flex-col gap-3 md:gap-4 chat-container allow-scroll">
                    <div class="text-center text-gray-400 mt-10">
                        <i class="fas fa-comments text-4xl mb-4"></i>
                        <p>é€‰æ‹©ä¸€ä¸ªè§’è‰²å¼€å§‹èŠå¤©å§</p>
                    </div>
                </div>

                <!-- Input Area -->
                <div id="inputArea" class="input-area p-3 md:p-4 border-t border-gray-100">
                    <form id="chatForm" class="flex gap-2 items-end">
                        <button type="button" id="voiceBtn"
                                class="w-11 h-11 md:w-10 md:h-10 flex items-center justify-center rounded-full bg-gray-100 hover:bg-blue-100 active:bg-blue-200 text-gray-500 hover:text-blue-600 transition-all disabled:opacity-50 flex-shrink-0"
                                disabled title="è¯­éŸ³è¾“å…¥">
                            <i class="fas fa-microphone text-lg"></i>
                        </button>
                        <button type="button" id="autoReplyBtn"
                                class="w-11 h-11 md:w-10 md:h-10 flex items-center justify-center rounded-full bg-gray-100 hover:bg-purple-100 active:bg-purple-200 text-gray-500 hover:text-purple-600 transition-all disabled:opacity-50 flex-shrink-0"
                                disabled title="AI è‡ªåŠ¨å›å¤/ç»­å†™">
                            <i class="fas fa-robot text-lg"></i>
                        </button>
                        <textarea id="userInput" placeholder="è¾“å…¥æ¶ˆæ¯..." rows="1"
                               class="flex-1 min-w-0 px-4 py-3 md:py-2 border border-gray-300 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:bg-gray-100 text-base resize-none max-h-32 scrollbar-hide"
                               disabled></textarea>
                        <button type="submit" id="sendBtn"
                                class="bg-blue-600 text-white px-4 md:px-6 py-3 md:py-2 rounded-xl hover:bg-blue-700 active:bg-blue-800 transition-colors disabled:bg-gray-400 flex-shrink-0 h-[44px] md:h-[42px]"
                                disabled>
                            <i class="fas fa-paper-plane"></i>
                        </button>
                    </form>
                    <div id="recordingStatus" class="hidden text-center mt-2">
                        <span class="inline-flex items-center px-3 py-1 rounded-full bg-red-100 text-red-600 text-xs font-medium animate-pulse">
                            <i class="fas fa-circle mr-2"></i> æ­£åœ¨å½•éŸ³... ç‚¹å‡»æŒ‰é’®åœæ­¢
                        </span>
                    </div>
                </div>
            </main>
        </div>
    </div>

    <!-- Settings Modal -->
    <div id="settingsModal" class="fixed inset-0 bg-black bg-opacity-50 hidden flex items-end md:items-center justify-center z-50 md:p-4">
        <div class="bg-white rounded-t-2xl md:rounded-2xl p-4 md:p-6 w-full md:max-w-md shadow-xl max-h-[85vh] md:max-h-[90vh] flex flex-col">
            <div class="flex items-center justify-between mb-4 flex-shrink-0">
                <h2 class="text-xl font-bold">API è®¾ç½®</h2>
                <button id="closeSettings" class="md:hidden p-2 -mr-2 text-gray-500 hover:text-gray-700">
                    <i class="fas fa-times text-xl"></i>
                </button>
            </div>
            <div class="space-y-4 overflow-y-auto flex-1 pr-1 -mr-1 allow-scroll">
                <div>
                    <label class="block text-sm font-medium text-gray-700 mb-1">OpenRouter API Key</label>
                    <div class="flex flex-col sm:flex-row gap-2">
                        <input type="password" id="apiKeyInput" placeholder="sk-or-v1-..."
                               class="flex-1 px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                        <button id="verifyKey" class="px-4 py-3 md:py-2 bg-gray-100 hover:bg-gray-200 active:bg-gray-300 rounded-lg text-sm transition-colors whitespace-nowrap">éªŒè¯å¹¶åŠ è½½</button>
                    </div>
                    <p class="text-xs text-gray-400 mt-1">Key å°†ä¿å­˜åœ¨æ‚¨çš„æµè§ˆå™¨æœ¬åœ°å­˜å‚¨ä¸­</p>
                </div>
                <div>
                    <label class="block text-sm font-medium text-gray-700 mb-1">æ¨¡å‹åˆ—è¡¨</label>
                    <input type="text" id="modelSearch" placeholder="æœç´¢æ¨¡å‹ (å¦‚: gpt-4, claude)..."
                           class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-t-lg focus:ring-2 focus:ring-blue-500 outline-none border-b-0 text-base md:text-sm">
                    <select id="modelSelect" size="5" class="w-full px-2 py-1 border border-gray-300 rounded-b-lg focus:ring-2 focus:ring-blue-500 outline-none bg-white text-base">
                        <option value="openai/gpt-3.5-turbo">Loading models...</option>
                    </select>
                    <button id="refreshModels" class="text-sm md:text-xs text-blue-600 mt-2 md:mt-1 hover:underline py-1">åˆ·æ–°æ¨¡å‹åˆ—è¡¨</button>
                </div>
                <div class="space-y-3 bg-gray-50 p-3 rounded-lg">
                    <h3 class="text-sm font-bold text-gray-800">åœºæ™¯æ¨¡å‹é…ç½®</h3>
                    <div>
                        <label class="block text-xs font-medium text-gray-600 mb-1">ğŸ­ è§’è‰²ç”Ÿæˆæ¨¡å‹</label>
                        <select id="roleGenModel" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none bg-white text-sm">
                            <option value="">ä»ä¸Šæ–¹åˆ—è¡¨é€‰æ‹©...</option>
                        </select>
                        <p class="text-[10px] text-gray-400 mt-1">ç”¨äº AI ç”Ÿæˆè§’è‰²æè¿°å’Œåœºæ™¯</p>
                    </div>
                    <div>
                        <label class="block text-xs font-medium text-gray-600 mb-1">ğŸ’¬ å¯¹è¯æ¨¡å‹</label>
                        <select id="chatModel" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none bg-white text-sm">
                            <option value="">ä»ä¸Šæ–¹åˆ—è¡¨é€‰æ‹©...</option>
                        </select>
                        <p class="text-[10px] text-gray-400 mt-1">ç”¨äºä¸è§’è‰²å¯¹è¯åŠè‡ªåŠ¨ç”Ÿæˆç”¨æˆ·å›å¤</p>
                    </div>
                    <div>
                        <label class="block text-xs font-medium text-gray-600 mb-1">ğŸ–¼ï¸ å›¾ç‰‡æç¤ºè¯æ¨¡å‹</label>
                        <select id="imagePromptModel" class="w-full px-3 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none bg-white text-sm">
                            <option value="">ä»ä¸Šæ–¹åˆ—è¡¨é€‰æ‹©...</option>
                        </select>
                        <p class="text-[10px] text-gray-400 mt-1">ç”¨äºæ ¹æ®æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡æç¤ºè¯</p>
                    </div>
                </div>
                <hr class="border-gray-100">
                <div class="space-y-3">
                    <h3 class="text-sm font-bold text-gray-800">è¯­éŸ³è¯†åˆ«è®¾ç½® (ASR)</h3>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">ASR æ¨¡å¼</label>
                        <select id="asrMode"
                                class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                            <option value="cloud">â˜ï¸ äº‘ç«¯ ASR (ç«å±±å¼•æ“)</option>
                            <option value="local">ğŸ“± æœ¬åœ° ASR (Whisper)</option>
                        </select>
                        <p class="text-[10px] text-gray-400 mt-1">æœ¬åœ°æ¨¡å¼å®Œå…¨ç¦»çº¿è¿è¡Œï¼Œé¦–æ¬¡éœ€ä¸‹è½½æ¨¡å‹(~75MB)</p>
                    </div>
                    <div id="cloudAsrSettings">
                        <div class="mb-3">
                            <label class="block text-sm font-medium text-gray-700 mb-1">Access Key (ASR)</label>
                            <input type="password" id="volcToken" placeholder="ç«å±±å¼•æ“ Access Key"
                                   class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                        </div>
                        <div>
                            <label class="block text-sm font-medium text-gray-700 mb-1">ASR Resource ID (èµ„æºæ ‡è¯†)</label>
                            <select id="volcCluster"
                                    class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                                <option value="volcengine_streaming_common">volcengine_streaming_common (ä¸­æ–‡)</option>
                                <option value="volcengine_streaming_en">volcengine_streaming_en (è‹±æ–‡)</option>
                            </select>
                        </div>
                    </div>
                    <div id="localAsrSettings" class="hidden">
                        <div class="mb-3">
                            <label class="block text-sm font-medium text-gray-700 mb-1">Whisper æ¨¡å‹</label>
                            <select id="whisperModel"
                                    class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                                <option value="Xenova/whisper-tiny">whisper-tiny (~75MB, å¿«é€Ÿ)</option>
                                <option value="Xenova/whisper-base">whisper-base (~142MB, æ›´å‡†ç¡®)</option>
                                <option value="Xenova/whisper-small">whisper-small (~466MB, é«˜å‡†ç¡®)</option>
                            </select>
                            <p class="text-[10px] text-gray-400 mt-1">æ¨¡å‹è¶Šå¤§è¶Šå‡†ç¡®ï¼Œä½†åŠ è½½å’Œæ¨ç†æ—¶é—´æ›´é•¿</p>
                        </div>
                        <div class="mb-3">
                            <label class="block text-sm font-medium text-gray-700 mb-1">è¯†åˆ«è¯­è¨€</label>
                            <select id="whisperLanguage"
                                    class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                                <option value="chinese">ä¸­æ–‡</option>
                                <option value="english">è‹±æ–‡</option>
                                <option value="auto">è‡ªåŠ¨æ£€æµ‹</option>
                            </select>
                        </div>
                        <div id="whisperModelStatus" class="p-3 bg-gray-50 rounded-lg">
                            <div class="flex items-center justify-between">
                                <span class="text-sm text-gray-600">æ¨¡å‹çŠ¶æ€:</span>
                                <span id="whisperModelStatusText" class="text-sm font-medium text-gray-500">æœªåŠ è½½</span>
                            </div>
                            <div id="whisperModelProgress" class="hidden mt-2">
                                <div class="w-full bg-gray-200 rounded-full h-2">
                                    <div id="whisperProgressBar" class="bg-blue-500 h-2 rounded-full transition-all duration-300" style="width: 0%"></div>
                                </div>
                                <p id="whisperProgressText" class="text-[10px] text-gray-500 mt-1 text-center">ä¸‹è½½ä¸­...</p>
                            </div>
                        </div>
                    </div>
                </div>
                <hr class="border-gray-100 hidden">
                <div class="space-y-3">
                    <h3 class="text-sm font-bold text-gray-800">ç«å±±å¼•æ“è¯­éŸ³åˆæˆè®¾ç½® (TTS)</h3>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">TTS æ¨¡å¼</label>
                        <select id="volcTtsMode"
                                class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                            <option value="normal">æ™®é€šæ¨¡å¼ (v1 API)</option>
                            <option value="stream">å•å‘æµå¼ (v3 API)</option>
                        </select>
                        <p class="text-[10px] text-gray-400 mt-1">æ™®é€šæ¨¡å¼ä½¿ç”¨ Access Tokenï¼Œæµå¼æ¨¡å¼ä½¿ç”¨ Access Key</p>
                    </div>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">AppID</label>
                        <input type="text" id="volcAppId" placeholder="ç«å±±å¼•æ“ AppID"
                               class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                    </div>
                    <div id="ttsNormalAuthContainer">
                        <label class="block text-sm font-medium text-gray-700 mb-1">Access Token (æ™®é€šæ¨¡å¼)</label>
                        <input type="password" id="volcTtsToken" placeholder="ç«å±±å¼•æ“ Access Token"
                               class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                        <p class="text-[10px] text-gray-400 mt-1">æ³¨ï¼šTTS é€šå¸¸ä½¿ç”¨ Access Tokenï¼Œä¸ ASR çš„ Access Key ä¸åŒ</p>
                    </div>
                    <div id="ttsStreamAuthContainer" class="hidden">
                        <label class="block text-sm font-medium text-gray-700 mb-1">Access Key (æµå¼æ¨¡å¼)</label>
                        <input type="password" id="volcTtsAccessKey" placeholder="ç«å±±å¼•æ“ Access Key"
                               class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                        <p class="text-[10px] text-gray-400 mt-1">æµå¼æ¨¡å¼éœ€è¦ä½¿ç”¨ Access Key è®¤è¯</p>
                    </div>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">TTS Resource ID (èµ„æºæ ‡è¯†)</label>
                        <input type="text" id="volcTtsCluster" placeholder="ä¾‹å¦‚: volcano_tts æˆ– volc.tts.default"
                               class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                        <p class="text-[10px] text-gray-400 mt-1">æç¤ºï¼šè¯·ç¡®ä¿åœ¨ç«å±±å¼•æ“æ§åˆ¶å°å·²å¼€é€šå¯¹åº”æœåŠ¡å¹¶æˆæƒ</p>
                    </div>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">é»˜è®¤éŸ³è‰² (Voice Type)</label>
                        <select id="volcTtsVoice" class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                            <option value="zh_female_vv_uranus_bigtts">zh_female_vv_uranus_bigtts</option>
                            <option value="zh_male_dayi_saturn_bigtts">zh_male_dayi_saturn_bigtts</option>
                            <option value="zh_female_mizai_saturn_bigtts">zh_female_mizai_saturn_bigtts</option>
                            <option value="zh_female_jitangnv_saturn_bigtts">zh_female_jitangnv_saturn_bigtts</option>
                            <option value="zh_female_meilinvyou_saturn_bigtts">zh_female_meilinvyou_saturn_bigtts</option>
                            <option value="zh_female_santongyongns_saturn_bigtts">zh_female_santongyongns_saturn_bigtts</option>
                            <option value="zh_male_ruyayichen_saturn_bigtts">zh_male_ruyayichen_saturn_bigtts</option>
                            <option value="saturn_zh_female_cancan_tob">saturn_zh_female_cancan_tob</option>
                            <option value="saturn_zh_female_keainvsheng_tob">saturn_zh_female_keainvsheng_tob</option>
                            <option value="saturn_zh_female_tiaopigongzhu_tob">saturn_zh_female_tiaopigongzhu_tob</option>
                        </select>
                    </div>
                    <div class="pt-2 border-t border-gray-100 mt-2">
                        <div class="flex items-center justify-between mb-2">
                            <label for="autoTtsEnabled" class="text-sm font-medium text-gray-700">è‡ªåŠ¨æ’­æ”¾çŸ­å›å¤</label>
                            <input type="checkbox" id="autoTtsEnabled" class="w-5 h-5 text-blue-600 rounded border-gray-300 focus:ring-blue-500">
                        </div>
                        <div id="autoTtsThresholdContainer" class="hidden">
                            <label class="block text-sm font-medium text-gray-700 mb-1">æœ€å¤§å­—ç¬¦æ•°é™åˆ¶</label>
                            <input type="number" id="autoTtsThreshold" placeholder="100"
                                   class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                            <p class="text-[10px] text-gray-400 mt-1">ä»…å½“å›å¤å­—æ•°å°‘äºæ­¤å€¼æ—¶è‡ªåŠ¨æ’­æ”¾</p>
                        </div>
                    </div>
                </div>
                <hr class="border-gray-100">
                <div class="space-y-3">
                    <h3 class="text-sm font-bold text-gray-800">Replicate æ–‡ç”Ÿå›¾è®¾ç½®</h3>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">Replicate API Token</label>
                        <input type="password" id="replicateToken" placeholder="r8_..."
                               class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                        <p class="text-[10px] text-gray-400 mt-1">ç”¨äºæ–‡ç”Ÿå›¾åŠŸèƒ½ã€‚åœ¨ <a href="https://replicate.com/account/api-tokens" target="_blank" class="text-blue-600 hover:underline">Replicate</a> è·å–</p>
                    </div>
                    <div>
                        <label class="block text-sm font-medium text-gray-700 mb-1">å›¾ç‰‡ç”Ÿæˆæ¨¡å‹</label>
                        <select id="replicateModel" class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none bg-white text-base">
                            <option value="realistic-vision-v5.1">Realistic Vision v5.1 (å†™å®é£æ ¼)</option>
                            <option value="realvisxl-v3.0-turbo">RealVisXL v3.0 Turbo (å¿«é€Ÿç”Ÿæˆ)</option>
                            <option value="dreamshaper-xl-turbo">DreamShaper XL Turbo (æ¢¦å¹»é£æ ¼)</option>
                            <option value="qwen-image-fast">Qwen Image Fast (é€šä¹‰ä¸‡è±¡å¿«é€Ÿ)</option>
                            <option value="qwen-image">Qwen Image ğŸ¨ (é€šä¹‰ä¸‡è±¡é«˜è´¨é‡)</option>
                            <option value="p-image">P-Image (Pruna AIé«˜æ•ˆ)</option>
                            <option value="flux-fast">Flux Fast ğŸ”¥ (è¶…å¿«FLUXæ¨¡å‹)</option>
                            <option value="z-image-turbo">Z-Image Turbo âš¡ (8æ­¥æé€Ÿç”Ÿæˆ)</option>
                            <option value="flux-2-pro">FLUX.2 Pro ğŸ¨ (é«˜è´¨é‡ä¸“ä¸šç‰ˆ)</option>
                            <option value="nano-banana-pro">Nano Banana Pro ğŸŒ (Googleé«˜æ•ˆæ¨¡å‹)</option>
                            <option value="gpt-image-1.5">GPT Image 1.5 ğŸ–¼ï¸ (OpenAIé«˜è´¨é‡)</option>
                        </select>
                    </div>
                </div>
            </div>
            <!-- åº•éƒ¨æŒ‰é’®å›ºå®šåœ¨åº•éƒ¨ -->
            <div class="flex gap-3 mt-4 pt-4 border-t border-gray-100 flex-shrink-0">
                <button id="closeSettingsDesktop" class="hidden md:block flex-1 px-4 py-2 text-gray-600 hover:bg-gray-100 rounded-lg">å…³é—­</button>
                <button id="saveSettings" class="flex-1 px-4 py-3 md:py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 active:bg-blue-800 font-medium">ä¿å­˜è®¾ç½®</button>
            </div>
        </div>
    </div>

    <!-- Create/Edit Role Modal -->
    <div id="roleModal" class="fixed inset-0 bg-black bg-opacity-50 hidden flex items-end md:items-center justify-center z-50 md:p-4">
        <div class="bg-white rounded-t-2xl md:rounded-2xl p-4 md:p-6 w-full md:max-w-md shadow-xl max-h-[90vh] flex flex-col">
            <div class="flex justify-between items-center mb-4 flex-shrink-0">
                <h2 id="roleModalTitle" class="text-xl font-bold">åˆ›å»ºæ–°è§’è‰²</h2>
                <button id="closeRoleModal" class="p-2 -mr-2 text-gray-400 hover:text-gray-600">
                    <i class="fas fa-times text-xl"></i>
                </button>
            </div>

            <div class="overflow-y-auto flex-1 pr-1 -mr-1 allow-scroll pb-4">
            <!-- AI Generation Section -->
            <div class="bg-blue-50 p-4 rounded-xl mb-4 md:mb-6 border border-blue-100">
                <div class="flex gap-2 items-end">
                    <textarea id="aiPromptInput" placeholder="è¾“å…¥ç®€å•æƒ³æ³•è®© AI ç”Ÿæˆè§’è‰²" rows="1"
                           class="flex-1 px-4 py-3 md:py-2 border border-blue-200 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base md:text-sm resize-none max-h-32 scrollbar-hide"></textarea>
                    <button id="aiGenerateBtn" class="px-4 py-3 md:py-2 bg-blue-600 text-white rounded-lg text-sm font-semibold hover:bg-blue-700 active:bg-blue-800 transition-all shadow-sm flex items-center justify-center gap-2 whitespace-nowrap flex-shrink-0">
                        <i class="fas fa-magic"></i> ç”Ÿæˆ
                    </button>
                </div>
            </div>

            <div class="space-y-4 pb-2">
                <div>
                    <label class="block text-sm font-medium text-gray-700 mb-1">è§’è‰²åç§°</label>
                    <input type="text" id="newRoleName" placeholder="ä¾‹å¦‚ï¼šç¦å°”æ‘©æ–¯"
                           class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                </div>
                <div>
                    <label class="block text-sm font-medium text-gray-700 mb-1">è§’è‰²æè¿° (ç®€çŸ­)</label>
                    <input type="text" id="newRoleDesc" placeholder="ä¾‹å¦‚ï¼šä¼Ÿå¤§çš„ä¾¦æ¢"
                           class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base">
                </div>
                <div>
                    <label class="block text-sm font-medium text-gray-700 mb-1">æç¤ºè¯ (System Prompt)</label>
                    <textarea id="newRolePrompt" rows="4" placeholder="æè¿°è§’è‰²çš„æ€§æ ¼ã€è¯´è¯æ–¹å¼å’ŒèƒŒæ™¯..."
                              class="w-full px-4 py-3 md:py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 outline-none text-base"></textarea>
                </div>
            </div>
            </div><!-- å…³é—­æ»šåŠ¨å®¹å™¨ -->

            <!-- åº•éƒ¨æŒ‰é’® -->
            <div class="flex gap-3 mt-4 pt-4 border-t border-gray-100 flex-shrink-0">
                <button id="cancelRoleModal" class="flex-1 px-4 py-3 md:py-2 text-gray-600 hover:bg-gray-100 active:bg-gray-200 rounded-lg">å–æ¶ˆ</button>
                <button id="saveRole" class="flex-1 px-4 py-3 md:py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 active:bg-blue-800 font-semibold">ä¿å­˜è§’è‰²</button>
            </div>
        </div>
    </div>

    <!-- Voice Chat Modal -->
    <div id="voiceChatModal" class="fixed inset-0 bg-gradient-to-br from-purple-900 via-blue-900 to-indigo-900 hidden flex flex-col items-center justify-center z-[200]">
        <div class="absolute top-4 right-4">
            <button id="closeVoiceChatBtn" class="p-3 rounded-full bg-white/10 hover:bg-white/20 text-white transition-colors">
                <i class="fas fa-times text-xl"></i>
            </button>
        </div>

        <div class="flex flex-col items-center justify-center flex-1 w-full max-w-lg px-4">
            <!-- Status Display -->
            <div id="voiceChatStatus" class="text-white text-xl font-medium mb-8 text-center">
                å‡†å¤‡ä¸­...
            </div>

            <!-- Audio Visualizer -->
            <div class="relative mb-8">
                <div id="voiceVisualizer" class="w-32 h-32 rounded-full bg-white/10 flex items-center justify-center relative overflow-hidden">
                    <!-- Pulse Animation -->
                    <div id="voicePulse" class="absolute inset-0 rounded-full bg-purple-500/30 animate-ping"></div>
                    <!-- Microphone Icon -->
                    <i id="voiceChatIcon" class="fas fa-microphone text-4xl text-white relative z-10"></i>
                </div>
                <!-- Audio Level Bars -->
                <div id="audioLevelBars" class="flex gap-1 justify-center mt-4 h-8">
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 8px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 12px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 16px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 20px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 24px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 20px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 16px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 12px;"></div>
                    <div class="audio-bar w-1 bg-white/50 rounded-full transition-all duration-100" style="height: 8px;"></div>
                </div>
            </div>

            <!-- Current Transcript -->
            <div id="voiceChatTranscript" class="text-white/80 text-center max-h-40 overflow-y-auto mb-4 px-4 w-full">
                <p class="text-sm text-white/50">ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å¯¹è¯</p>
            </div>

            <!-- AI Response -->
            <div id="voiceChatResponse" class="text-white text-center max-h-32 overflow-y-auto mb-8 px-4 w-full hidden">
                <p class="text-lg"></p>
            </div>
        </div>

    </div>

    <script>
        // State Management
        const state = {
            apiKey: localStorage.getItem('openrouter_api_key') || '',
            selectedModel: localStorage.getItem('selected_model') || 'x-ai/grok-4.1-fast',
            roleGenModel: localStorage.getItem('role_gen_model') || 'x-ai/grok-4.1-fast',
            chatModel: localStorage.getItem('chat_model') || 'google/gemini-2.5-flash-preview',
            imagePromptModel: localStorage.getItem('image_prompt_model') || 'x-ai/grok-4.1-fast',
            volcAppId: localStorage.getItem('volc_appid') || '',
            volcToken: localStorage.getItem('volc_token') || '',
            volcTtsToken: localStorage.getItem('volc_tts_token') || '',
            volcTtsMode: localStorage.getItem('volc_tts_mode') || 'normal',
            volcTtsAccessKey: localStorage.getItem('volc_tts_access_key') || '',
            volcCluster: localStorage.getItem('volc_cluster') || 'volcengine_streaming_common',
            volcTtsCluster: localStorage.getItem('volc_tts_cluster') || 'volcano_tts',
            volcTtsVoice: localStorage.getItem('volc_tts_voice') || 'zh_female_vv_uranus_bigtts',
            autoTtsEnabled: localStorage.getItem('auto_tts_enabled') === 'true',
            autoTtsThreshold: parseInt(localStorage.getItem('auto_tts_threshold') || '100'),
            replicateToken: localStorage.getItem('replicate_token') || '',
            replicateModel: localStorage.getItem('replicate_model') || 'realistic-vision-v5.1',
            allModels: [], // Store all fetched models for filtering
            roles: (() => {
                // å†…ç½®è§’è‰²
                const builtinRoles = [
                    { id: 'voice_assistant', name: 'AIè¯­éŸ³åŠ©æ‰‹', desc: 'æ™ºèƒ½å‹å¥½çš„è¯­éŸ³äº¤äº’åŠ©æ‰‹', prompt: 'You are an AI voice assistant designed for natural conversation. You are helpful, friendly, and respond in a conversational tone suitable for voice interaction. Keep your responses concise and clear. Please respond in Chinese.', icon: 'ğŸ™ï¸' }
                ];
                // åŠ è½½å†…ç½®è§’è‰²çš„ç¼–è¾‘
                const builtinEdits = JSON.parse(localStorage.getItem('builtin_role_edits')) || {};
                const mergedBuiltin = builtinRoles.map(role => ({
                    ...role,
                    ...(builtinEdits[role.id] || {})
                }));
                // åŠ è½½è‡ªå®šä¹‰è§’è‰²
                const customRoles = JSON.parse(localStorage.getItem('custom_roles')) || [];
                return [...mergedBuiltin, ...customRoles];
            })(),
            currentRoleId: null,
            chatHistory: JSON.parse(localStorage.getItem('chat_history')) || {}, // roleId -> messages[]
            ttsCache: {}, // (text + voiceType) -> base64 audio
            currentAudio: null, // Track currently playing audio
            currentPlayingIndex: null, // Track which message index is currently playing
            isPlayingAll: false, // Track if continuous playback is active
            playAllQueue: [], // Queue for continuous playback
            editingRoleId: null, // Track which role is being edited (null = create mode)
            audioContext: null, // Web Audio API Context
            // Voice Chat State
            voiceChatActive: false, // Whether voice chat mode is active
            voiceChatListening: false, // Whether currently listening for voice
            voiceChatMediaStream: null, // MediaStream for voice chat
            voiceChatAnalyser: null, // AnalyserNode for audio level detection
            voiceChatRecorder: null, // MediaRecorder for capturing audio
            voiceChatAudioChunks: [], // Audio chunks being recorded
            voiceChatSilenceTimer: null, // Timer for silence detection
            voiceChatVadActive: false, // Voice Activity Detection state
            voiceChatSpeechDetected: false, // Whether speech was detected in current session
            voiceChatProcessing: false, // Whether processing ASR/LLM/TTS
            voiceChatSpeechStartChunkIndex: -1, // Chunk index when speech started
            // Local ASR State
            asrMode: localStorage.getItem('asr_mode') || 'cloud', // 'cloud' or 'local'
            whisperModel: localStorage.getItem('whisper_model') || 'Xenova/whisper-tiny',
            whisperLanguage: localStorage.getItem('whisper_language') || 'chinese',
            whisperPipeline: null, // Whisper pipeline instance
            whisperModelLoaded: false, // Whether Whisper model is loaded
            whisperModelLoading: false // Whether Whisper model is currently loading
        };

        // Audio Helpers
        function getAudioContext() {
            if (!state.audioContext) {
                state.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            return state.audioContext;
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function stopCurrentAudio() {
            if (state.currentAudio) {
                if (state.currentAudio.stop) {
                    // AudioBufferSourceNode
                    try { state.currentAudio.stop(); } catch(e) {}
                } else if (state.currentAudio.pause) {
                    // HTMLAudioElement
                    state.currentAudio.pause();
                    state.currentAudio.currentTime = 0;
                }
                state.currentAudio = null;
            }
            
            // If we were playing a specific message, reset its button state
            if (state.currentPlayingIndex !== null) {
                const btn = document.querySelector(`button[data-msg-index="${state.currentPlayingIndex}"]`);
                if (btn) {
                    const icon = btn.querySelector('i');
                    if (icon) icon.className = 'fas fa-volume-up';
                    btn.classList.remove('text-blue-600', 'animate-pulse');
                    
                    // Restore cache color state if needed
                    const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
                    const messages = state.chatHistory[state.currentRoleId] || [];
                    const msg = messages[state.currentPlayingIndex];
                    if (msg) {
                        const cacheKey = msg.content + '_' + voiceType;
                        if (state.ttsCache[cacheKey]) {
                            btn.classList.remove('text-gray-400', 'hover:text-blue-500');
                            btn.classList.add('text-green-500', 'hover:text-green-600');
                        } else {
                            btn.classList.remove('text-green-500', 'hover:text-green-600');
                            btn.classList.add('text-gray-400', 'hover:text-blue-500');
                        }
                    }
                }
                state.currentPlayingIndex = null;
            }
        }

        // DOM Elements
        const elements = {
            settingsBtn: document.getElementById('settingsBtn'),
            settingsModal: document.getElementById('settingsModal'),
            closeSettings: document.getElementById('closeSettings'),
            closeSettingsDesktop: document.getElementById('closeSettingsDesktop'),
            saveSettings: document.getElementById('saveSettings'),
            apiKeyInput: document.getElementById('apiKeyInput'),
            verifyKey: document.getElementById('verifyKey'),
            modelSearch: document.getElementById('modelSearch'),
            modelSelect: document.getElementById('modelSelect'),
            refreshModels: document.getElementById('refreshModels'),
            roleGenModel: document.getElementById('roleGenModel'),
            chatModel: document.getElementById('chatModel'),
            imagePromptModel: document.getElementById('imagePromptModel'),

            roleList: document.getElementById('roleList'),
            addRoleBtn: document.getElementById('addRoleBtn'),
            roleModal: document.getElementById('roleModal'),
            roleModalTitle: document.getElementById('roleModalTitle'),
            closeRoleModal: document.getElementById('closeRoleModal'),
            cancelRoleModal: document.getElementById('cancelRoleModal'),
            saveRole: document.getElementById('saveRole'),
            newRoleName: document.getElementById('newRoleName'),
            newRoleDesc: document.getElementById('newRoleDesc'),
            newRolePrompt: document.getElementById('newRolePrompt'),
            aiPromptInput: document.getElementById('aiPromptInput'),
            aiGenerateBtn: document.getElementById('aiGenerateBtn'),

            chatMessages: document.getElementById('chatMessages'),
            chatForm: document.getElementById('chatForm'),
            userInput: document.getElementById('userInput'),
            sendBtn: document.getElementById('sendBtn'),
            voiceBtn: document.getElementById('voiceBtn'),
            autoReplyBtn: document.getElementById('autoReplyBtn'),
            recordingStatus: document.getElementById('recordingStatus'),
            volcAppId: document.getElementById('volcAppId'),
            volcToken: document.getElementById('volcToken'),
            volcTtsToken: document.getElementById('volcTtsToken'),
            volcTtsMode: document.getElementById('volcTtsMode'),
            volcTtsAccessKey: document.getElementById('volcTtsAccessKey'),
            ttsNormalAuthContainer: document.getElementById('ttsNormalAuthContainer'),
            ttsStreamAuthContainer: document.getElementById('ttsStreamAuthContainer'),
            volcCluster: document.getElementById('volcCluster'),
            volcTtsCluster: document.getElementById('volcTtsCluster'),
            volcTtsVoice: document.getElementById('volcTtsVoice'),
            autoTtsEnabled: document.getElementById('autoTtsEnabled'),
            autoTtsThreshold: document.getElementById('autoTtsThreshold'),
            autoTtsThresholdContainer: document.getElementById('autoTtsThresholdContainer'),
            replicateToken: document.getElementById('replicateToken'),
            // æœ¬åœ° ASR å…ƒç´ 
            asrMode: document.getElementById('asrMode'),
            cloudAsrSettings: document.getElementById('cloudAsrSettings'),
            localAsrSettings: document.getElementById('localAsrSettings'),
            whisperModel: document.getElementById('whisperModel'),
            whisperLanguage: document.getElementById('whisperLanguage'),
            whisperModelStatus: document.getElementById('whisperModelStatus'),
            whisperModelStatusText: document.getElementById('whisperModelStatusText'),
            whisperModelProgress: document.getElementById('whisperModelProgress'),
            whisperProgressBar: document.getElementById('whisperProgressBar'),
            whisperProgressText: document.getElementById('whisperProgressText'),
            replicateModel: document.getElementById('replicateModel'),
            activeRoleName: document.getElementById('activeRoleName'),
            activeRoleDesc: document.getElementById('activeRoleDesc'),
            activeRoleHeader: document.getElementById('activeRoleHeader'),
            clearChatBtn: document.getElementById('clearChatBtn'),
            playAllBtn: document.getElementById('playAllBtn'),
            downloadAllBtn: document.getElementById('downloadAllBtn'),
            compressHistoryBtn: document.getElementById('compressHistoryBtn'),
            // è¯­éŸ³å¯¹è¯å…ƒç´ 
            voiceChatBtn: document.getElementById('voiceChatBtn'),
            voiceChatModal: document.getElementById('voiceChatModal'),
            closeVoiceChatBtn: document.getElementById('closeVoiceChatBtn'),
            voiceChatStatus: document.getElementById('voiceChatStatus'),
            voiceVisualizer: document.getElementById('voiceVisualizer'),
            voicePulse: document.getElementById('voicePulse'),
            voiceChatIcon: document.getElementById('voiceChatIcon'),
            audioLevelBars: document.getElementById('audioLevelBars'),
            voiceChatTranscript: document.getElementById('voiceChatTranscript'),
            voiceChatResponse: document.getElementById('voiceChatResponse'),
            // ç§»åŠ¨ç«¯å…ƒç´ 
            menuBtn: document.getElementById('menuBtn'),
            mobileSidebar: document.getElementById('mobileSidebar'),
            mobileOverlay: document.getElementById('mobileOverlay'),
            closeSidebarBtn: document.getElementById('closeSidebarBtn'),
            roleListMobile: document.getElementById('roleListMobile'),
            addRoleBtnMobile: document.getElementById('addRoleBtnMobile'),
            roleAvatarBtn: document.getElementById('roleAvatarBtn')
        };

        // Initialize
        async function init() {
            // Configure marked to disable strikethrough which causes issues with tildes in roleplay
            marked.use({
                tokenizer: {
                    del(src) {
                        return false; // Disable strikethrough
                    }
                }
            });

            state.volcCluster = localStorage.getItem('volc_cluster') || 'volcengine_streaming_common';
            // è¿ç§»æ—§çš„ ASR Resource ID å€¼åˆ°æ–°é€‰é¡¹
            if (state.volcCluster === 'volc_auc_common' || state.volcCluster === 'volc.bigasr.auc') {
                state.volcCluster = 'volcengine_streaming_common';
                localStorage.setItem('volc_cluster', state.volcCluster);
            }

            // ç§»åŠ¨ç«¯è¾“å…¥æ¡†å›ºå®šåœ¨åº•éƒ¨
            setupMobileInputFixed();
            window.addEventListener('resize', setupMobileInputFixed);

            renderRoles();

            // é»˜è®¤é€‰æ‹© AIè¯­éŸ³åŠ©æ‰‹ è§’è‰²
            const defaultRole = state.roles.find(r => r.id === 'voice_assistant');
            if (defaultRole && !state.currentRoleId) {
                selectRole(defaultRole.id);
            }

            elements.apiKeyInput.value = state.apiKey;
            elements.volcAppId.value = state.volcAppId;
            elements.volcToken.value = state.volcToken;
            elements.volcTtsToken.value = state.volcTtsToken;
            elements.volcTtsMode.value = state.volcTtsMode;
            elements.volcTtsAccessKey.value = state.volcTtsAccessKey;
            updateTtsModeUI();
            elements.volcCluster.value = state.volcCluster;
            elements.volcTtsCluster.value = state.volcTtsCluster;
            elements.volcTtsVoice.value = state.volcTtsVoice;
            elements.autoTtsEnabled.checked = state.autoTtsEnabled;
            elements.autoTtsThreshold.value = state.autoTtsThreshold;
            if (state.autoTtsEnabled) elements.autoTtsThresholdContainer.classList.remove('hidden');
            elements.replicateToken.value = state.replicateToken;
            elements.replicateModel.value = state.replicateModel;
            // åˆå§‹åŒ–æœ¬åœ° ASR è®¾ç½®
            elements.asrMode.value = state.asrMode;
            elements.whisperModel.value = state.whisperModel;
            elements.whisperLanguage.value = state.whisperLanguage;
            updateAsrModeUI();
            if (state.apiKey) {
                fetchModels();
            }
            setupEventListeners();
        }

        // æ›´æ–° ASR æ¨¡å¼ UI
        function updateAsrModeUI() {
            if (state.asrMode === 'local') {
                elements.cloudAsrSettings.classList.add('hidden');
                elements.localAsrSettings.classList.remove('hidden');
                updateWhisperModelStatus();
            } else {
                elements.cloudAsrSettings.classList.remove('hidden');
                elements.localAsrSettings.classList.add('hidden');
            }
        }

        // æ›´æ–° Whisper æ¨¡å‹çŠ¶æ€æ˜¾ç¤º
        function updateWhisperModelStatus() {
            if (state.whisperModelLoading) {
                elements.whisperModelStatusText.textContent = 'åŠ è½½ä¸­...';
                elements.whisperModelStatusText.className = 'text-sm font-medium text-yellow-500';
            } else if (state.whisperModelLoaded) {
                elements.whisperModelStatusText.textContent = 'å·²åŠ è½½ âœ“';
                elements.whisperModelStatusText.className = 'text-sm font-medium text-green-500';
                elements.whisperModelProgress.classList.add('hidden');
            } else {
                elements.whisperModelStatusText.textContent = 'æœªåŠ è½½';
                elements.whisperModelStatusText.className = 'text-sm font-medium text-gray-500';
            }
        }

        // æ›´æ–° TTS æ¨¡å¼ UI
        function updateTtsModeUI() {
            if (state.volcTtsMode === 'stream') {
                elements.ttsNormalAuthContainer.classList.add('hidden');
                elements.ttsStreamAuthContainer.classList.remove('hidden');
            } else {
                elements.ttsNormalAuthContainer.classList.remove('hidden');
                elements.ttsStreamAuthContainer.classList.add('hidden');
            }
        }

        // ç§»åŠ¨ç«¯è¾“å…¥æ¡†å›ºå®šåœ¨åº•éƒ¨
        function setupMobileInputFixed() {
            const inputArea = document.getElementById('inputArea');
            const mainArea = document.getElementById('mainChatArea');
            const chatMessages = document.getElementById('chatMessages');
            const isMobile = window.innerWidth < 768;

            if (isMobile) {
                inputArea.classList.add('input-area-mobile-fixed');
                mainArea.classList.add('main-with-fixed-input');
                chatMessages.classList.add('chat-messages-mobile-fixed');
            } else {
                inputArea.classList.remove('input-area-mobile-fixed');
                mainArea.classList.remove('main-with-fixed-input');
                chatMessages.classList.remove('chat-messages-mobile-fixed');
            }
        }

        // ç§»åŠ¨ç«¯ä¾§è¾¹æ æ§åˆ¶
        function openMobileSidebar() {
            elements.mobileSidebar.classList.add('open');
            elements.mobileOverlay.classList.add('open');
            document.body.style.overflow = 'hidden';
        }

        function closeMobileSidebar() {
            elements.mobileSidebar.classList.remove('open');
            elements.mobileOverlay.classList.remove('open');
            document.body.style.overflow = '';
        }

        function setupEventListeners() {
            // ç§»åŠ¨ç«¯ä¾§è¾¹æ äº‹ä»¶
            elements.menuBtn.onclick = openMobileSidebar;
            elements.closeSidebarBtn.onclick = closeMobileSidebar;
            elements.mobileOverlay.onclick = closeMobileSidebar;
            elements.addRoleBtnMobile.onclick = () => {
                closeMobileSidebar();
                openCreateRoleModal();
            };
            // ç§»åŠ¨ç«¯ç‚¹å‡»å¤´åƒæ‰“å¼€ä¾§è¾¹æ 
            elements.roleAvatarBtn.onclick = () => {
                if (window.innerWidth < 768) {
                    openMobileSidebar();
                }
            };

            elements.settingsBtn.onclick = () => {
                elements.apiKeyInput.value = state.apiKey;
                elements.settingsModal.classList.remove('hidden');
            };
            elements.closeSettings.onclick = () => elements.settingsModal.classList.add('hidden');
            elements.closeSettingsDesktop.onclick = () => elements.settingsModal.classList.add('hidden');
            elements.saveSettings.onclick = () => {
                state.apiKey = elements.apiKeyInput.value;
                state.selectedModel = elements.modelSelect.value;
                state.roleGenModel = elements.roleGenModel.value || state.roleGenModel;
                state.chatModel = elements.chatModel.value || state.chatModel;
                state.imagePromptModel = elements.imagePromptModel.value || state.imagePromptModel;
                state.volcAppId = elements.volcAppId.value;
                state.volcToken = elements.volcToken.value;
                state.volcTtsToken = elements.volcTtsToken.value;
                state.volcTtsMode = elements.volcTtsMode.value;
                state.volcTtsAccessKey = elements.volcTtsAccessKey.value;
                state.volcCluster = elements.volcCluster.value;
                state.volcTtsCluster = elements.volcTtsCluster.value;
                state.volcTtsVoice = elements.volcTtsVoice.value;
                state.autoTtsEnabled = elements.autoTtsEnabled.checked;
                state.autoTtsThreshold = parseInt(elements.autoTtsThreshold.value) || 100;
                state.replicateToken = elements.replicateToken.value;
                state.replicateModel = elements.replicateModel.value;
                // ä¿å­˜æœ¬åœ° ASR è®¾ç½®
                state.asrMode = elements.asrMode.value;
                state.whisperModel = elements.whisperModel.value;
                state.whisperLanguage = elements.whisperLanguage.value;

                localStorage.setItem('openrouter_api_key', state.apiKey);
                localStorage.setItem('selected_model', state.selectedModel);
                localStorage.setItem('role_gen_model', state.roleGenModel);
                localStorage.setItem('chat_model', state.chatModel);
                localStorage.setItem('image_prompt_model', state.imagePromptModel);
                localStorage.setItem('volc_appid', state.volcAppId);
                localStorage.setItem('volc_token', state.volcToken);
                localStorage.setItem('volc_tts_token', state.volcTtsToken);
                localStorage.setItem('volc_tts_mode', state.volcTtsMode);
                localStorage.setItem('volc_tts_access_key', state.volcTtsAccessKey);
                localStorage.setItem('volc_cluster', state.volcCluster);
                localStorage.setItem('volc_tts_cluster', state.volcTtsCluster);
                localStorage.setItem('volc_tts_voice', state.volcTtsVoice);
                localStorage.setItem('auto_tts_enabled', state.autoTtsEnabled);
                localStorage.setItem('auto_tts_threshold', state.autoTtsThreshold);
                localStorage.setItem('replicate_token', state.replicateToken);
                localStorage.setItem('replicate_model', state.replicateModel);
                // ä¿å­˜æœ¬åœ° ASR è®¾ç½®åˆ° localStorage
                localStorage.setItem('asr_mode', state.asrMode);
                localStorage.setItem('whisper_model', state.whisperModel);
                localStorage.setItem('whisper_language', state.whisperLanguage);

                elements.settingsModal.classList.add('hidden');
                checkInputs();
            };

            // ASR æ¨¡å¼åˆ‡æ¢äº‹ä»¶
            elements.asrMode.onchange = () => {
                state.asrMode = elements.asrMode.value;
                updateAsrModeUI();
            };

            // TTS æ¨¡å¼åˆ‡æ¢äº‹ä»¶
            elements.volcTtsMode.onchange = () => {
                state.volcTtsMode = elements.volcTtsMode.value;
                updateTtsModeUI();
            };

            elements.autoTtsEnabled.onchange = () => {
                if (elements.autoTtsEnabled.checked) {
                    elements.autoTtsThresholdContainer.classList.remove('hidden');
                } else {
                    elements.autoTtsThresholdContainer.classList.add('hidden');
                }
            };

            elements.verifyKey.onclick = () => {
                state.apiKey = elements.apiKeyInput.value;
                fetchModels();
            };
            elements.refreshModels.onclick = fetchModels;

            elements.modelSearch.oninput = () => {
                const term = elements.modelSearch.value.toLowerCase();
                renderModelOptions(state.allModels.filter(m =>
                    m.id.toLowerCase().includes(term) ||
                    (m.name && m.name.toLowerCase().includes(term))
                ));
            };

            elements.addRoleBtn.onclick = openCreateRoleModal;
            elements.closeRoleModal.onclick = () => {
                elements.roleModal.classList.add('hidden');
                state.editingRoleId = null;
            };
            elements.cancelRoleModal.onclick = () => {
                elements.roleModal.classList.add('hidden');
                state.editingRoleId = null;
            };
            elements.saveRole.onclick = saveRole;
            elements.aiGenerateBtn.onclick = generateRoleWithAI;
            elements.autoReplyBtn.onclick = autoReply;

            // Textarea auto-resize and Enter key handling
            const adjustTextareaHeight = () => {
                elements.userInput.style.height = 'auto';
                elements.userInput.style.height = (elements.userInput.scrollHeight) + 'px';

                // ç§»åŠ¨ç«¯ï¼šåŠ¨æ€è°ƒæ•´åº•éƒ¨å†…è¾¹è·ä»¥é€‚åº”è¾“å…¥æ¡†é«˜åº¦å˜åŒ–
                const isMobile = window.innerWidth < 768;
                if (isMobile) {
                    const inputArea = document.getElementById('inputArea');
                    const mainArea = document.getElementById('mainChatArea');
                    if (inputArea && mainArea) {
                        const inputHeight = inputArea.offsetHeight;
                        mainArea.style.paddingBottom = (inputHeight + 16) + 'px';
                    }
                }
            };
            elements.userInput.addEventListener('input', adjustTextareaHeight);

            elements.userInput.addEventListener('keydown', (e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    if (!elements.sendBtn.disabled) {
                        sendMessage();
                    }
                }
            });

            // AI Prompt Input (çµæ„Ÿä¸€é”®ç”Ÿæˆ) auto-resize and Enter key handling
            const adjustAiPromptHeight = () => {
                elements.aiPromptInput.style.height = 'auto';
                elements.aiPromptInput.style.height = (elements.aiPromptInput.scrollHeight) + 'px';
            };
            elements.aiPromptInput.addEventListener('input', adjustAiPromptHeight);

            elements.aiPromptInput.addEventListener('keydown', (e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    if (!elements.aiGenerateBtn.disabled) {
                        generateRoleWithAI();
                    }
                }
            });

            elements.chatForm.onsubmit = (e) => {
                e.preventDefault();
                sendMessage();
            };

            elements.clearChatBtn.onclick = () => {
                if (state.currentRoleId && confirm('ç¡®å®šè¦æ¸…ç©ºä¸å½“å‰è§’è‰²çš„å¯¹è¯è®°å½•å—ï¼Ÿ')) {
                    state.chatHistory[state.currentRoleId] = [];
                    saveChatHistory();
                    renderMessages();
                }
            };

            elements.compressHistoryBtn.onclick = compressConversationHistory;

            setupPlayAllButton();
            setupVoiceChat();

            // Voice Recognition Logic
            let mediaRecorder;
            let audioChunks = [];

            // è·å–æµè§ˆå™¨æ”¯æŒçš„æœ€ä½³éŸ³é¢‘æ ¼å¼
            function getSupportedMimeType() {
                const types = [
                    'audio/webm;codecs=opus',
                    'audio/webm',
                    'audio/mp4',
                    'audio/ogg;codecs=opus',
                    'audio/wav'
                ];
                for (const type of types) {
                    if (MediaRecorder.isTypeSupported(type)) {
                        return type;
                    }
                }
                return '';
            }

            elements.voiceBtn.onclick = async () => {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                    elements.recordingStatus.classList.add('hidden');
                    elements.voiceBtn.classList.remove('bg-red-500', 'text-white');
                    return;
                }

                try {
                    // è¯·æ±‚é«˜è´¨é‡éŸ³é¢‘ï¼Œé€‚åˆè¯­éŸ³è¯†åˆ«
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            sampleRate: 16000  // è¯·æ±‚ 16kHzï¼ˆæµè§ˆå™¨å¯èƒ½å¿½ç•¥ï¼‰
                        }
                    });

                    const mimeType = getSupportedMimeType();
                    const options = mimeType ? { mimeType } : {};
                    mediaRecorder = new MediaRecorder(stream, options);
                    audioChunks = [];

                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };

                    mediaRecorder.onstop = async () => {
                        const actualMimeType = mediaRecorder.mimeType || mimeType || 'audio/webm';
                        const audioBlob = new Blob(audioChunks, { type: actualMimeType });
                        await handleVoiceUpload(audioBlob);
                        stream.getTracks().forEach(track => track.stop());
                    };

                    mediaRecorder.start(100); // æ¯100msæ”¶é›†ä¸€æ¬¡æ•°æ®ï¼Œæé«˜å…¼å®¹æ€§
                    elements.recordingStatus.classList.remove('hidden');
                    elements.voiceBtn.classList.add('bg-red-500', 'text-white');
                } catch (err) {
                    alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·ç¡®ä¿å·²æˆäºˆæƒé™ã€‚');
                    console.error(err);
                }
            };

            async function handleVoiceUpload(blob) {
                const asrStartTime = performance.now();
                console.log(`[ASR] ========== å¼€å§‹ASRå¤„ç† ==========`);
                console.log(`[ASR] éŸ³é¢‘Blobå¤§å°: ${(blob.size / 1024).toFixed(2)} KB, ç±»å‹: ${blob.type}`);

                if (!state.volcAppId || !state.volcToken) {
                    alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®ç«å±±å¼•æ“ AppID å’Œ Access Token');
                    return;
                }

                if (blob.size < 1000) {
                    alert('å½•éŸ³æ•°æ®å¤ªå°ï¼Œè¯·é‡æ–°å½•éŸ³');
                    return;
                }

                elements.userInput.placeholder = "æ­£åœ¨è¯†åˆ«è¯­éŸ³...";
                elements.userInput.disabled = true;

                const formDataStartTime = performance.now();
                const formData = new FormData();
                const ext = blob.type.includes('mp4') ? 'mp4' : blob.type.includes('webm') ? 'webm' : 'audio';
                formData.append('audio', blob, `recording.${ext}`);
                formData.append('appid', state.volcAppId);
                formData.append('token', state.volcToken);
                formData.append('cluster', state.volcCluster);
                console.log(`[ASR] FormDataå‡†å¤‡è€—æ—¶: ${(performance.now() - formDataStartTime).toFixed(2)} ms`);

                try {
                    const uploadStartTime = performance.now();
                    console.log(`[ASR] å¼€å§‹ä¸Šä¼ åˆ°æœåŠ¡å™¨...`);
                    const resp = await fetch('/api/asr', {
                        method: 'POST',
                        body: formData
                    });
                    const uploadEndTime = performance.now();
                    console.log(`[ASR] æœåŠ¡å™¨å“åº”è€—æ—¶: ${(uploadEndTime - uploadStartTime).toFixed(2)} ms`);

                    const parseStartTime = performance.now();
                    const data = await resp.json();
                    console.log(`[ASR] JSONè§£æè€—æ—¶: ${(performance.now() - parseStartTime).toFixed(2)} ms`);

                    // æ‰“å°æœåŠ¡ç«¯è¿”å›çš„è®¡æ—¶ä¿¡æ¯
                    if (data.timing) {
                        console.log(`[ASR] === æœåŠ¡ç«¯è®¡æ—¶è¯¦æƒ… ===`);
                        for (const [key, value] of Object.entries(data.timing)) {
                            console.log(`[ASR]   ${key}: ${value} ms`);
                        }
                    }

                    const totalTime = performance.now() - asrStartTime;
                    console.log(`[ASR] ========== ASRæ€»è€—æ—¶: ${totalTime.toFixed(2)} ms ==========`);

                    if (data.text) {
                        elements.userInput.value = data.text;
                        elements.userInput.dispatchEvent(new Event('input'));
                        // ASR è¯†åˆ«æˆåŠŸåç›´æ¥å‘é€æ¶ˆæ¯
                        elements.userInput.disabled = false;
                        elements.userInput.placeholder = "è¾“å…¥æ¶ˆæ¯...";
                        sendMessage();
                        return; // æå‰è¿”å›ï¼Œé¿å… finally é‡å¤è®¾ç½®
                    } else {
                        alert('è¯†åˆ«å¤±è´¥: ' + (data.message || 'æœªçŸ¥é”™è¯¯'));
                    }
                } catch (err) {
                    console.error(`[ASR] é”™è¯¯: ${err.message}`);
                    alert('è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: ' + (err.message || 'ç½‘ç»œè¿æ¥å¼‚å¸¸'));
                } finally {
                    elements.userInput.disabled = false;
                    elements.userInput.placeholder = "è¾“å…¥æ¶ˆæ¯...";
                }
            }
        }

        function saveChatHistory() {
            localStorage.setItem('chat_history', JSON.stringify(state.chatHistory));
        }

        // å‹ç¼©å¯¹è¯å†å²ï¼Œä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦ä»¥å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦
        async function compressConversationHistory() {
            if (!state.currentRoleId) {
                alert('è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§’è‰²');
                return;
            }

            const messages = state.chatHistory[state.currentRoleId] || [];
            if (messages.length < 4) {
                alert('å¯¹è¯å†å²å¤ªçŸ­ï¼Œæ— éœ€å‹ç¼©ï¼ˆè‡³å°‘éœ€è¦4æ¡æ¶ˆæ¯ï¼‰');
                return;
            }

            if (!state.apiKey) {
                alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key');
                return;
            }

            const role = state.roles.find(r => r.id === state.currentRoleId);
            if (!role) return;

            // ç¡®è®¤å‹ç¼©
            const msgCount = messages.length;
            if (!confirm(`å½“å‰æœ‰ ${msgCount} æ¡å¯¹è¯è®°å½•ã€‚\n\nå‹ç¼©åå°†ä¿ç•™æœ€è¿‘2æ¡å¯¹è¯ï¼Œå…¶ä½™å†…å®¹å°†è¢«å‹ç¼©ä¸ºæ‘˜è¦ã€‚\n\nç¡®å®šè¦å‹ç¼©å¯¹è¯å†å²å—ï¼Ÿ`)) {
                return;
            }

            // æ›´æ–°æŒ‰é’®çŠ¶æ€
            const btn = elements.compressHistoryBtn;
            const icon = btn.querySelector('i');
            const originalClass = icon.className;
            icon.className = 'fas fa-spinner animate-spin text-lg';
            btn.disabled = true;

            try {
                // ä¿ç•™æœ€è¿‘çš„2æ¡æ¶ˆæ¯
                const recentMessages = messages.slice(-2);
                const toCompress = messages.slice(0, -2);

                if (toCompress.length === 0) {
                    alert('æ²¡æœ‰éœ€è¦å‹ç¼©çš„å†…å®¹');
                    return;
                }

                // æ ¼å¼åŒ–è¦å‹ç¼©çš„å¯¹è¯
                const conversationText = toCompress.map(m => {
                    const speaker = m.role === 'user' ? 'ç”¨æˆ·' : role.name;
                    return `${speaker}ï¼š${m.content}`;
                }).join('\n');

                // è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
                const response = await fetch('/api/proxy-llm', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        apiKey: state.apiKey,
                        model: state.chatModel,
                        messages: [
                            {
                                role: 'system',
                                content: `ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹è§’è‰²æ‰®æ¼”å¯¹è¯å†å²å‹ç¼©æˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€é‡è¦äº‹ä»¶ã€è§’è‰²å…³ç³»å‘å±•å’Œæƒ…æ„Ÿå˜åŒ–ã€‚

è§’è‰²è®¾å®šï¼š${role.name} - ${role.desc}

è¦æ±‚ï¼š
1. ä½¿ç”¨ç¬¬ä¸‰äººç§°å™è¿°
2. ä¿ç•™å¯¹è¯ä¸­çš„å…³é”®å‰§æƒ…ç‚¹å’Œé‡è¦å†³å®š
3. è®°å½•è§’è‰²ä¹‹é—´å…³ç³»çš„å˜åŒ–
4. æ‘˜è¦åº”è¯¥ç®€æ´ä½†ä¿¡æ¯å®Œæ•´
5. ç”¨ä¸­æ–‡è¾“å‡º
6. æ ¼å¼ï¼šã€å¯¹è¯æ‘˜è¦ã€‘å¼€å¤´ï¼Œç„¶åæ˜¯æ‘˜è¦å†…å®¹`
                            },
                            {
                                role: 'user',
                                content: `è¯·å‹ç¼©ä»¥ä¸‹å¯¹è¯å†å²ï¼š\n\n${conversationText}`
                            }
                        ]
                    })
                });

                if (!response.ok) {
                    throw new Error('API è¯·æ±‚å¤±è´¥');
                }

                const data = await response.json();
                const summary = data.choices?.[0]?.message?.content;

                if (!summary) {
                    throw new Error('æ— æ³•ç”Ÿæˆæ‘˜è¦');
                }

                // åˆ›å»ºæ–°çš„å¯¹è¯å†å²ï¼šæ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯
                const compressedHistory = [
                    { role: 'system', content: summary, isCompressed: true },
                    ...recentMessages
                ];

                // æ›´æ–°çŠ¶æ€
                state.chatHistory[state.currentRoleId] = compressedHistory;
                saveChatHistory();
                renderMessages();

                alert(`å‹ç¼©å®Œæˆï¼\nåŸæœ‰ ${msgCount} æ¡æ¶ˆæ¯ â†’ ç°æœ‰ ${compressedHistory.length} æ¡ï¼ˆå«1æ¡æ‘˜è¦ï¼‰`);

            } catch (error) {
                console.error('Compress Error:', error);
                alert('å‹ç¼©å¯¹è¯å†å²å¤±è´¥: ' + error.message);
            } finally {
                icon.className = originalClass;
                btn.disabled = false;
            }
        }

        async function fetchModels() {
            const keyToUse = elements.apiKeyInput.value || state.apiKey;
            if (!keyToUse) {
                alert('è¯·å…ˆè¾“å…¥ API Key');
                return;
            }
            elements.modelSelect.innerHTML = '<option>æ­£åœ¨è·å–æ¨¡å‹...</option>';
            try {
                const response = await fetch('https://openrouter.ai/api/v1/models', {
                    headers: { 'Authorization': `Bearer ${keyToUse}` }
                });
                const data = await response.json();
                if (data.data && Array.isArray(data.data)) {
                    state.allModels = data.data;
                    renderModelOptions(state.allModels);
                } else {
                    throw new Error('API è¿”å›æ ¼å¼é”™è¯¯');
                }
            } catch (error) {
                console.error(error);
                const fallbackModels = [
                    { id: 'x-ai/grok-4.1-fast', name: 'Grok 4.1 Fast' },
                    { id: 'x-ai/grok-2-1212', name: 'Grok 2 (1212)' },
                    { id: 'google/gemini-flash-1.5', name: 'Gemini Flash 1.5' }
                ];
                state.allModels = fallbackModels;
                renderModelOptions(fallbackModels);
                alert('è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®ã€‚å·²åŠ è½½å¸¸ç”¨å¤‡é€‰åˆ—è¡¨ã€‚');
            }
        }

        function renderModelOptions(models) {
            elements.modelSelect.innerHTML = '';
            models.forEach(model => {
                const option = document.createElement('option');
                option.value = model.id;
                option.textContent = model.name || model.id;
                option.className = "py-1 px-2 hover:bg-blue-50";
                if (model.id === state.selectedModel) option.selected = true;
                elements.modelSelect.appendChild(option);
            });
            if (models.length === 0) {
                elements.modelSelect.innerHTML = '<option disabled>æœªæ‰¾åˆ°åŒ¹é…æ¨¡å‹</option>';
            }

            // åŒæ—¶æ›´æ–°åœºæ™¯æ¨¡å‹é€‰æ‹©å™¨
            updateScenarioModelSelects(state.allModels);
        }

        // æ›´æ–°åœºæ™¯æ¨¡å‹é€‰æ‹©å™¨
        function updateScenarioModelSelects(models) {
            const selects = [
                { el: elements.roleGenModel, value: state.roleGenModel },
                { el: elements.chatModel, value: state.chatModel },
                { el: elements.imagePromptModel, value: state.imagePromptModel }
            ];

            selects.forEach(({ el, value }) => {
                el.innerHTML = '<option value="">ä»ä¸Šæ–¹åˆ—è¡¨é€‰æ‹©...</option>';
                models.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model.id;
                    option.textContent = model.name || model.id;
                    if (model.id === value) option.selected = true;
                    el.appendChild(option);
                });
            });
        }

        function renderRoles() {
            // åˆ›å»ºè§’è‰²å¡ç‰‡çš„é€šç”¨å‡½æ•°
            function createRoleCard(role, isMobile = false) {
                const isCustom = String(role.id).startsWith('custom-');
                const div = document.createElement('div');
                // ç§»åŠ¨ç«¯ä½¿ç”¨æ›´å¤§çš„è§¦æ‘¸åŒºåŸŸ
                const padding = isMobile ? 'p-4' : 'p-3';
                div.className = `role-card ${padding} border border-gray-200 rounded-xl cursor-pointer hover:shadow-md active:scale-[0.98] transition-all flex items-center gap-3 relative group ${state.currentRoleId === role.id ? 'active' : ''}`;

                // Content container to separate click area from delete button
                const contentDiv = document.createElement('div');
                contentDiv.className = 'flex items-center gap-3 flex-1 overflow-hidden';
                contentDiv.onclick = () => {
                    selectRole(role.id);
                    if (isMobile) closeMobileSidebar();
                };
                contentDiv.innerHTML = `
                    <div class="text-2xl">${role.icon || 'ğŸ‘¤'}</div>
                    <div class="flex-1 overflow-hidden">
                        <div class="font-bold ${isMobile ? 'text-base' : 'text-sm'} truncate">${role.name}</div>
                        <div class="text-xs text-gray-500 truncate">${role.desc}</div>
                    </div>
                `;
                div.appendChild(contentDiv);

                // æŒ‰é’®å®¹å™¨
                const btnContainer = document.createElement('div');
                const mobileClass = isMobile ? 'opacity-100' : 'opacity-0 group-hover:opacity-100';
                btnContainer.className = `absolute right-2 top-1/2 -translate-y-1/2 flex items-center gap-1 ${mobileClass} transition-all z-50`;

                // ç¼–è¾‘æŒ‰é’®ï¼ˆæ‰€æœ‰è§’è‰²éƒ½å¯ç¼–è¾‘ï¼‰
                const editBtn = document.createElement('div');
                editBtn.className = `text-gray-400 hover:text-blue-500 active:text-blue-600 cursor-pointer p-1 bg-white rounded-full shadow-sm ${isMobile ? 'w-10 h-10 flex items-center justify-center' : ''}`;
                editBtn.innerHTML = `<i class="fas fa-edit ${isMobile ? 'text-xl' : 'text-lg'}"></i>`;
                editBtn.title = 'ç¼–è¾‘è§’è‰²';
                editBtn.addEventListener('click', function(e) {
                    e.preventDefault();
                    e.stopPropagation();
                    editRole(role.id);
                    if (isMobile) closeMobileSidebar();
                });
                btnContainer.appendChild(editBtn);

                // åˆ é™¤æŒ‰é’®ï¼ˆä»…è‡ªå®šä¹‰è§’è‰²ï¼‰
                if (isCustom) {
                    const delBtn = document.createElement('div');
                    delBtn.className = `text-gray-400 hover:text-red-500 active:text-red-600 cursor-pointer p-1 bg-white rounded-full shadow-sm ${isMobile ? 'w-10 h-10 flex items-center justify-center' : ''}`;
                    delBtn.innerHTML = `<i class="fas fa-times-circle ${isMobile ? 'text-xl' : 'text-lg'}"></i>`;
                    delBtn.title = 'åˆ é™¤è§’è‰²';
                    delBtn.addEventListener('click', function(e) {
                        e.preventDefault();
                        e.stopPropagation();
                        deleteRole(role.id);
                    });
                    btnContainer.appendChild(delBtn);
                }

                div.appendChild(btnContainer);
                return div;
            }

            // æ¸²æŸ“æ¡Œé¢ç«¯è§’è‰²åˆ—è¡¨
            elements.roleList.innerHTML = '';
            state.roles.forEach(role => {
                elements.roleList.appendChild(createRoleCard(role, false));
            });

            // æ¸²æŸ“ç§»åŠ¨ç«¯è§’è‰²åˆ—è¡¨
            elements.roleListMobile.innerHTML = '';
            state.roles.forEach(role => {
                elements.roleListMobile.appendChild(createRoleCard(role, true));
            });
        }

        function deleteRole(roleId) {
            if (!confirm('ç¡®å®šè¦åˆ é™¤è¿™ä¸ªè§’è‰²å—ï¼Ÿç›¸å…³çš„å¯¹è¯è®°å½•ä¹Ÿå°†è¢«æ¸…é™¤ã€‚')) return;

            // 1. Update state first
            state.roles = state.roles.filter(r => r.id !== roleId);
            delete state.chatHistory[roleId];

            // 2. Persist to localStorage
            saveChatHistory();
            const customRoles = state.roles.filter(r => String(r.id).startsWith('custom-'));
            localStorage.setItem('custom_roles', JSON.stringify(customRoles));

            // 3. Update UI
            if (state.currentRoleId === roleId) {
                state.currentRoleId = null;
                elements.activeRoleName.textContent = 'è¯·é€‰æ‹©è§’è‰²';
                elements.activeRoleDesc.textContent = 'å¼€å§‹æ‚¨çš„å¯¹è¯';
                elements.activeRoleHeader.querySelector('div').textContent = '?';
                elements.clearChatBtn.classList.add('hidden');
                elements.compressHistoryBtn.classList.add('hidden');
                renderMessages(); // Clear messages view
            }

            // 4. Force re-render of role list immediately
            setTimeout(() => {
                renderRoles();
                checkInputs();
            }, 0);
        }

        function editRole(roleId) {
            const role = state.roles.find(r => r.id === roleId);
            if (!role) return;

            // è®¾ç½®ç¼–è¾‘æ¨¡å¼
            state.editingRoleId = roleId;

            // æ›´æ–°å¼¹çª—æ ‡é¢˜
            elements.roleModalTitle.textContent = 'ç¼–è¾‘è§’è‰²';

            // å¡«å……ç°æœ‰æ•°æ®
            elements.newRoleName.value = role.name || '';
            elements.newRoleDesc.value = role.desc || '';
            elements.newRolePrompt.value = role.prompt || '';
            elements.saveRole.dataset.generatedIcon = role.icon || 'ğŸ‘¤';

            // æ˜¾ç¤ºå¼¹çª—
            elements.roleModal.classList.remove('hidden');
        }

        function openCreateRoleModal() {
            // æ¸…é™¤ç¼–è¾‘æ¨¡å¼
            state.editingRoleId = null;

            // æ›´æ–°å¼¹çª—æ ‡é¢˜
            elements.roleModalTitle.textContent = 'åˆ›å»ºæ–°è§’è‰²';

            // æ¸…ç©ºè¾“å…¥
            elements.newRoleName.value = '';
            elements.newRoleDesc.value = '';
            elements.newRolePrompt.value = '';
            elements.aiPromptInput.value = '';
            delete elements.saveRole.dataset.generatedIcon;

            // æ˜¾ç¤ºå¼¹çª—
            elements.roleModal.classList.remove('hidden');
        }

        async function generateRoleWithAI() {
            const userIdea = elements.aiPromptInput.value.trim();
            if (!userIdea) return alert('è¯·è¾“å…¥ä¸€ä¸ªç®€å•çš„æƒ³æ³•');
            if (!state.apiKey) return alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key');

            const originalBtnText = elements.aiGenerateBtn.innerHTML;
            elements.aiGenerateBtn.disabled = true;
            elements.aiGenerateBtn.innerHTML = '<i class="fas fa-spinner animate-spin"></i> ç”Ÿæˆä¸­...';

            const systemPrompt = `You are an expert RPG world builder and character designer.
Your task is to take a simple concept and expand it into a rich, multi-dimensional role-playing scenario.
The scenario should include:
1. A compelling character name.
2. A concise but intriguing description.
3. A comprehensive System Prompt that includes:
   - Personality traits and psychological depth.
   - Detailed background and motivations.
   - Specific speech patterns, catchphrases, or linguistic quirks.
   - Guidelines on how to react to different user inputs.
   - The setting or environment they are currently in.

Return the result in JSON format with the following fields:
- name: The character's name
- desc: A short, catchy description (max 30 chars)
- prompt: The full, detailed system prompt in Chinese. IMPORTANT: The prompt must instruct the character to respond without any markdown formatting (no **bold**, *italic*, # headings, - lists, or code blocks).
- icon: A single emoji that represents the character.

Respond ONLY with the JSON object. Do not include markdown code blocks.`;

            try {
                console.log('Generating role with model:', state.roleGenModel);
                const response = await fetch('/api/proxy-llm', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        apiKey: state.apiKey,
                        model: state.roleGenModel,
                        messages: [
                            { role: 'system', content: systemPrompt },
                            { role: 'user', content: `Idea: ${userIdea}` }
                        ]
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    console.error('Proxy Error Response:', errorData);
                    throw new Error(errorData.error?.message || errorData.message || `HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                if (data.choices && data.choices[0]) {
                    let content = data.choices[0].message.content.trim();
                    // Remove markdown code blocks if present
                    if (content.startsWith('```')) {
                        content = content.replace(/^```json\n?/, '').replace(/```$/, '').trim();
                    }
                    
                    const result = JSON.parse(content);
                    elements.newRoleName.value = result.name || '';
                    elements.newRoleDesc.value = result.desc || '';
                    elements.newRolePrompt.value = result.prompt || '';
                    elements.saveRole.dataset.generatedIcon = result.icon || 'âœ¨';
                } else if (data.error) {
                    throw new Error(data.error.message || 'API Error');
                } else {
                    throw new Error('ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é€‰æ‹©æˆ– API Key');
                }
            } catch (error) {
                console.error('AI Generation Error:', error);
                alert('AI ç”Ÿæˆå¤±è´¥: ' + error.message);
            } finally {
                elements.aiGenerateBtn.disabled = false;
                elements.aiGenerateBtn.innerHTML = originalBtnText;
            }
        }

        function saveRole() {
            const name = elements.newRoleName.value.trim();
            const desc = elements.newRoleDesc.value.trim();
            const prompt = elements.newRolePrompt.value.trim();
            const icon = elements.saveRole.dataset.generatedIcon || 'âœ¨';
            if (!name || !prompt) return alert('è¯·å¡«å†™åç§°å’Œæç¤ºè¯');

            if (state.editingRoleId) {
                // ç¼–è¾‘æ¨¡å¼ï¼šæ›´æ–°ç°æœ‰è§’è‰²
                const roleIndex = state.roles.findIndex(r => r.id === state.editingRoleId);
                if (roleIndex !== -1) {
                    state.roles[roleIndex] = {
                        ...state.roles[roleIndex],
                        name, desc, prompt, icon
                    };

                    // å¦‚æœæ˜¯å½“å‰é€‰ä¸­çš„è§’è‰²ï¼Œæ›´æ–°æ˜¾ç¤º
                    if (state.currentRoleId === state.editingRoleId) {
                        elements.activeRoleName.textContent = name;
                        elements.activeRoleDesc.textContent = desc;
                        elements.roleAvatarBtn.textContent = icon;
                    }
                }
            } else {
                // åˆ›å»ºæ¨¡å¼ï¼šæ·»åŠ æ–°è§’è‰²
                const newRole = {
                    id: 'custom-' + Date.now(),
                    name, desc, prompt, icon
                };
                state.roles.push(newRole);
            }

            // ä¿å­˜è‡ªå®šä¹‰è§’è‰²åˆ° localStorage
            localStorage.setItem('custom_roles', JSON.stringify(state.roles.filter(r => String(r.id).startsWith('custom-'))));

            // å¯¹äºå†…ç½®è§’è‰²çš„ä¿®æ”¹ï¼Œæˆ‘ä»¬éœ€è¦å•ç‹¬å­˜å‚¨
            const builtinRoleEdits = {};
            state.roles.forEach(r => {
                if (!String(r.id).startsWith('custom-')) {
                    builtinRoleEdits[r.id] = { name: r.name, desc: r.desc, prompt: r.prompt, icon: r.icon };
                }
            });
            localStorage.setItem('builtin_role_edits', JSON.stringify(builtinRoleEdits));

            renderRoles();
            elements.roleModal.classList.add('hidden');

            // æ¸…ç†çŠ¶æ€
            state.editingRoleId = null;
            elements.newRoleName.value = '';
            elements.newRoleDesc.value = '';
            elements.newRolePrompt.value = '';
            elements.aiPromptInput.value = '';
            delete elements.saveRole.dataset.generatedIcon;
        }

        function selectRole(roleId) {
            // Stop any playing audio when switching roles
            stopCurrentAudio();

            // Stop continuous playback if active
            if (state.isPlayingAll) {
                state.isPlayingAll = false;
            }

            state.currentRoleId = roleId;
            const role = state.roles.find(r => r.id === roleId);
            elements.activeRoleName.textContent = role.name;
            elements.activeRoleDesc.textContent = role.desc;
            // æ›´æ–°å¤´åƒæŒ‰é’®
            elements.roleAvatarBtn.textContent = role.icon || 'ğŸ‘¤';
            elements.clearChatBtn.classList.remove('hidden');
            elements.playAllBtn.classList.remove('hidden');
            elements.downloadAllBtn.classList.remove('hidden');
            elements.compressHistoryBtn.classList.remove('hidden');
            elements.voiceChatBtn.classList.remove('hidden');

            renderRoles();
            renderMessages();
            checkInputs();
        }

        function checkInputs() {
            const isReady = state.apiKey && state.currentRoleId;
            elements.userInput.disabled = !isReady;
            elements.sendBtn.disabled = !isReady;
            elements.voiceBtn.disabled = !state.currentRoleId;
            elements.autoReplyBtn.disabled = !isReady;
            
            if (!state.apiKey) {
                elements.userInput.placeholder = "è¯·å…ˆè®¾ç½® API Key...";
            } else if (!state.currentRoleId) {
                elements.userInput.placeholder = "è¯·é€‰æ‹©ä¸€ä¸ªè§’è‰²...";
            } else {
                elements.userInput.placeholder = "è¾“å…¥æ¶ˆæ¯...";
            }
        }

        function renderMessages() {
            elements.chatMessages.innerHTML = '';
            const messages = state.chatHistory[state.currentRoleId] || [];
            if (messages.length === 0) {
                elements.chatMessages.innerHTML = `
                    <div class="text-center text-gray-400 mt-10">
                        <p>ä¸ <b>${state.roles.find(r => r.id === state.currentRoleId).name}</b> çš„å¯¹è¯å¼€å§‹äº†</p>
                    </div>
                `;
                return;
            }

            // æ‰¾åˆ°æœ€åä¸€æ¡ AI æ¶ˆæ¯çš„ç´¢å¼•ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¾ç¤ºé‡æ–°ç”ŸæˆæŒ‰é’®ï¼‰
            let lastAssistantIndex = -1;
            for (let i = messages.length - 1; i >= 0; i--) {
                if (messages[i].role === 'assistant' && messages[i].content !== '...') {
                    lastAssistantIndex = i;
                    break;
                }
            }

            messages.forEach((msg, index) => {
                // è·³è¿‡å·¥å…·è°ƒç”¨å’Œå·¥å…·ç»“æœæ¶ˆæ¯ï¼ˆè¿™äº›æ˜¯æŠ€æœ¯æ¶ˆæ¯ï¼Œä¸åº”è¯¥æ˜¾ç¤ºï¼‰
                if (msg.role === 'tool' || msg.tool_calls) {
                    return;
                }

                // å¤„ç†å‹ç¼©çš„æ‘˜è¦æ¶ˆæ¯ï¼ˆæ˜¾ç¤ºä¸ºç‰¹æ®Šæ ·å¼ï¼‰
                if (msg.isCompressed && msg.role === 'system') {
                    const div = document.createElement('div');
                    div.className = 'flex justify-center items-center my-4';
                    div.innerHTML = `
                        <div class="max-w-[90%] md:max-w-[85%] rounded-xl p-4 bg-purple-50 border border-purple-200 text-gray-700 shadow-sm">
                            <div class="flex items-center gap-2 mb-2 text-purple-600 font-medium">
                                <i class="fas fa-compress-alt"></i>
                                <span>å¯¹è¯æ‘˜è¦ï¼ˆå·²å‹ç¼©çš„å†å²è®°å½•ï¼‰</span>
                            </div>
                            <div class="text-sm leading-relaxed">${marked.parse(msg.content)}</div>
                        </div>
                    `;
                    elements.chatMessages.appendChild(div);
                    return;
                }

                const isUser = msg.role === 'user';
                const div = document.createElement('div');
                div.className = `flex ${isUser ? 'justify-end' : 'justify-start'} items-end gap-2`;

                const contentHtml = marked.parse(msg.content);

                // Check if audio is cached for this message
                const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
                const cacheKey = msg.content + '_' + voiceType;
                const isCached = !isUser && state.ttsCache[cacheKey];
                const buttonClass = isCached
                    ? 'text-green-500 hover:text-green-600'
                    : 'text-gray-400 hover:text-blue-500';
                const buttonTitle = isCached ? 'æ’­æ”¾è¯­éŸ³ (å·²ç¼“å­˜)' : 'æ’­æ”¾è¯­éŸ³';

                // æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
                const imageHtml = msg.imageUrl ? `
                    <div class="mt-3 rounded-lg overflow-hidden border border-gray-200">
                        <img src="${msg.imageUrl}"
                             alt="ç”Ÿæˆçš„å›¾ç‰‡"
                             class="w-full h-auto cursor-pointer hover:opacity-90 transition-opacity"
                             onclick="window.open('${msg.imageUrl}', '_blank')"
                             loading="lazy"
                             onload="document.getElementById('chatMessages').scrollTop = document.getElementById('chatMessages').scrollHeight"
                             onerror="this.onerror=null; this.parentElement.innerHTML='<div class=\\'p-4 text-center text-red-500\\'><i class=\\'fas fa-exclamation-triangle mr-2\\'></i>å›¾ç‰‡åŠ è½½å¤±è´¥<br><small>${msg.imageUrl}</small></div>';">
                    </div>
                ` : '';

                // å½“å†…å®¹ä¸º "..." æ—¶ä¸æ˜¾ç¤ºæŒ‰é’®ï¼ˆæ­£åœ¨ç­‰å¾… LLM å›å¤ï¼‰
                const isLoading = msg.content === '...';

                div.innerHTML = `
                    <div class="max-w-[85%] md:max-w-[80%] rounded-2xl p-3 ${isUser ? 'bg-blue-600 text-white' : 'bg-gray-100 text-gray-800 shadow-sm'} message-content relative group">
                        ${contentHtml}
                        ${imageHtml}
                        ${!isUser && !isLoading ? `
                            <div class="absolute -right-11 md:-right-10 bottom-0 flex flex-col gap-1">
                                ${index === lastAssistantIndex ? `
                                <button onclick="regenerateMessage(${index}, this)"
                                        data-regen-index="${index}"
                                        class="regen-btn p-2 min-w-[44px] min-h-[44px] flex items-center justify-center text-gray-400 hover:text-orange-500 active:scale-110 transition-all"
                                        title="é‡æ–°ç”Ÿæˆå›å¤">
                                    <i class="fas fa-redo text-lg md:text-base"></i>
                                </button>
                                ` : ''}
                                <button onclick="generateImageFromMessage(${index}, this)"
                                        data-img-index="${index}"
                                        class="img-gen-btn p-2 min-w-[44px] min-h-[44px] flex items-center justify-center text-gray-400 hover:text-purple-500 active:scale-110 transition-all"
                                        title="æ ¹æ®æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡">
                                    <i class="fas fa-image text-lg md:text-base"></i>
                                </button>
                                <button onclick="playTts('${msg.content.replace(/'/g, "\\'").replace(/\n/g, " ")}', this, ${index})"
                                        data-msg-index="${index}"
                                        class="tts-btn p-2 min-w-[44px] min-h-[44px] flex items-center justify-center ${buttonClass} active:scale-110 transition-all"
                                        title="${buttonTitle}">
                                    <i class="fas fa-volume-up text-lg md:text-base"></i>
                                </button>
                            </div>
                        ` : ''}
                    </div>
                `;
                elements.chatMessages.appendChild(div);
            });
            elements.chatMessages.scrollTop = elements.chatMessages.scrollHeight;
        }

        // æ¸…ç†æ–‡æœ¬ä»¥é€‚åˆ TTS æœ—è¯»
        function cleanTextForTts(text) {
            return text
                // ç§»é™¤ emoji è¡¨æƒ…ç¬¦å·
                .replace(/[\u{1F600}-\u{1F64F}]/gu, '') // è¡¨æƒ…ç¬¦å·
                .replace(/[\u{1F300}-\u{1F5FF}]/gu, '') // æ‚é¡¹ç¬¦å·å’Œè±¡å½¢æ–‡å­—
                .replace(/[\u{1F680}-\u{1F6FF}]/gu, '') // äº¤é€šå’Œåœ°å›¾ç¬¦å·
                .replace(/[\u{1F1E0}-\u{1F1FF}]/gu, '') // æ——å¸œ
                .replace(/[\u{2600}-\u{26FF}]/gu, '')   // æ‚é¡¹ç¬¦å·
                .replace(/[\u{2700}-\u{27BF}]/gu, '')   // è£…é¥°ç¬¦å·
                .replace(/[\u{1F900}-\u{1F9FF}]/gu, '') // è¡¥å……ç¬¦å·å’Œè±¡å½¢æ–‡å­—
                .replace(/[\u{1FA00}-\u{1FA6F}]/gu, '') // æ£‹ç±»ç¬¦å·
                .replace(/[\u{1FA70}-\u{1FAFF}]/gu, '') // ç¬¦å·å’Œè±¡å½¢æ–‡å­—æ‰©å±•A
                .replace(/[\u{231A}-\u{231B}]/gu, '')   // æ‰‹è¡¨ã€æ²™æ¼
                .replace(/[\u{23E9}-\u{23F3}]/gu, '')   // åª’ä½“æ§åˆ¶ç¬¦å·
                .replace(/[\u{23F8}-\u{23FA}]/gu, '')   // åª’ä½“æ§åˆ¶ç¬¦å·
                .replace(/[\u{25AA}-\u{25AB}]/gu, '')   // æ–¹å—
                .replace(/[\u{25B6}]/gu, '')            // æ’­æ”¾æŒ‰é’®
                .replace(/[\u{25C0}]/gu, '')            // å€’é€€æŒ‰é’®
                .replace(/[\u{25FB}-\u{25FE}]/gu, '')   // æ–¹å—
                .replace(/[\u{2934}-\u{2935}]/gu, '')   // ç®­å¤´
                .replace(/[\u{2B05}-\u{2B07}]/gu, '')   // ç®­å¤´
                .replace(/[\u{2B1B}-\u{2B1C}]/gu, '')   // æ–¹å—
                .replace(/[\u{2B50}]/gu, '')            // æ˜Ÿæ˜Ÿ
                .replace(/[\u{2B55}]/gu, '')            // åœ†åœˆ
                .replace(/[\u{3030}]/gu, '')            // æ³¢æµªçº¿
                .replace(/[\u{303D}]/gu, '')            // éƒ¨åˆ†äº¤æ›¿æ ‡è®°
                .replace(/[\u{3297}]/gu, '')            // æ—¥æ–‡"ç¥"
                .replace(/[\u{3299}]/gu, '')            // æ—¥æ–‡"ç§˜"
                // ç§»é™¤ markdown æ ¼å¼æ®‹ç•™
                .replace(/\*\*/g, '')                   // ç²—ä½“æ ‡è®°
                .replace(/\*/g, '')                     // æ–œä½“æ ‡è®°
                .replace(/#{1,6}\s*/g, '')              // æ ‡é¢˜æ ‡è®°
                .replace(/```[\s\S]*?```/g, '')         // ä»£ç å—
                .replace(/`([^`]+)`/g, '$1')            // è¡Œå†…ä»£ç 
                .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // é“¾æ¥ï¼Œä¿ç•™æ–‡å­—
                // æ¸…ç†å¤šä½™ç©ºç™½
                .replace(/\n{3,}/g, '\n\n')             // å¤šä¸ªæ¢è¡Œå˜æˆä¸¤ä¸ª
                .replace(/\s{2,}/g, ' ')                // å¤šä¸ªç©ºæ ¼å˜æˆä¸€ä¸ª
                .trim();
        }

        async function playTts(ignoredText, btn, index) {
            // æ ¹æ® TTS æ¨¡å¼æ£€æŸ¥æ‰€éœ€å‚æ•°
            if (state.volcTtsMode === 'stream') {
                if (!state.volcAppId || !state.volcTtsAccessKey || !state.volcTtsCluster) {
                    alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®ç«å±±å¼•æ“ TTS å‚æ•° (AppID, Access Key å’Œ Resource ID)');
                    return;
                }
            } else {
                if (!state.volcAppId || !state.volcTtsToken) {
                    alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®ç«å±±å¼•æ“ TTS å‚æ•° (AppID å’Œ Access Token)');
                    return;
                }
            }

            // Get authoritative text from state to ensure cache key consistency
            // The text passed in arguments might have newlines replaced with spaces due to onclick HTML attribute limitations
            const messages = state.chatHistory[state.currentRoleId];
            if (!messages || !messages[index]) {
                console.error('Message not found for TTS');
                return;
            }
            const text = messages[index].content;

            // Stop continuous playback if active
            if (state.isPlayingAll) {
                stopPlayAll();
            }

            // Check if this button is currently playing - if so, stop it (toggle behavior)
            if (state.currentPlayingIndex === index && state.currentAudio) {
                stopCurrentAudio();
                return;
            }

            // Helper to get the current button instance (in case DOM re-rendered)
            const getButton = () => {
                const currentBtn = document.querySelector(`button[data-msg-index="${index}"]`);
                return currentBtn || btn; 
            };

            const updateButtonState = (isLoading, isPlaying) => {
                const targetBtn = getButton();
                if (!targetBtn) return;

                const icon = targetBtn.querySelector('i');
                if (!icon) return;

                const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
                const cacheKey = text + '_' + voiceType;
                const isCached = state.ttsCache[cacheKey];

                if (isLoading) {
                    icon.className = 'fas fa-spinner animate-spin';
                    targetBtn.disabled = true;
                    targetBtn.classList.remove('text-gray-400', 'text-green-500', 'hover:text-blue-500', 'hover:text-green-600');
                    targetBtn.classList.add('text-blue-600');
                } else if (isPlaying) {
                    icon.className = 'fas fa-volume-up';
                    targetBtn.disabled = false;
                    targetBtn.classList.remove('text-gray-400', 'text-green-500', 'hover:text-blue-500', 'hover:text-green-600');
                    targetBtn.classList.add('text-blue-600', 'animate-pulse');
                } else {
                    icon.className = 'fas fa-volume-up';
                    targetBtn.disabled = false;
                    targetBtn.classList.remove('text-blue-600', 'animate-pulse');
                    if (isCached) {
                        targetBtn.classList.remove('text-gray-400', 'hover:text-blue-500');
                        targetBtn.classList.add('text-green-500', 'hover:text-green-600');
                        targetBtn.title = 'æ’­æ”¾è¯­éŸ³ (å·²ç¼“å­˜)';
                    } else {
                        targetBtn.classList.remove('text-green-500', 'hover:text-green-600');
                        targetBtn.classList.add('text-gray-400', 'hover:text-blue-500');
                        targetBtn.title = 'æ’­æ”¾è¯­éŸ³';
                    }
                }
            };

            // Stop previous audio
            stopCurrentAudio();
            
            // Reset all buttons state to ensure UI consistency
            document.querySelectorAll('button[data-msg-index]').forEach(b => {
                b.disabled = false;
                b.classList.remove('text-blue-600', 'animate-pulse');
                const i = b.querySelector('i');
                if(i) i.className = 'fas fa-volume-up';
                
                // Restore cache color
                const msgIdx = b.getAttribute('data-msg-index');
                const messages = state.chatHistory[state.currentRoleId] || [];
                const msg = messages[msgIdx];
                if(msg) {
                    const vt = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
                    const ck = msg.content + '_' + vt;
                    if(state.ttsCache[ck]) {
                         b.classList.remove('text-gray-400', 'hover:text-blue-500');
                         b.classList.add('text-green-500', 'hover:text-green-600');
                    } else {
                         b.classList.remove('text-green-500', 'hover:text-green-600');
                         b.classList.add('text-gray-400', 'hover:text-blue-500');
                    }
                }
            });

            const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
            const cacheKey = text + '_' + voiceType;

            const playAudioData = (base64Data, format = 'mp3', sampleRate = 24000) => {
                // Double check if user stopped it while we were fetching
                if (state.currentPlayingIndex !== null && state.currentPlayingIndex !== index) {
                    return;
                }

                stopCurrentAudio();

                if (format === 'pcm') {
                    // ä½¿ç”¨ Web Audio API æ’­æ”¾ PCM
                    playPcmAudio(base64Data, sampleRate, index, updateButtonState);
                } else {
                    // ä½¿ç”¨ HTML5 Audio æ’­æ”¾ MP3
                    const audio = new Audio(`data:audio/${format};base64,` + base64Data);
                    state.currentAudio = audio;
                    state.currentPlayingIndex = index;

                    updateButtonState(false, true);

                    audio.onended = () => {
                        updateButtonState(false, false);
                        state.currentAudio = null;
                        state.currentPlayingIndex = null;
                    };

                    audio.onerror = (e) => {
                        console.error('Audio Playback Error:', e);
                        alert('éŸ³é¢‘æ’­æ”¾å¤±è´¥');
                        updateButtonState(false, false);
                        state.currentAudio = null;
                        state.currentPlayingIndex = null;
                    };

                    audio.play().catch(e => {
                        console.error('Play Promise Error:', e);
                        updateButtonState(false, false);
                        state.currentAudio = null;
                        state.currentPlayingIndex = null;
                    });
                }
            };

            // æ’­æ”¾ PCM ç¼“å­˜éŸ³é¢‘
            const playPcmAudio = (base64Data, sampleRate, idx, updateBtnState) => {
                if (!state.audioContext) {
                    state.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                const audioContext = state.audioContext;

                // è§£ç  base64 PCM æ•°æ®
                const binaryString = atob(base64Data);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // å°† 16-bit PCM è½¬æ¢ä¸º Float32
                const int16Array = new Int16Array(bytes.buffer);
                const float32Array = new Float32Array(int16Array.length);
                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }

                // åˆ›å»º AudioBuffer
                const audioBuffer = audioContext.createBuffer(1, float32Array.length, sampleRate);
                audioBuffer.getChannelData(0).set(float32Array);

                // åˆ›å»º AudioBufferSourceNode
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                state.currentAudio = { stop: () => { try { source.stop(); } catch(e) {} } };
                state.currentPlayingIndex = idx;
                updateBtnState(false, true);

                source.onended = () => {
                    updateBtnState(false, false);
                    state.currentAudio = null;
                    state.currentPlayingIndex = null;
                };

                source.start(0);
            };

            // Check cache first
            if (state.ttsCache[cacheKey]) {
                console.log('Using cached audio');
                const cached = state.ttsCache[cacheKey];
                playAudioData(cached.data, cached.format || 'mp3', cached.sampleRate || 24000);
                return;
            }

            // Fetch from API
            updateButtonState(true, false);

            try {
                const cleanedText = cleanTextForTts(text).substring(0, 1000); // æ¸…ç†å¹¶é™åˆ¶é•¿åº¦

                if (state.volcTtsMode === 'stream') {
                    // å•å‘æµå¼æ¨¡å¼ (v3 API) - ä½¿ç”¨ SSE è¾¹æ”¶è¾¹æ’­
                    await playTtsStream(cleanedText, voiceType, cacheKey, index, updateButtonState, getButton);
                } else {
                    // æ™®é€šæ¨¡å¼ (v1 API)
                    const response = await fetch('/api/tts', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            text: cleanedText,
                            appid: state.volcAppId,
                            token: state.volcTtsToken,
                            cluster: state.volcTtsCluster,
                            voice_type: voiceType
                        })
                    });

                    const data = await response.json();
                    if (data.success && data.audio) {
                        state.ttsCache[cacheKey] = { data: data.audio, format: 'mp3' };

                        // Update button appearance to show it's cached (green color)
                        const targetBtn = getButton();
                        if (targetBtn) {
                            targetBtn.classList.remove('text-gray-400');
                            targetBtn.classList.add('text-green-500', 'hover:text-green-600');
                            targetBtn.title = 'æ’­æ”¾è¯­éŸ³ (å·²ç¼“å­˜)';
                        }

                        playAudioData(data.audio, 'mp3');
                    } else {
                        throw new Error(data.message || 'è½¬æ¢å¤±è´¥');
                    }
                }
            } catch (err) {
                console.error('TTS Error:', err);
                alert('è¯­éŸ³åˆæˆå¤±è´¥: ' + err.message);
                updateButtonState(false, false);
            }
        }

        // æµå¼ TTS æ’­æ”¾å‡½æ•° - ä½¿ç”¨ Web Audio API è¾¹æ”¶è¾¹æ’­ï¼ˆå¸¦ç¼“å†²ï¼‰
        async function playTtsStream(text, voiceType, cacheKey, index, updateButtonState, getButton) {
            // åˆå§‹åŒ– AudioContext
            if (!state.audioContext) {
                state.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            const audioContext = state.audioContext;

            // PCM å‚æ•°ï¼ˆä¸åç«¯ä¸€è‡´ï¼‰
            const sampleRate = 24000;
            const numChannels = 1;

            // ç¼“å†²é…ç½®ï¼š2ç§’ = 24000 * 2 = 48000 samples = 96000 bytes (16-bit)
            const BUFFER_DURATION_SEC = 2;
            const BUFFER_THRESHOLD_BYTES = sampleRate * 2 * BUFFER_DURATION_SEC; // 2 bytes per sample

            // ç”¨äºæ’é˜Ÿæ’­æ”¾çš„éŸ³é¢‘ç¼“å†²åŒº
            let audioQueue = [];
            let isPlaying = false;
            let nextPlayTime = 0;
            let allChunksReceived = false;
            let totalPcmData = []; // ç”¨äºä¿å­˜å®Œæ•´éŸ³é¢‘æ•°æ®
            let bufferedBytes = 0; // å½“å‰å·²ç¼“å†²çš„å­—èŠ‚æ•°
            let bufferingComplete = false; // ç¼“å†²æ˜¯å¦å®Œæˆ
            let currentSource = null;
            let isStopped = false;

            // æ’­æ”¾ä¸‹ä¸€ä¸ªéŸ³é¢‘å—
            const playNextChunk = () => {
                if (isStopped || audioQueue.length === 0) {
                    if (allChunksReceived && audioQueue.length === 0) {
                        // æ’­æ”¾å®Œæˆ
                        isPlaying = false;
                        updateButtonState(false, false);
                        state.currentAudio = null;
                        state.currentPlayingIndex = null;
                    }
                    return;
                }

                isPlaying = true;
                const pcmData = audioQueue.shift();

                // åˆ›å»º AudioBuffer
                const audioBuffer = audioContext.createBuffer(numChannels, pcmData.length, sampleRate);
                const channelData = audioBuffer.getChannelData(0);
                for (let i = 0; i < pcmData.length; i++) {
                    channelData[i] = pcmData[i];
                }

                // åˆ›å»º AudioBufferSourceNode
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                currentSource = source;

                // è®¡ç®—æ’­æ”¾æ—¶é—´
                const currentTime = audioContext.currentTime;
                if (nextPlayTime < currentTime) {
                    nextPlayTime = currentTime;
                }

                source.start(nextPlayTime);
                nextPlayTime += audioBuffer.duration;

                source.onended = () => {
                    if (!isStopped) {
                        playNextChunk();
                    }
                };
            };

            // å°è¯•å¼€å§‹æ’­æ”¾ï¼ˆéœ€è¦ç¼“å†²è¶³å¤Ÿæˆ–æ”¶åˆ°å…¨éƒ¨æ•°æ®ï¼‰
            const tryStartPlayback = () => {
                if (isPlaying || isStopped) return;

                // å¦‚æœç¼“å†²å®Œæˆï¼ˆè¾¾åˆ°é˜ˆå€¼æˆ–æ‰€æœ‰æ•°æ®å·²æ¥æ”¶ï¼‰ï¼Œå¼€å§‹æ’­æ”¾
                if (bufferingComplete || allChunksReceived) {
                    console.log(`Starting playback: buffered ${bufferedBytes} bytes, threshold ${BUFFER_THRESHOLD_BYTES}`);
                    playNextChunk();
                }
            };

            // åœæ­¢æ’­æ”¾
            const stopStreamPlayback = () => {
                isStopped = true;
                audioQueue = [];
                if (currentSource) {
                    try { currentSource.stop(); } catch (e) {}
                }
                if (state.streamEventSource) {
                    state.streamEventSource.close();
                    state.streamEventSource = null;
                }
            };

            // è®¾ç½®å½“å‰éŸ³é¢‘çŠ¶æ€ï¼ˆç”¨äºåœæ­¢åŠŸèƒ½ï¼‰
            state.currentAudio = { stop: stopStreamPlayback };
            state.currentPlayingIndex = index;
            updateButtonState(false, true);

            // æ„å»º SSE URL
            const params = new URLSearchParams({
                text: text,
                appid: state.volcAppId,
                access_key: state.volcTtsAccessKey,
                resource_id: state.volcTtsCluster,
                voice_type: voiceType
            });

            const eventSource = new EventSource(`/api/tts-stream?${params.toString()}`);
            state.streamEventSource = eventSource;

            console.log(`TTS Stream: buffering ${BUFFER_DURATION_SEC}s (${BUFFER_THRESHOLD_BYTES} bytes) before playback...`);

            eventSource.onmessage = (event) => {
                if (isStopped) return;

                try {
                    const data = JSON.parse(event.data);

                    if (data.type === 'audio') {
                        // è§£ç  base64 PCM æ•°æ®
                        const binaryString = atob(data.data);
                        const bytes = new Uint8Array(binaryString.length);
                        for (let i = 0; i < binaryString.length; i++) {
                            bytes[i] = binaryString.charCodeAt(i);
                        }

                        // å°† 16-bit PCM è½¬æ¢ä¸º Float32ï¼ˆWeb Audio API æ ¼å¼ï¼‰
                        const int16Array = new Int16Array(bytes.buffer);
                        const float32Array = new Float32Array(int16Array.length);
                        for (let i = 0; i < int16Array.length; i++) {
                            float32Array[i] = int16Array[i] / 32768.0;
                        }

                        // ä¿å­˜ç”¨äºç¼“å­˜ï¼ˆä½¿ç”¨åŸå§‹å­—èŠ‚ï¼‰
                        for (let i = 0; i < bytes.length; i++) {
                            totalPcmData.push(bytes[i]);
                        }

                        // æ›´æ–°ç¼“å†²è®¡æ•°
                        bufferedBytes += bytes.length;

                        // åŠ å…¥æ’­æ”¾é˜Ÿåˆ—
                        audioQueue.push(float32Array);

                        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç¼“å†²é˜ˆå€¼
                        if (!bufferingComplete && bufferedBytes >= BUFFER_THRESHOLD_BYTES) {
                            bufferingComplete = true;
                            console.log(`Buffer threshold reached (${bufferedBytes} bytes), starting playback...`);
                        }

                        // å°è¯•å¼€å§‹æ’­æ”¾
                        tryStartPlayback();

                    } else if (data.type === 'end') {
                        console.log('TTS stream ended, total chunks:', data.totalChunks, 'total bytes:', totalPcmData.length);
                        allChunksReceived = true;
                        eventSource.close();
                        state.streamEventSource = null;

                        // ç¼“å­˜å®Œæ•´éŸ³é¢‘ï¼ˆä¿å­˜ä¸º PCM base64ï¼‰
                        if (totalPcmData.length > 0) {
                            try {
                                const pcmBytes = new Uint8Array(totalPcmData);
                                // åˆ†å—è½¬æ¢ä¸º base64ï¼Œé¿å…å¤§æ•°ç»„å¯¼è‡´æ ˆæº¢å‡º
                                let base64Pcm = '';
                                const chunkSize = 32768;
                                for (let i = 0; i < pcmBytes.length; i += chunkSize) {
                                    const chunk = pcmBytes.subarray(i, Math.min(i + chunkSize, pcmBytes.length));
                                    base64Pcm += String.fromCharCode.apply(null, chunk);
                                }
                                base64Pcm = btoa(base64Pcm);

                                state.ttsCache[cacheKey] = { data: base64Pcm, format: 'pcm', sampleRate: sampleRate };
                                console.log('TTS audio cached successfully, size:', base64Pcm.length);

                                // Update button appearance
                                const targetBtn = getButton();
                                if (targetBtn) {
                                    targetBtn.classList.remove('text-gray-400');
                                    targetBtn.classList.add('text-green-500', 'hover:text-green-600');
                                    targetBtn.title = 'æ’­æ”¾è¯­éŸ³ (å·²ç¼“å­˜)';
                                }
                            } catch (e) {
                                console.error('Failed to cache TTS audio:', e);
                            }
                        }

                        // å°è¯•å¼€å§‹æ’­æ”¾ï¼ˆå¦‚æœè¿˜æ²¡å¼€å§‹ï¼‰
                        tryStartPlayback();

                        // å¦‚æœé˜Ÿåˆ—å·²ç©ºï¼Œæ ‡è®°å®Œæˆ
                        if (audioQueue.length === 0 && !isPlaying) {
                            updateButtonState(false, false);
                            state.currentAudio = null;
                            state.currentPlayingIndex = null;
                        }

                    } else if (data.type === 'error') {
                        console.error('TTS stream error:', data.message);
                        eventSource.close();
                        state.streamEventSource = null;
                        throw new Error(data.message);
                    }
                } catch (e) {
                    console.error('Error processing SSE data:', e);
                }
            };

            eventSource.onerror = (e) => {
                console.error('SSE connection error:', e);
                eventSource.close();
                state.streamEventSource = null;
                if (!isStopped && !allChunksReceived) {
                    updateButtonState(false, false);
                    state.currentAudio = null;
                    state.currentPlayingIndex = null;
                }
            };
        }

        // é‡æ–°ç”ŸæˆæŒ‡å®šç´¢å¼•çš„ AI å›å¤
        async function regenerateMessage(messageIndex, btn) {
            if (!state.currentRoleId) return;

            const messages = state.chatHistory[state.currentRoleId] || [];
            const msg = messages[messageIndex];
            if (!msg || msg.role !== 'assistant') {
                alert('åªèƒ½é‡æ–°ç”Ÿæˆ AI å›å¤');
                return;
            }

            // æ‰¾åˆ°å¯¹åº”çš„ç”¨æˆ·æ¶ˆæ¯ï¼ˆå‰ä¸€æ¡æ¶ˆæ¯ï¼‰
            let userMsgIndex = messageIndex - 1;
            while (userMsgIndex >= 0 && messages[userMsgIndex].role !== 'user') {
                userMsgIndex--;
            }
            if (userMsgIndex < 0) {
                alert('æ‰¾ä¸åˆ°å¯¹åº”çš„ç”¨æˆ·æ¶ˆæ¯');
                return;
            }

            // æ›´æ–°æŒ‰é’®çŠ¶æ€ä¸ºåŠ è½½ä¸­
            const icon = btn.querySelector('i');
            const originalClass = icon.className;
            icon.className = 'fas fa-spinner animate-spin';
            btn.disabled = true;

            try {
                const role = state.roles.find(r => r.id === state.currentRoleId);
                const formatInstruction = '\n\nã€æ ¼å¼è¦æ±‚ã€‘è¯·ä½¿ç”¨çº¯æ–‡æœ¬å›å¤ï¼Œç¦æ­¢ä½¿ç”¨ä»»ä½• markdown æ ¼å¼ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š**ç²—ä½“**ã€*æ–œä½“*ã€# æ ‡é¢˜ã€- åˆ—è¡¨ã€```ä»£ç å—``` ç­‰ã€‚å…è®¸ä½¿ç”¨ emoji è¡¨æƒ…ç¬¦å·ã€‚';

                // æ„å»ºåˆ°å½“å‰æ¶ˆæ¯ä¸ºæ­¢çš„å†å²ï¼ˆä¸åŒ…æ‹¬å½“å‰è¦é‡æ–°ç”Ÿæˆçš„æ¶ˆæ¯ï¼‰
                const historyMessages = messages.slice(0, messageIndex).filter(m => m.content !== '...');
                const compressedSummary = historyMessages.find(m => m.isCompressed && m.role === 'system');
                const regularMessages = historyMessages.filter(m => !m.isCompressed);

                let systemContent = role.prompt + formatInstruction;
                if (compressedSummary) {
                    systemContent += '\n\nã€ä¹‹å‰çš„å¯¹è¯æ‘˜è¦ã€‘\n' + compressedSummary.content;
                }

                let apiMessages = [
                    { role: 'system', content: systemContent },
                    ...regularMessages
                ];

                // æ˜¾ç¤ºåŠ è½½çŠ¶æ€
                msg.content = '...';
                renderMessages();

                // è°ƒç”¨ LLM
                const response = await fetch('/api/proxy-llm', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        apiKey: state.apiKey,
                        model: state.chatModel,
                        messages: apiMessages,
                        tools: [TEXT_TO_IMAGE_TOOL],
                        tool_choice: 'auto',
                        replicateToken: state.replicateToken,
                        replicateModel: state.replicateModel
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error?.message || errorData.message || `HTTP error! status: ${response.status}`);
                }

                let data = await response.json();

                // å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå›¾ç‰‡ç”Ÿæˆï¼‰
                if (data.tool_results && data.tool_results.length > 0) {
                    const toolResult = data.tool_results[0];
                    const resultData = JSON.parse(toolResult.content);

                    apiMessages.push(data.choices[0].message);
                    apiMessages.push(toolResult);

                    if (resultData.success && resultData.imageUrl) {
                        msg.imageUrl = resultData.imageUrl;
                        msg.imagePrompt = resultData.prompt;

                        // ç¬¬äºŒæ¬¡è°ƒç”¨ LLM
                        const response2 = await fetch('/api/proxy-llm', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                apiKey: state.apiKey,
                                model: state.chatModel,
                                messages: apiMessages
                            })
                        });

                        if (response2.ok) {
                            const data2 = await response2.json();
                            if (data2.choices && data2.choices[0]) {
                                let content = data2.choices[0].message.content;
                                content = content.replace(/!\[([^\]]*)\]\([^)]+\)/g, '');
                                content = content.replace(/https?:\/\/[^\s]+\.(png|jpg|jpeg|gif|webp)[^\s]*/gi, '');
                                content = content.replace(/\n{3,}/g, '\n\n').trim();
                                msg.content = content;
                            }
                        }
                    } else if (resultData.error) {
                        msg.content = `å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š${resultData.error}`;
                    }
                } else {
                    // æ­£å¸¸å›å¤
                    if (data.choices && data.choices[0]) {
                        msg.content = data.choices[0].message.content;
                    } else {
                        msg.content = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å“åº”ã€‚è¯·æ£€æŸ¥æ‚¨çš„è®¾ç½®ã€‚";
                    }
                }

                // æ¸…é™¤è¯¥æ¶ˆæ¯çš„ TTS ç¼“å­˜ï¼ˆå› ä¸ºå†…å®¹å·²å˜ï¼‰
                const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
                const oldCacheKeys = Object.keys(state.ttsCache).filter(k => k.endsWith('_' + voiceType));
                // ä¸éœ€è¦ç‰¹åˆ«æ¸…é™¤ï¼Œå› ä¸º cacheKey æ˜¯åŸºäºå†…å®¹çš„

                saveChatHistory();
            } catch (error) {
                msg.content = `é‡æ–°ç”Ÿæˆå¤±è´¥: ${error.message}`;
                console.error(error);
            }

            renderMessages();

            // æ¢å¤æŒ‰é’®çŠ¶æ€ï¼ˆrenderMessages ä¼šé‡æ–°åˆ›å»ºæŒ‰é’®ï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦æ¢å¤ï¼‰
        }

        // æ ¹æ®æ¶ˆæ¯å†…å®¹ç”Ÿæˆå›¾ç‰‡
        async function generateImageFromMessage(messageIndex, btn) {
            if (!state.currentRoleId) return;

            const messages = state.chatHistory[state.currentRoleId] || [];
            const msg = messages[messageIndex];
            if (!msg || msg.role !== 'assistant') {
                alert('åªèƒ½ä¸º AI å›å¤ç”Ÿæˆå›¾ç‰‡');
                return;
            }

            // æ£€æŸ¥ Replicate Token
            if (!state.replicateToken) {
                alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® Replicate API Token');
                return;
            }

            // æ›´æ–°æŒ‰é’®çŠ¶æ€ä¸ºåŠ è½½ä¸­
            const icon = btn.querySelector('i');
            const originalClass = icon.className;
            icon.className = 'fas fa-spinner fa-spin text-lg md:text-base';
            btn.disabled = true;
            btn.classList.add('text-purple-500');
            btn.classList.remove('text-gray-400');

            try {
                // æ„å»ºå›¾ç‰‡ç”Ÿæˆæç¤ºè¯ - æ ¹æ®å½“å‰æ¶ˆæ¯å†…å®¹ç”Ÿæˆæè¿°æ€§æç¤ºè¯
                const role = state.roles.find(r => r.id === state.currentRoleId);
                const contextPrompt = `You are an image prompt generator. Your task is to create an English image prompt based on the following roleplay context.

**IMPORTANT: You MUST output ONLY in English. Do NOT use any Chinese characters or other non-English text. This is critical for the image generation model to work correctly.**

Context:
- Character: ${role ? role.name : 'Unknown'}
- Scene/Message: ${msg.content}

Generate a concise, vivid visual description in English (max 200 words). Focus on:
- Visual elements and composition
- Scene setting and atmosphere
- Mood and lighting
- Art style (photorealistic, cinematic, etc.)

Output ONLY the English prompt, nothing else.`;

                // å…ˆç”¨ LLM ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
                console.log('Generating image prompt with model:', state.imagePromptModel);
                const llmResponse = await fetch('/api/proxy-llm', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        apiKey: state.apiKey,
                        model: state.imagePromptModel,
                        messages: [{ role: 'user', content: contextPrompt }]
                    })
                });

                if (!llmResponse.ok) {
                    throw new Error('ç”Ÿæˆå›¾ç‰‡æç¤ºè¯å¤±è´¥');
                }

                const llmData = await llmResponse.json();
                const imagePrompt = llmData.choices?.[0]?.message?.content || msg.content;

                console.log('Generated image prompt:', imagePrompt);

                // è°ƒç”¨æ–‡ç”Ÿå›¾ APIï¼ˆä¼ é€’ OpenRouter API Key ä»¥ä¾¿æœåŠ¡ç«¯ç¿»è¯‘ä¸­æ–‡æç¤ºè¯ï¼‰
                const imageResponse = await fetch('/api/text-to-image', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        apiToken: state.replicateToken,
                        prompt: imagePrompt,
                        model: state.replicateModel,
                        width: 768,
                        height: 768,
                        openrouterApiKey: state.apiKey  // ç”¨äºæœåŠ¡ç«¯ç¿»è¯‘ä¸­æ–‡æç¤ºè¯
                    })
                });

                const imageData = await imageResponse.json();

                if (imageData.success && imageData.imageUrl) {
                    // æ›´æ–°æ¶ˆæ¯ï¼Œæ·»åŠ å›¾ç‰‡
                    msg.imageUrl = imageData.imageUrl;
                    msg.imagePrompt = imagePrompt;
                    saveChatHistory();
                    renderMessages();
                } else {
                    throw new Error(imageData.message || 'å›¾ç‰‡ç”Ÿæˆå¤±è´¥');
                }
            } catch (err) {
                console.error('Image generation error:', err);
                alert('å›¾ç‰‡ç”Ÿæˆå¤±è´¥: ' + err.message);
                // æ¢å¤æŒ‰é’®çŠ¶æ€
                icon.className = originalClass;
                btn.disabled = false;
                btn.classList.remove('text-purple-500');
                btn.classList.add('text-gray-400');
            }
        }

        async function playAllCachedAudio() {
            if (!state.currentRoleId) return;

            const messages = state.chatHistory[state.currentRoleId] || [];
            const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';

            // Build queue of cached assistant messages
            state.playAllQueue = [];
            messages.forEach((msg, index) => {
                if (msg.role === 'assistant') {
                    const cacheKey = msg.content + '_' + voiceType;
                    if (state.ttsCache[cacheKey]) {
                        state.playAllQueue.push({
                            text: msg.content,
                            index: index,
                            audioData: state.ttsCache[cacheKey]
                        });
                    }
                }
            });

            if (state.playAllQueue.length === 0) {
                alert('å½“å‰åœºæ™¯æ²¡æœ‰å·²ç¼“å­˜çš„éŸ³é¢‘ã€‚è¯·å…ˆç‚¹å‡»æ¶ˆæ¯æ—çš„æ’­æ”¾æŒ‰é’®ç”ŸæˆéŸ³é¢‘ã€‚');
                return;
            }

            // Stop any currently playing audio
            stopCurrentAudio();

            // Update button state
            const icon = elements.playAllBtn.querySelector('i');
            icon.className = 'fas fa-stop-circle text-xl';
            elements.playAllBtn.title = 'åœæ­¢è¿ç»­æ’­æ”¾';
            elements.playAllBtn.classList.remove('text-gray-400', 'hover:text-green-500');
            elements.playAllBtn.classList.add('text-red-500', 'hover:text-red-600');

            state.isPlayingAll = true;
            playNextInQueue();
        }

        function playNextInQueue() {
            if (!state.isPlayingAll || state.playAllQueue.length === 0) {
                // Playback finished or stopped
                stopPlayAll();
                return;
            }

            const item = state.playAllQueue.shift();
            const cachedData = item.audioData;
            const format = cachedData.format || 'mp3';

            // Highlight the current message being played
            const btn = document.querySelector(`button[data-msg-index="${item.index}"]`);
            if (btn) {
                const icon = btn.querySelector('i');
                if (icon) {
                    icon.className = 'fas fa-volume-up';
                    btn.classList.remove('text-gray-400', 'text-green-500', 'hover:text-blue-500', 'hover:text-green-600');
                    btn.classList.add('text-blue-600', 'animate-pulse');
                }
            }

            const onPlayEnded = () => {
                // Reset button state
                if (btn) {
                    const icon = btn.querySelector('i');
                    if (icon) {
                        icon.className = 'fas fa-volume-up';
                        btn.classList.remove('text-blue-600', 'animate-pulse');
                        btn.classList.add('text-green-500', 'hover:text-green-600');
                    }
                }
                state.currentAudio = null;

                // Play next after a short pause
                setTimeout(() => {
                    playNextInQueue();
                }, 500);
            };

            if (format === 'pcm') {
                // ä½¿ç”¨ Web Audio API æ’­æ”¾ PCM
                if (!state.audioContext) {
                    state.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                const audioContext = state.audioContext;
                const sampleRate = cachedData.sampleRate || 24000;

                // è§£ç  base64 PCM æ•°æ®
                const binaryString = atob(cachedData.data);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // å°† 16-bit PCM è½¬æ¢ä¸º Float32
                const int16Array = new Int16Array(bytes.buffer);
                const float32Array = new Float32Array(int16Array.length);
                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }

                // åˆ›å»º AudioBuffer
                const audioBuffer = audioContext.createBuffer(1, float32Array.length, sampleRate);
                audioBuffer.getChannelData(0).set(float32Array);

                // åˆ›å»º AudioBufferSourceNode
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                state.currentAudio = { stop: () => { try { source.stop(); } catch(e) {} } };
                source.onended = onPlayEnded;
                source.start(0);
            } else {
                // ä½¿ç”¨ HTML5 Audio æ’­æ”¾ MP3
                const audio = new Audio("data:audio/mp3;base64," + cachedData.data);
                state.currentAudio = audio;

                audio.onended = onPlayEnded;

                audio.onerror = (e) => {
                    console.error('Audio Playback Error:', e);
                    state.currentAudio = null;
                    // Continue to next even if error
                    playNextInQueue();
                };

                audio.play().catch(e => {
                    console.error('Play Promise Error:', e);
                    playNextInQueue();
                });
            }
        }

        function stopPlayAll() {
            state.isPlayingAll = false;
            state.playAllQueue = [];

            stopCurrentAudio();

            // Reset all button states
            document.querySelectorAll('button[data-msg-index]').forEach(btn => {
                const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
                const messages = state.chatHistory[state.currentRoleId] || [];
                const index = parseInt(btn.getAttribute('data-msg-index'));
                const msg = messages[index];

                if (msg) {
                    const cacheKey = msg.content + '_' + voiceType;
                    const isCached = state.ttsCache[cacheKey];

                    const icon = btn.querySelector('i');
                    if (icon) {
                        icon.className = 'fas fa-volume-up';
                        btn.classList.remove('text-blue-600', 'animate-pulse');
                        if (isCached) {
                            btn.classList.remove('text-gray-400', 'hover:text-blue-500');
                            btn.classList.add('text-green-500', 'hover:text-green-600');
                        } else {
                            btn.classList.remove('text-green-500', 'hover:text-green-600');
                            btn.classList.add('text-gray-400', 'hover:text-blue-500');
                        }
                    }
                }
            });

            // Reset play all button
            const icon = elements.playAllBtn.querySelector('i');
            icon.className = 'fas fa-play-circle text-xl';
            elements.playAllBtn.title = 'è¿ç»­æ’­æ”¾æ‰€æœ‰å·²ç¼“å­˜éŸ³é¢‘';
            elements.playAllBtn.classList.remove('text-red-500', 'hover:text-red-600');
            elements.playAllBtn.classList.add('text-gray-400', 'hover:text-green-500');
        }

        // Update playAllBtn click handler to toggle between play and stop
        function setupPlayAllButton() {
            elements.playAllBtn.onclick = () => {
                if (state.isPlayingAll) {
                    stopPlayAll();
                } else {
                    playAllCachedAudio();
                }
            };

            // Download all cached audio button
            elements.downloadAllBtn.onclick = downloadAllCachedAudio;
        }

        // Download all cached audio merged into a single WAV file
        async function downloadAllCachedAudio() {
            if (!state.currentRoleId) return;

            const messages = state.chatHistory[state.currentRoleId] || [];
            const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';

            // Collect all cached audio data
            const audioDataList = [];
            messages.forEach((msg, index) => {
                if (msg.role === 'assistant') {
                    const cacheKey = msg.content + '_' + voiceType;
                    if (state.ttsCache[cacheKey]) {
                        audioDataList.push({
                            text: msg.content,
                            audioData: state.ttsCache[cacheKey]
                        });
                    }
                }
            });

            if (audioDataList.length === 0) {
                alert('å½“å‰åœºæ™¯æ²¡æœ‰å·²ç¼“å­˜çš„éŸ³é¢‘ã€‚è¯·å…ˆç‚¹å‡»æ¶ˆæ¯æ—çš„æ’­æ”¾æŒ‰é’®ç”ŸæˆéŸ³é¢‘ã€‚');
                return;
            }

            // Update button state to show processing
            const icon = elements.downloadAllBtn.querySelector('i');
            const originalClass = icon.className;
            icon.className = 'fas fa-spinner animate-spin text-lg';
            elements.downloadAllBtn.disabled = true;

            try {
                // Initialize audio context for decoding
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const decodedBuffers = [];
                const targetSampleRate = 24000; // Standard sample rate

                for (const item of audioDataList) {
                    const cachedData = item.audioData;
                    const format = cachedData.format || 'mp3';

                    if (format === 'pcm') {
                        // Decode PCM data
                        const binaryString = atob(cachedData.data);
                        const bytes = new Uint8Array(binaryString.length);
                        for (let i = 0; i < binaryString.length; i++) {
                            bytes[i] = binaryString.charCodeAt(i);
                        }
                        const int16Array = new Int16Array(bytes.buffer);
                        const float32Array = new Float32Array(int16Array.length);
                        for (let i = 0; i < int16Array.length; i++) {
                            float32Array[i] = int16Array[i] / 32768.0;
                        }
                        const sampleRate = cachedData.sampleRate || 24000;
                        const audioBuffer = audioContext.createBuffer(1, float32Array.length, sampleRate);
                        audioBuffer.getChannelData(0).set(float32Array);
                        decodedBuffers.push(audioBuffer);
                    } else {
                        // Decode MP3 data
                        const binaryString = atob(cachedData.data);
                        const bytes = new Uint8Array(binaryString.length);
                        for (let i = 0; i < binaryString.length; i++) {
                            bytes[i] = binaryString.charCodeAt(i);
                        }
                        try {
                            const audioBuffer = await audioContext.decodeAudioData(bytes.buffer.slice(0));
                            decodedBuffers.push(audioBuffer);
                        } catch (e) {
                            console.error('Failed to decode audio:', e);
                        }
                    }
                }

                if (decodedBuffers.length === 0) {
                    alert('æ— æ³•è§£ç ä»»ä½•éŸ³é¢‘æ•°æ®ã€‚');
                    return;
                }

                // Calculate total length and merge all buffers
                const silenceDuration = 0.5; // 500ms silence between clips
                const silenceSamples = Math.floor(targetSampleRate * silenceDuration);
                let totalLength = 0;
                decodedBuffers.forEach((buffer, idx) => {
                    totalLength += buffer.length;
                    if (idx < decodedBuffers.length - 1) {
                        totalLength += silenceSamples;
                    }
                });

                // Create merged buffer
                const mergedBuffer = audioContext.createBuffer(1, totalLength, targetSampleRate);
                const mergedData = mergedBuffer.getChannelData(0);
                let offset = 0;

                decodedBuffers.forEach((buffer, idx) => {
                    // Resample if needed
                    const sourceData = buffer.getChannelData(0);
                    if (buffer.sampleRate !== targetSampleRate) {
                        // Simple linear interpolation resampling
                        const ratio = buffer.sampleRate / targetSampleRate;
                        const newLength = Math.floor(sourceData.length / ratio);
                        for (let i = 0; i < newLength; i++) {
                            const srcIdx = i * ratio;
                            const srcIdxFloor = Math.floor(srcIdx);
                            const srcIdxCeil = Math.min(srcIdxFloor + 1, sourceData.length - 1);
                            const t = srcIdx - srcIdxFloor;
                            mergedData[offset + i] = sourceData[srcIdxFloor] * (1 - t) + sourceData[srcIdxCeil] * t;
                        }
                        offset += newLength;
                    } else {
                        mergedData.set(sourceData, offset);
                        offset += sourceData.length;
                    }

                    // Add silence between clips
                    if (idx < decodedBuffers.length - 1) {
                        offset += silenceSamples;
                    }
                });

                // Convert to WAV format
                const wavBlob = audioBufferToWav(mergedBuffer);

                // Create download link
                const role = state.roles.find(r => r.id === state.currentRoleId);
                const fileName = `${role ? role.name : 'audio'}_${new Date().toISOString().slice(0, 10)}.wav`;
                const url = URL.createObjectURL(wavBlob);
                const a = document.createElement('a');
                a.href = url;
                a.download = fileName;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);

                audioContext.close();
            } catch (error) {
                console.error('Download error:', error);
                alert('ä¸‹è½½éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: ' + error.message);
            } finally {
                // Restore button state
                icon.className = originalClass;
                elements.downloadAllBtn.disabled = false;
            }
        }

        // Helper function to convert AudioBuffer to WAV Blob
        function audioBufferToWav(audioBuffer) {
            const numChannels = audioBuffer.numberOfChannels;
            const sampleRate = audioBuffer.sampleRate;
            const format = 1; // PCM
            const bitDepth = 16;

            const bytesPerSample = bitDepth / 8;
            const blockAlign = numChannels * bytesPerSample;

            const data = audioBuffer.getChannelData(0);
            const samples = data.length;
            const buffer = new ArrayBuffer(44 + samples * bytesPerSample);
            const view = new DataView(buffer);

            // WAV header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples * bytesPerSample, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true); // fmt chunk size
            view.setUint16(20, format, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * blockAlign, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitDepth, true);
            writeString(view, 36, 'data');
            view.setUint32(40, samples * bytesPerSample, true);

            // Write samples
            let offset = 44;
            for (let i = 0; i < samples; i++) {
                const sample = Math.max(-1, Math.min(1, data[i]));
                view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                offset += 2;
            }

            return new Blob([buffer], { type: 'audio/wav' });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        async function autoReply() {
            if (!state.apiKey || !state.currentRoleId) return;

            const role = state.roles.find(r => r.id === state.currentRoleId);
            const originalPlaceholder = elements.userInput.placeholder;

            // ä¿å­˜æŒ‰é’®åŸå§‹çŠ¶æ€å¹¶è®¾ç½®åŠ è½½åŠ¨ç”»
            const btn = elements.autoReplyBtn;
            const icon = btn.querySelector('i');
            const originalIconClass = icon.className;
            icon.className = 'fas fa-spinner fa-spin text-lg';
            btn.classList.add('text-purple-500');
            btn.classList.remove('text-gray-500');

            elements.userInput.placeholder = "AI æ­£åœ¨æ€è€ƒæ‚¨çš„å›å¤...";
            elements.userInput.disabled = true;
            elements.autoReplyBtn.disabled = true;

            // Prepare messages for the "User Suggestion"
            const chatHistory = state.chatHistory[state.currentRoleId] || [];
            const compressedSummary = chatHistory.find(m => m.isCompressed && m.role === 'system');
            const recentHistory = chatHistory.filter(m => m.content && m.content !== '...' && !m.isCompressed).slice(-10);

            // å°†å¯¹è¯å†å²æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„æ–‡æœ¬
            let conversationText = '';
            if (compressedSummary) {
                conversationText = `ã€ä¹‹å‰å¯¹è¯æ‘˜è¦ã€‘\n${compressedSummary.content}\n\nã€æœ€è¿‘å¯¹è¯ã€‘\n`;
            }
            if (recentHistory.length === 0) {
                conversationText += `${role.name}ï¼š"ä½ å¥½ï¼Œæˆ‘æ˜¯${role.name}ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"`;
            } else {
                conversationText += recentHistory.map(m => {
                    const speaker = m.role === 'user' ? 'ç”¨æˆ·' : role.name;
                    return `${speaker}ï¼š"${m.content}"`;
                }).join('\n');
            }

            const messages = [
                {
                    role: 'system',
                    content: `ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å†™ä½œåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨è§’è‰²æ‰®æ¼”å¯¹è¯ä¸­æƒ³å‡ºä¸‹ä¸€å¥è¯ã€‚

å½“å‰åœºæ™¯ï¼šç”¨æˆ·æ­£åœ¨å’Œä¸€ä¸ªåä¸º"${role.name}"çš„è§’è‰²å¯¹è¯ã€‚
è§’è‰²è®¾å®šï¼š${role.prompt}

å¯¹è¯è®°å½•ï¼š
${conversationText}

è¯·å¸®ç”¨æˆ·æƒ³ä¸€å¥è‡ªç„¶ã€æœ‰è¶£çš„å›å¤ã€‚
è¦æ±‚ï¼š
- ç«™åœ¨ç”¨æˆ·çš„è§’åº¦è¯´è¯
- ç”¨ä¸­æ–‡
- ç›´æ¥è¾“å‡ºå¯¹è¯å†…å®¹ï¼Œä¸è¦åŠ å¼•å·æˆ–å‰ç¼€`
                },
                {
                    role: 'user',
                    content: 'è¯·å¸®æˆ‘æƒ³ä¸€å¥å›å¤'
                }
            ];

            try {
                console.log('Auto reply with model:', state.chatModel);
                console.log('Auto reply messages:', JSON.stringify(messages, null, 2));

                const response = await fetch('/api/proxy-llm', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        apiKey: state.apiKey,
                        model: state.chatModel,
                        messages: messages
                    })
                });

                console.log('Auto reply response status:', response.status);

                if (!response.ok) {
                    const errorData = await response.json();
                    console.error('Auto reply error response:', errorData);
                    throw new Error(errorData.error?.message || errorData.message || `HTTP error! status: ${response.status}`);
                }

                const data = await response.json();
                console.log('Auto reply response data:', JSON.stringify(data, null, 2));

                if (data.choices && data.choices[0] && data.choices[0].message && data.choices[0].message.content) {
                    const content = data.choices[0].message.content.trim().replace(/^["']|["']$/g, '');
                    if (content) {
                        elements.userInput.value = content;
                        elements.userInput.dispatchEvent(new Event('input'));
                        console.log('Auto reply filled input with:', content);
                    } else {
                        console.warn('Auto reply returned empty content');
                        alert('AI è¿”å›äº†ç©ºå†…å®¹ï¼Œè¯·é‡è¯•');
                    }
                } else {
                    console.warn('Auto reply response missing expected data structure:', data);
                    alert('AI å“åº”æ ¼å¼å¼‚å¸¸ï¼Œè¯·é‡è¯•');
                }
            } catch (error) {
                console.error('Auto Reply Error:', error);
                alert('æ— æ³•ç”Ÿæˆå»ºè®®å›å¤: ' + error.message);
            } finally {
                // æ¢å¤æŒ‰é’®åŸå§‹çŠ¶æ€
                icon.className = originalIconClass;
                btn.classList.remove('text-purple-500');
                btn.classList.add('text-gray-500');

                elements.userInput.placeholder = originalPlaceholder;
                elements.userInput.disabled = false;
                elements.autoReplyBtn.disabled = false;
                checkInputs();
            }
        }

        // å®šä¹‰æ–‡ç”Ÿå›¾å·¥å…·
        const TEXT_TO_IMAGE_TOOL = {
            type: 'function',
            function: {
                name: 'generate_image',
                description: 'æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾ç‰‡ã€‚å½“ç”¨æˆ·è¦æ±‚ç”Ÿæˆã€åˆ›å»ºã€ç”»å›¾ç‰‡æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚**é‡è¦ï¼šprompt å¿…é¡»ä½¿ç”¨è‹±æ–‡æè¿°ï¼Œå¦‚æœç”¨æˆ·æä¾›ä¸­æ–‡æè¿°ï¼Œä½ éœ€è¦å…ˆå°†å…¶ç¿»è¯‘æˆè¯¦ç»†çš„è‹±æ–‡æç¤ºè¯ã€‚**',
                parameters: {
                    type: 'object',
                    properties: {
                        prompt: {
                            type: 'string',
                            description: 'å›¾ç‰‡æè¿°æ–‡æœ¬ï¼ˆå¿…é¡»ä½¿ç”¨è‹±æ–‡ï¼‰ã€‚è¯¦ç»†æè¿°æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€é£æ ¼ç­‰ã€‚ä¾‹å¦‚ï¼š"A cute cat sitting on clouds"ã€‚å¦‚æœç”¨æˆ·æä¾›ä¸­æ–‡æè¿°ï¼Œè¯·å…ˆç¿»è¯‘æˆè‹±æ–‡ã€‚'
                        },
                        // negative_prompt: {
                        //     type: 'string',
                        //     description: 'è´Ÿé¢æç¤ºè¯ï¼ˆè‹±æ–‡ï¼‰ï¼Œæè¿°ä¸æƒ³åœ¨å›¾ç‰‡ä¸­å‡ºç°çš„å†…å®¹',
                        //     default: '(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck'
                        // },
                        width: {
                            type: 'number',
                            description: 'å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤ 512',
                            default: 512,
                            enum: [512, 768, 1024]
                        },
                        height: {
                            type: 'number',
                            description: 'å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤ 728',
                            default: 728,
                            enum: [512, 728, 768, 1024]
                        }
                    },
                    required: ['prompt']
                }
            }
        };

        async function sendMessage() {
            const content = elements.userInput.value.trim();
            if (!content || !state.apiKey || !state.currentRoleId) return;

            // Pre-warm AudioContext on user interaction to ensure auto-play works later
            if (state.autoTtsEnabled) {
                const ctx = getAudioContext();
                if (ctx.state === 'suspended') {
                    ctx.resume();
                }
            }

            const role = state.roles.find(r => r.id === state.currentRoleId);
            if (!state.chatHistory[state.currentRoleId]) {
                state.chatHistory[state.currentRoleId] = [];
            }

            // Add user message
            state.chatHistory[state.currentRoleId].push({ role: 'user', content });
            elements.userInput.value = '';
            elements.userInput.style.height = 'auto';
            renderMessages();

            // Prepare API call with Context Isolation
            const formatInstruction = '\n\nã€æ ¼å¼è¦æ±‚ã€‘è¯·ä½¿ç”¨çº¯æ–‡æœ¬å›å¤ï¼Œç¦æ­¢ä½¿ç”¨ä»»ä½• markdown æ ¼å¼ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š**ç²—ä½“**ã€*æ–œä½“*ã€# æ ‡é¢˜ã€- åˆ—è¡¨ã€```ä»£ç å—``` ç­‰ã€‚å…è®¸ä½¿ç”¨ emoji è¡¨æƒ…ç¬¦å·ã€‚';

            // å¤„ç†å‹ç¼©çš„æ‘˜è¦æ¶ˆæ¯ï¼šå°†å…¶ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯çš„ä¸€éƒ¨åˆ†
            const historyMessages = state.chatHistory[state.currentRoleId].filter(m => m.content !== '...');
            const compressedSummary = historyMessages.find(m => m.isCompressed && m.role === 'system');
            const regularMessages = historyMessages.filter(m => !m.isCompressed);

            let systemContent = role.prompt + formatInstruction;
            if (compressedSummary) {
                systemContent += '\n\nã€ä¹‹å‰çš„å¯¹è¯æ‘˜è¦ã€‘\n' + compressedSummary.content;
            }

            let messages = [
                { role: 'system', content: systemContent },
                ...regularMessages
            ];

            // Add placeholder for AI response
            const aiMsg = { role: 'assistant', content: '...' };
            state.chatHistory[state.currentRoleId].push(aiMsg);
            renderMessages();

            try {
                // ç¬¬ä¸€æ¬¡è°ƒç”¨ LLMï¼Œæä¾›å·¥å…·
                console.log('Chat with model:', state.chatModel);
                let response = await fetch('/api/proxy-llm', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        apiKey: state.apiKey,
                        model: state.chatModel,
                        messages: messages,
                        tools: [TEXT_TO_IMAGE_TOOL],
                        tool_choice: 'auto',
                        replicateToken: state.replicateToken,
                        replicateModel: state.replicateModel
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error?.message || errorData.message || `HTTP error! status: ${response.status}`);
                }

                let data = await response.json();

                // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if (data.tool_results && data.tool_results.length > 0) {
                    // æœ‰å·¥å…·è°ƒç”¨ï¼Œå¤„ç†ç»“æœ
                    const toolCall = data.choices[0].message.tool_calls[0];
                    const toolResult = data.tool_results[0];
                    const resultData = JSON.parse(toolResult.content);

                    // è°ƒè¯•æ—¥å¿—
                    console.log('Tool result:', toolResult);
                    console.log('Parsed result:', resultData);
                    console.log('Image URL:', resultData.imageUrl);

                    // å°†å·¥å…·è°ƒç”¨æ·»åŠ åˆ° API æ¶ˆæ¯å†å²ï¼ˆç”¨äºåç»­è°ƒç”¨ï¼‰ï¼Œä½†ä¸æ·»åŠ åˆ° chatHistoryï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                    messages.push(data.choices[0].message);
                    messages.push(toolResult);

                    // å¦‚æœå›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œåœ¨ AI æ¶ˆæ¯ä¸­æ˜¾ç¤ºå›¾ç‰‡
                    if (resultData.success && resultData.imageUrl) {
                        aiMsg.content = `æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...`;
                        aiMsg.imageUrl = resultData.imageUrl;
                        aiMsg.imagePrompt = resultData.prompt;
                        renderMessages();

                        // ç¬¬äºŒæ¬¡è°ƒç”¨ LLMï¼Œè®©å®ƒæ ¹æ®å·¥å…·ç»“æœç”Ÿæˆå›å¤
                        response = await fetch('/api/proxy-llm', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify({
                                apiKey: state.apiKey,
                                model: state.chatModel,
                                messages: messages
                            })
                        });

                        if (!response.ok) {
                            throw new Error('Second LLM call failed');
                        }

                        data = await response.json();
                        if (data.choices && data.choices[0]) {
                            // ç§»é™¤ LLM è¿”å›å†…å®¹ä¸­çš„ markdown å›¾ç‰‡ï¼ˆé¿å…é‡å¤æ˜¾ç¤ºï¼‰
                            let content = data.choices[0].message.content;
                            // ç§»é™¤ markdown å›¾ç‰‡è¯­æ³•: ![alt](url)
                            content = content.replace(/!\[([^\]]*)\]\([^)]+\)/g, '');
                            // ç§»é™¤å¯èƒ½çš„çº¯ URL å›¾ç‰‡é“¾æ¥
                            content = content.replace(/https?:\/\/[^\s]+\.(png|jpg|jpeg|gif|webp)[^\s]*/gi, '');
                            // æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
                            content = content.replace(/\n{3,}/g, '\n\n').trim();
                            aiMsg.content = content;
                        }
                    } else if (resultData.error) {
                        aiMsg.content = `å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š${resultData.error}`;
                    }
                } else {
                    // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ­£å¸¸å›å¤
                    if (data.choices && data.choices[0]) {
                        aiMsg.content = data.choices[0].message.content;
                    } else {
                        aiMsg.content = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å“åº”ã€‚è¯·æ£€æŸ¥æ‚¨çš„è®¾ç½®ã€‚";
                    }
                }
                saveChatHistory();
            } catch (error) {
                aiMsg.content = `ç½‘ç»œè¯·æ±‚å¤±è´¥: ${error.message}`;
                console.error(error);
            }
            renderMessages();

            // Auto Play TTS if enabled and length matches
            if (state.autoTtsEnabled && aiMsg.role === 'assistant' && aiMsg.content && aiMsg.content !== '...' && !aiMsg.content.startsWith('ç½‘ç»œè¯·æ±‚å¤±è´¥') && !aiMsg.content.startsWith('å›¾ç‰‡ç”Ÿæˆå¤±è´¥')) {
                const len = aiMsg.content.length;
                if (len <= state.autoTtsThreshold) {
                    const lastIndex = state.chatHistory[state.currentRoleId].length - 1;
                    const btn = document.querySelector(`button[data-msg-index="${lastIndex}"]`);
                    if (btn) {
                        console.log(`Auto-playing TTS (Length: ${len}, Threshold: ${state.autoTtsThreshold})`);
                        playTts(aiMsg.content, btn, lastIndex);
                    }
                }
            }
        }

        // ========== Voice Chat Functions ==========

        function setupVoiceChat() {
            // Open voice chat modal
            elements.voiceChatBtn.onclick = openVoiceChat;
            elements.closeVoiceChatBtn.onclick = closeVoiceChat;
        }

        function openVoiceChat() {
            if (!state.currentRoleId) {
                alert('è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§’è‰²');
                return;
            }

            // Check required settings
            if (!state.apiKey) {
                alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key');
                return;
            }
            if (!state.volcAppId || !state.volcToken) {
                alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®ç«å±±å¼•æ“ ASR å‚æ•°');
                return;
            }
            if (state.volcTtsMode === 'stream') {
                if (!state.volcTtsAccessKey || !state.volcTtsCluster) {
                    alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®ç«å±±å¼•æ“ TTS å‚æ•° (Access Key å’Œ Resource ID)');
                    return;
                }
            } else {
                if (!state.volcTtsToken) {
                    alert('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®ç«å±±å¼•æ“ TTS å‚æ•° (Access Token)');
                    return;
                }
            }

            elements.voiceChatModal.classList.remove('hidden');
            state.voiceChatActive = true;

            // è‡ªåŠ¨å¼€å§‹ç›‘å¬ï¼Œæ— éœ€ç”¨æˆ·å†æ¬¡ç‚¹å‡»
            startVoiceChatListening();
        }

        function closeVoiceChat() {
            stopVoiceChatListening();
            elements.voiceChatModal.classList.add('hidden');
            state.voiceChatActive = false;
            state.voiceChatProcessing = false;
        }

        function updateVoiceChatUI(status, message = '') {
            const statusEl = elements.voiceChatStatus;
            const iconEl = elements.voiceChatIcon;
            const pulseEl = elements.voicePulse;
            const bars = elements.audioLevelBars.querySelectorAll('.audio-bar');

            switch (status) {
                case 'ready':
                    statusEl.textContent = 'å‡†å¤‡å°±ç»ª';
                    iconEl.className = 'fas fa-microphone text-4xl text-white relative z-10';
                    pulseEl.classList.remove('animate-ping');
                    pulseEl.classList.add('hidden');
                    bars.forEach(bar => bar.style.height = '8px');
                    break;
                case 'calibrating':
                    statusEl.textContent = 'ç¯å¢ƒå™ªå£°æ ¡å‡†ä¸­...';
                    iconEl.className = 'fas fa-wave-square text-4xl text-white relative z-10';
                    pulseEl.classList.remove('hidden');
                    pulseEl.classList.remove('animate-ping');
                    pulseEl.classList.add('animate-pulse');
                    break;
                case 'listening':
                    statusEl.textContent = 'æ­£åœ¨è†å¬...';
                    iconEl.className = 'fas fa-microphone text-4xl text-white relative z-10';
                    pulseEl.classList.remove('hidden');
                    pulseEl.classList.remove('animate-pulse');
                    pulseEl.classList.add('animate-ping');
                    break;
                case 'detecting':
                    statusEl.textContent = 'æ£€æµ‹åˆ°è¯­éŸ³...';
                    break;
                case 'processing_asr':
                    statusEl.textContent = 'è¯†åˆ«è¯­éŸ³ä¸­...';
                    iconEl.className = 'fas fa-spinner fa-spin text-4xl text-white relative z-10';
                    pulseEl.classList.add('hidden');
                    break;
                case 'processing_llm':
                    statusEl.textContent = 'AI æ€è€ƒä¸­...';
                    iconEl.className = 'fas fa-brain text-4xl text-white relative z-10';
                    break;
                case 'playing_tts':
                    statusEl.textContent = 'AI å›å¤ä¸­...';
                    iconEl.className = 'fas fa-volume-up text-4xl text-white relative z-10';
                    break;
                case 'error':
                    statusEl.textContent = message || 'å‘ç”Ÿé”™è¯¯';
                    iconEl.className = 'fas fa-exclamation-triangle text-4xl text-yellow-400 relative z-10';
                    pulseEl.classList.add('hidden');
                    setTimeout(() => updateVoiceChatUI('ready'), 2000);
                    break;
            }
        }

        function updateAudioLevelBars(level) {
            const bars = elements.audioLevelBars.querySelectorAll('.audio-bar');
            const normalizedLevel = Math.min(1, Math.max(0, level));

            bars.forEach((bar, index) => {
                const centerIndex = Math.floor(bars.length / 2);
                const distanceFromCenter = Math.abs(index - centerIndex);
                const factor = 1 - (distanceFromCenter / centerIndex) * 0.5;
                const height = 8 + normalizedLevel * 24 * factor;
                bar.style.height = `${height}px`;
            });
        }

        async function toggleVoiceChatListening() {
            if (state.voiceChatProcessing) return;

            if (state.voiceChatListening) {
                stopVoiceChatListening();
                updateVoiceChatUI('ready');
            } else {
                await startVoiceChatListening();
            }
        }

        async function startVoiceChatListening() {
            try {
                // Get audio stream with noise suppression
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 16000
                    }
                });

                state.voiceChatMediaStream = stream;
                state.voiceChatListening = true;
                updateVoiceChatUI('listening');

                // Setup AudioContext and Analyser for VAD
                const audioContext = getAudioContext();
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                const source = audioContext.createMediaStreamSource(stream);
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 512;
                analyser.smoothingTimeConstant = 0.8;
                source.connect(analyser);
                state.voiceChatAnalyser = analyser;

                // Setup MediaRecorder
                const mimeType = getSupportedMimeTypeForVoiceChat();
                const options = mimeType ? { mimeType } : {};
                const recorder = new MediaRecorder(stream, options);
                state.voiceChatRecorder = recorder;
                state.voiceChatAudioChunks = [];
                state.voiceChatSpeechDetected = false; // æ ‡è®°æ˜¯å¦æ£€æµ‹åˆ°è¿‡è¯­éŸ³
                state.voiceChatSpeechStartChunkIndex = -1; // è¯­éŸ³å¼€å§‹æ—¶çš„ chunk ç´¢å¼•

                recorder.ondataavailable = (event) => {
                    // æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®ï¼ˆä¿ç•™å®Œæ•´çš„ webm æ–‡ä»¶å¤´ï¼‰
                    if (event.data.size > 0) {
                        state.voiceChatAudioChunks.push(event.data);
                    }
                    // è®°å½•è¯­éŸ³å¼€å§‹æ—¶çš„ chunk ç´¢å¼•
                    if (state.voiceChatVadActive && !state.voiceChatSpeechDetected) {
                        state.voiceChatSpeechDetected = true;
                        // ä¿ç•™è¯­éŸ³å¼€å§‹å‰çš„ 1-2 ä¸ª chunkï¼ˆçº¦ 100-200msï¼‰ï¼Œç¡®ä¿ä¸ä¸¢å¤±è¯­éŸ³å¼€å¤´
                        state.voiceChatSpeechStartChunkIndex = Math.max(0, state.voiceChatAudioChunks.length - 2);
                        console.log(`[VoiceChat] è¯­éŸ³å¼€å§‹ï¼Œèµ·å§‹ chunk ç´¢å¼•: ${state.voiceChatSpeechStartChunkIndex}`);
                    }
                };

                recorder.onstop = async () => {
                    // åªæœ‰åœ¨æ£€æµ‹åˆ°è¯­éŸ³æ—¶æ‰å‘é€ç»™æœåŠ¡å™¨
                    if (state.voiceChatAudioChunks.length > 0 && state.voiceChatActive && state.voiceChatSpeechDetected) {
                        // è£å‰ªé™éŸ³éƒ¨åˆ†ï¼šåªä¿ç•™ä»è¯­éŸ³å¼€å§‹çš„ chunks
                        // æ³¨æ„ï¼šç¬¬ä¸€ä¸ª chunk åŒ…å« webm æ–‡ä»¶å¤´ï¼Œå¿…é¡»ä¿ç•™
                        let chunksToUse;
                        if (state.voiceChatSpeechStartChunkIndex > 0) {
                            // ä¿ç•™ç¬¬ä¸€ä¸ª chunkï¼ˆæ–‡ä»¶å¤´ï¼‰+ è¯­éŸ³å¼€å§‹åçš„ chunks
                            const headerChunk = state.voiceChatAudioChunks[0];
                            const speechChunks = state.voiceChatAudioChunks.slice(state.voiceChatSpeechStartChunkIndex);
                            chunksToUse = [headerChunk, ...speechChunks];
                            console.log(`[VoiceChat] è£å‰ªé™éŸ³: åŸå§‹ ${state.voiceChatAudioChunks.length} chunks -> ä½¿ç”¨ ${chunksToUse.length} chunks (å¤´éƒ¨ + ä»ç´¢å¼• ${state.voiceChatSpeechStartChunkIndex} å¼€å§‹)`);
                        } else {
                            chunksToUse = state.voiceChatAudioChunks;
                        }

                        const audioBlob = new Blob(chunksToUse, { type: recorder.mimeType || mimeType || 'audio/webm' });
                        if (audioBlob.size > 1000) {
                            console.log(`[VoiceChat] æœ€ç»ˆéŸ³é¢‘å¤§å°: ${(audioBlob.size / 1024).toFixed(2)} KB`);
                            await processVoiceChatAudio(audioBlob);
                        }
                    } else if (!state.voiceChatSpeechDetected) {
                        // æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œé‡æ–°å¼€å§‹ç›‘å¬
                        console.log('[VoiceChat] æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œé‡æ–°å¼€å§‹ç›‘å¬');
                        state.voiceChatProcessing = false;
                        if (state.voiceChatActive) {
                            setTimeout(() => startVoiceChatListening(), 100);
                        }
                    }
                };

                // Start recording
                recorder.start(100);

                // Start VAD monitoring
                startVADMonitoring();

            } catch (err) {
                console.error('Voice chat error:', err);
                updateVoiceChatUI('error', 'æ— æ³•è®¿é—®éº¦å…‹é£');
            }
        }

        function getSupportedMimeTypeForVoiceChat() {
            const types = ['audio/webm;codecs=opus', 'audio/webm', 'audio/mp4', 'audio/ogg;codecs=opus'];
            for (const type of types) {
                if (MediaRecorder.isTypeSupported(type)) return type;
            }
            return '';
        }

        function stopVoiceChatListening() {
            // Clear silence timer
            if (state.voiceChatSilenceTimer) {
                clearTimeout(state.voiceChatSilenceTimer);
                state.voiceChatSilenceTimer = null;
            }

            // Stop recorder (onstop å›è°ƒä¼šå¤„ç†åç»­é€»è¾‘)
            // æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œé‡ç½® voiceChatSpeechDetectedï¼Œå› ä¸º onstop å›è°ƒéœ€è¦ç”¨å®ƒ
            if (state.voiceChatRecorder && state.voiceChatRecorder.state === 'recording') {
                state.voiceChatRecorder.stop();
            }

            // Stop media stream
            if (state.voiceChatMediaStream) {
                state.voiceChatMediaStream.getTracks().forEach(track => track.stop());
                state.voiceChatMediaStream = null;
            }

            state.voiceChatListening = false;
            state.voiceChatVadActive = false;
            state.voiceChatAnalyser = null;
            state.voiceChatRecorder = null;
            // voiceChatSpeechDetected åœ¨ startVoiceChatListening ä¸­é‡ç½®
        }

        // VAD (Voice Activity Detection) Configuration
        let vadAnimationFrame = null;
        let silenceStartTime = null;
        let speechStartTime = null;

        // VAD Parameters - optimized for noisy environments
        const VAD_CONFIG = {
            CALIBRATION_DURATION: 2000,    // 2 seconds to calibrate noise floor
            NOISE_MULTIPLIER: 3.5,         // Speech must be 3.5x louder than noise (increased)
            MIN_SPEECH_THRESHOLD: 0.08,    // Higher minimum threshold to reduce false positives
            MAX_SPEECH_THRESHOLD: 0.25,    // Higher maximum threshold for noisy environments
            SILENCE_DURATION: 1200,        // 1.2 seconds of silence to end recording
            SPEECH_MIN_DURATION: 400,      // Minimum 400ms of speech to process
            CONSECUTIVE_FRAMES_REQUIRED: 8, // Need 8 consecutive frames above threshold (increased)
            SPEECH_FREQUENCY_MIN: 200,     // Focus on speech fundamental frequencies (200Hz+)
            SPEECH_FREQUENCY_MAX: 2500,    // Narrower band for cleaner speech detection
            // New parameters for improved VAD
            NOISE_ADAPTATION_RATE: 0.02,   // How fast to adapt to changing noise
            ENERGY_SMOOTHING: 0.3,         // Smooth energy readings to reduce jitter
            ZCR_SPEECH_MIN: 0.02,          // Min zero-crossing rate for speech
            ZCR_SPEECH_MAX: 0.25,          // Max zero-crossing rate for speech
            SPECTRAL_FLATNESS_MAX: 0.5,    // Max spectral flatness (speech is less flat than noise)
            HANGOVER_FRAMES: 15,           // Keep speech active for extra frames after drop
            // 1ç§’ç¡®è®¤çª—å£å‚æ•°
            CONFIRMATION_WINDOW: 1000,     // 1ç§’ç¡®è®¤çª—å£
            SPEECH_RATIO_THRESHOLD: 0.4,   // 1ç§’å†…è‡³å°‘ 40% çš„å¸§è¢«åˆ¤å®šä¸ºè¯­éŸ³
            ENERGY_CONSISTENCY_THRESHOLD: 0.6 // èƒ½é‡ä¸€è‡´æ€§é˜ˆå€¼
        };

        let noiseFloor = 0;
        let isCalibrating = false;
        let calibrationSamples = [];
        let consecutiveSpeechFrames = 0;
        let consecutiveSilenceFrames = 0;
        let smoothedEnergy = 0;
        let hangoverCounter = 0;
        let noiseFloorHistory = [];

        // 1ç§’ç¡®è®¤çª—å£ç›¸å…³å˜é‡
        let speechCandidateStartTime = null;  // å€™é€‰è¯­éŸ³å¼€å§‹æ—¶é—´
        let confirmationWindowData = [];      // ç¡®è®¤çª—å£å†…çš„åˆ†ææ•°æ®
        let isInConfirmationWindow = false;   // æ˜¯å¦åœ¨ç¡®è®¤çª—å£ä¸­

        // Calculate spectral flatness (noise tends to have higher flatness than speech)
        function calculateSpectralFlatness(dataArray, minBin, maxBin) {
            let logSum = 0;
            let arithmeticSum = 0;
            let count = 0;

            for (let i = minBin; i < maxBin; i++) {
                const value = Math.max(dataArray[i], 1); // Avoid log(0)
                logSum += Math.log(value);
                arithmeticSum += value;
                count++;
            }

            if (count === 0 || arithmeticSum === 0) return 1;

            const geometricMean = Math.exp(logSum / count);
            const arithmeticMean = arithmeticSum / count;

            return geometricMean / arithmeticMean;
        }

        // Calculate spectral centroid (speech tends to have specific centroid range)
        function calculateSpectralCentroid(dataArray, minBin, maxBin, binSize) {
            let weightedSum = 0;
            let sum = 0;

            for (let i = minBin; i < maxBin; i++) {
                const frequency = i * binSize;
                weightedSum += frequency * dataArray[i];
                sum += dataArray[i];
            }

            return sum > 0 ? weightedSum / sum : 0;
        }

        function startVADMonitoring() {
            const analyser = state.voiceChatAnalyser;
            if (!analyser) return;

            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            silenceStartTime = null;
            speechStartTime = null;
            consecutiveSpeechFrames = 0;
            consecutiveSilenceFrames = 0;
            smoothedEnergy = 0;
            hangoverCounter = 0;
            noiseFloorHistory = [];

            // é‡ç½®ç¡®è®¤çª—å£çŠ¶æ€
            speechCandidateStartTime = null;
            confirmationWindowData = [];
            isInConfirmationWindow = false;

            // Start calibration phase
            isCalibrating = true;
            calibrationSamples = [];
            const calibrationStartTime = Date.now();

            updateVoiceChatUI('calibrating');
            elements.voiceChatStatus.textContent = 'ç¯å¢ƒå™ªå£°æ ¡å‡†ä¸­...';

            function checkAudioLevel() {
                if (!state.voiceChatListening || !state.voiceChatAnalyser) {
                    cancelAnimationFrame(vadAnimationFrame);
                    return;
                }

                analyser.getByteFrequencyData(dataArray);

                // Calculate frequency analysis parameters
                const sampleRate = 48000;
                const binSize = sampleRate / analyser.fftSize;
                const minBin = Math.floor(VAD_CONFIG.SPEECH_FREQUENCY_MIN / binSize);
                const maxBin = Math.min(Math.ceil(VAD_CONFIG.SPEECH_FREQUENCY_MAX / binSize), dataArray.length);

                // Calculate energy in speech frequency band
                let sum = 0;
                let count = 0;
                let peakValue = 0;
                for (let i = minBin; i < maxBin; i++) {
                    sum += dataArray[i];
                    count++;
                    if (dataArray[i] > peakValue) peakValue = dataArray[i];
                }
                const rawEnergy = count > 0 ? (sum / count / 255) : 0;

                // Apply smoothing to reduce jitter from transient noises
                smoothedEnergy = smoothedEnergy * (1 - VAD_CONFIG.ENERGY_SMOOTHING) + rawEnergy * VAD_CONFIG.ENERGY_SMOOTHING;

                // Calculate spectral features for better speech/noise discrimination
                const spectralFlatness = calculateSpectralFlatness(dataArray, minBin, maxBin);
                const spectralCentroid = calculateSpectralCentroid(dataArray, minBin, maxBin, binSize);

                // Speech typically has centroid between 300-1500 Hz
                const isCentroidInSpeechRange = spectralCentroid >= 300 && spectralCentroid <= 1500;
                // Speech has lower spectral flatness than noise
                const isSpectralPatternSpeechLike = spectralFlatness < VAD_CONFIG.SPECTRAL_FLATNESS_MAX;

                // Update visual feedback
                updateAudioLevelBars(smoothedEnergy);

                // Calibration phase
                if (isCalibrating) {
                    calibrationSamples.push(rawEnergy);

                    if (Date.now() - calibrationStartTime >= VAD_CONFIG.CALIBRATION_DURATION) {
                        // Use median instead of average for robustness
                        const sorted = [...calibrationSamples].sort((a, b) => a - b);
                        const medianNoise = sorted[Math.floor(sorted.length / 2)];
                        // Use 75th percentile for safety margin
                        const percentile75 = sorted[Math.floor(sorted.length * 0.75)];
                        noiseFloor = Math.max(medianNoise, percentile75 * 0.8);

                        // Initialize noise floor history for adaptive tracking
                        noiseFloorHistory = [noiseFloor, noiseFloor, noiseFloor];

                        isCalibrating = false;
                        calibrationSamples = [];

                        console.log(`[VAD] Calibration complete. Noise floor: ${noiseFloor.toFixed(4)}, Spectral reference captured`);
                        updateVoiceChatUI('listening');
                    }

                    vadAnimationFrame = requestAnimationFrame(checkAudioLevel);
                    return;
                }

                // Adaptive noise floor update during silence
                if (!state.voiceChatVadActive && consecutiveSilenceFrames > 30) {
                    // Slowly adapt noise floor to changing environment
                    const adaptedNoise = noiseFloor * (1 - VAD_CONFIG.NOISE_ADAPTATION_RATE) +
                                        rawEnergy * VAD_CONFIG.NOISE_ADAPTATION_RATE;
                    // Only update if noise is decreasing or slightly increasing
                    if (adaptedNoise < noiseFloor * 1.2) {
                        noiseFloor = adaptedNoise;
                        noiseFloorHistory.push(noiseFloor);
                        if (noiseFloorHistory.length > 10) noiseFloorHistory.shift();
                    }
                }

                // Calculate dynamic threshold based on noise floor
                const dynamicThreshold = Math.min(
                    Math.max(noiseFloor * VAD_CONFIG.NOISE_MULTIPLIER, VAD_CONFIG.MIN_SPEECH_THRESHOLD),
                    VAD_CONFIG.MAX_SPEECH_THRESHOLD
                );

                // Multi-factor speech detection
                const isEnergyAboveThreshold = smoothedEnergy > dynamicThreshold;
                const hasPeakEnergy = (peakValue / 255) > dynamicThreshold * 1.5;

                // Combined detection: energy + spectral characteristics
                const isSpeechLikely = isEnergyAboveThreshold &&
                                       (isSpectralPatternSpeechLike || isCentroidInSpeechRange) &&
                                       hasPeakEnergy;

                // è®°å½•å½“å‰å¸§çš„åˆ†ææ•°æ®ï¼ˆç”¨äº1ç§’ç¡®è®¤çª—å£ï¼‰
                const frameData = {
                    timestamp: Date.now(),
                    isSpeechLikely,
                    energy: smoothedEnergy,
                    spectralFlatness,
                    spectralCentroid
                };

                if (isSpeechLikely) {
                    consecutiveSpeechFrames++;
                    consecutiveSilenceFrames = 0;
                    hangoverCounter = VAD_CONFIG.HANGOVER_FRAMES;

                    // æ£€æµ‹åˆ°å¯èƒ½çš„è¯­éŸ³ï¼Œè¿›å…¥ç¡®è®¤çª—å£
                    if (consecutiveSpeechFrames >= VAD_CONFIG.CONSECUTIVE_FRAMES_REQUIRED && !isInConfirmationWindow && !state.voiceChatVadActive) {
                        isInConfirmationWindow = true;
                        speechCandidateStartTime = Date.now();
                        confirmationWindowData = [frameData];
                        console.log(`[VAD] è¿›å…¥1ç§’ç¡®è®¤çª—å£...`);
                        elements.voiceChatStatus.textContent = 'æ£€æµ‹ä¸­...';
                    }
                } else {
                    // Apply hangover to prevent cutting off speech during brief pauses
                    if (hangoverCounter > 0) {
                        hangoverCounter--;
                    } else {
                        consecutiveSilenceFrames++;
                        consecutiveSpeechFrames = 0;
                    }
                }

                // åœ¨ç¡®è®¤çª—å£ä¸­æ”¶é›†æ•°æ®
                if (isInConfirmationWindow && !state.voiceChatVadActive) {
                    confirmationWindowData.push(frameData);
                    const elapsed = Date.now() - speechCandidateStartTime;

                    // 1ç§’ç¡®è®¤çª—å£ç»“æŸï¼Œåˆ†ææ•°æ®
                    if (elapsed >= VAD_CONFIG.CONFIRMATION_WINDOW) {
                        const totalFrames = confirmationWindowData.length;
                        const speechFrames = confirmationWindowData.filter(f => f.isSpeechLikely).length;
                        const speechRatio = speechFrames / totalFrames;

                        // è®¡ç®—èƒ½é‡çš„ç¨³å®šæ€§ï¼ˆæ ‡å‡†å·®/å¹³å‡å€¼ï¼‰
                        const energies = confirmationWindowData.map(f => f.energy);
                        const avgEnergy = energies.reduce((a, b) => a + b, 0) / energies.length;
                        const variance = energies.reduce((a, b) => a + Math.pow(b - avgEnergy, 2), 0) / energies.length;
                        const stdDev = Math.sqrt(variance);
                        const energyConsistency = avgEnergy > 0 ? 1 - Math.min(stdDev / avgEnergy, 1) : 0;

                        // è®¡ç®—é¢‘è°±è´¨å¿ƒçš„ç¨³å®šæ€§
                        const centroids = confirmationWindowData.filter(f => f.isSpeechLikely).map(f => f.spectralCentroid);
                        const centroidInRange = centroids.filter(c => c >= 300 && c <= 1500).length;
                        const centroidRatio = centroids.length > 0 ? centroidInRange / centroids.length : 0;

                        console.log(`[VAD] ç¡®è®¤çª—å£åˆ†æ: è¯­éŸ³å¸§æ¯”ä¾‹=${(speechRatio*100).toFixed(1)}%, èƒ½é‡ä¸€è‡´æ€§=${(energyConsistency*100).toFixed(1)}%, è´¨å¿ƒåœ¨èŒƒå›´å†…=${(centroidRatio*100).toFixed(1)}%`);

                        // ç»¼åˆåˆ¤æ–­ï¼šè¯­éŸ³å¸§æ¯”ä¾‹ > 40% ä¸” èƒ½é‡æœ‰ä¸€å®šä¸€è‡´æ€§ ä¸” è´¨å¿ƒå¤§éƒ¨åˆ†åœ¨è¯­éŸ³èŒƒå›´å†…
                        if (speechRatio >= VAD_CONFIG.SPEECH_RATIO_THRESHOLD &&
                            energyConsistency >= VAD_CONFIG.ENERGY_CONSISTENCY_THRESHOLD &&
                            centroidRatio >= 0.5) {
                            // ç¡®è®¤æ˜¯çœŸå®è¯­éŸ³
                            state.voiceChatVadActive = true;
                            speechStartTime = speechCandidateStartTime; // ä½¿ç”¨å€™é€‰å¼€å§‹æ—¶é—´
                            console.log(`[VAD] âœ“ è¯­éŸ³ç¡®è®¤! Ratio: ${(speechRatio*100).toFixed(1)}%, Consistency: ${(energyConsistency*100).toFixed(1)}%`);
                            updateVoiceChatUI('detecting');
                            silenceStartTime = null;
                        } else {
                            // åˆ¤å®šä¸ºå™ªå£°ï¼Œé‡ç½®
                            console.log(`[VAD] âœ— åˆ¤å®šä¸ºå™ªå£°ï¼Œé‡ç½®`);
                            updateVoiceChatUI('listening');
                        }

                        // é‡ç½®ç¡®è®¤çª—å£
                        isInConfirmationWindow = false;
                        confirmationWindowData = [];
                        speechCandidateStartTime = null;
                    }
                }

                // è¯­éŸ³ç»“æŸæ£€æµ‹ï¼ˆä»…åœ¨å·²ç¡®è®¤è¯­éŸ³åï¼‰
                if (state.voiceChatVadActive && consecutiveSilenceFrames >= VAD_CONFIG.CONSECUTIVE_FRAMES_REQUIRED && hangoverCounter === 0) {
                    if (!silenceStartTime) {
                        silenceStartTime = Date.now();
                    } else if (Date.now() - silenceStartTime > VAD_CONFIG.SILENCE_DURATION) {
                        const speechDuration = speechStartTime ? Date.now() - speechStartTime : 0;
                        if (speechDuration > VAD_CONFIG.SPEECH_MIN_DURATION) {
                            console.log(`[VAD] Speech ended. Duration: ${speechDuration}ms`);
                            stopVoiceChatListening();
                            return;
                        } else {
                            console.log(`[VAD] Speech too short (${speechDuration}ms), resetting`);
                            state.voiceChatVadActive = false;
                            silenceStartTime = null;
                            speechStartTime = null;
                            updateVoiceChatUI('listening');
                        }
                    }
                }

                vadAnimationFrame = requestAnimationFrame(checkAudioLevel);
            }

            vadAnimationFrame = requestAnimationFrame(checkAudioLevel);
        }

        async function processVoiceChatAudio(audioBlob) {
            state.voiceChatProcessing = true;
            updateVoiceChatUI('processing_asr');

            try {
                // Step 1: ASR
                const asrText = await performASR(audioBlob);
                if (!asrText) {
                    updateVoiceChatUI('error', 'æ— æ³•è¯†åˆ«è¯­éŸ³');
                    state.voiceChatProcessing = false;
                    setTimeout(() => {
                        if (state.voiceChatActive) startVoiceChatListening();
                    }, 1000);
                    return;
                }

                // Show transcript
                elements.voiceChatTranscript.innerHTML = `<p class="text-base text-white">"${asrText}"</p>`;

                // Step 2: LLM
                updateVoiceChatUI('processing_llm');
                const llmResponse = await performLLMChat(asrText);
                if (!llmResponse) {
                    updateVoiceChatUI('error', 'AI æ— æ³•å›å¤');
                    state.voiceChatProcessing = false;
                    setTimeout(() => {
                        if (state.voiceChatActive) startVoiceChatListening();
                    }, 1000);
                    return;
                }

                // Show response
                elements.voiceChatResponse.classList.remove('hidden');
                elements.voiceChatResponse.innerHTML = `<p class="text-lg">${llmResponse}</p>`;

                // Step 3: TTS
                updateVoiceChatUI('playing_tts');
                await performTTS(llmResponse);

                // Step 4: Continue listening
                state.voiceChatProcessing = false;
                if (state.voiceChatActive) {
                    await startVoiceChatListening();
                }

            } catch (err) {
                console.error('Voice chat processing error:', err);
                updateVoiceChatUI('error', err.message || 'å¤„ç†å¤±è´¥');
                state.voiceChatProcessing = false;
                setTimeout(() => {
                    if (state.voiceChatActive) startVoiceChatListening();
                }, 2000);
            }
        }

        async function performASR(audioBlob) {
            // æ ¹æ® ASR æ¨¡å¼é€‰æ‹©äº‘ç«¯æˆ–æœ¬åœ°
            if (state.asrMode === 'local') {
                return await performLocalASR(audioBlob);
            } else {
                return await performCloudASR(audioBlob);
            }
        }

        // äº‘ç«¯ ASR (ç«å±±å¼•æ“)
        async function performCloudASR(audioBlob) {
            const formData = new FormData();
            const ext = audioBlob.type.includes('mp4') ? 'mp4' : audioBlob.type.includes('webm') ? 'webm' : 'audio';
            formData.append('audio', audioBlob, `recording.${ext}`);
            formData.append('appid', state.volcAppId);
            formData.append('token', state.volcToken);
            formData.append('cluster', state.volcCluster);

            const resp = await fetch('/api/asr', {
                method: 'POST',
                body: formData
            });

            const data = await resp.json();
            return data.text || null;
        }

        // æœ¬åœ° ASR (Whisper via transformers.js)
        async function performLocalASR(audioBlob) {
            const startTime = performance.now();
            console.log('[LocalASR] ========== å¼€å§‹æœ¬åœ° ASR å¤„ç† ==========');
            console.log(`[LocalASR] éŸ³é¢‘ Blob ç±»å‹: ${audioBlob.type}`);
            console.log(`[LocalASR] éŸ³é¢‘å¤§å°: ${(audioBlob.size / 1024).toFixed(2)} KB`);
            console.log(`[LocalASR] å½“å‰ ASR æ¨¡å¼: ${state.asrMode}`);
            console.log(`[LocalASR] Whisper æ¨¡å‹: ${state.whisperModel}`);
            console.log(`[LocalASR] Whisper è¯­è¨€: ${state.whisperLanguage}`);
            console.log(`[LocalASR] Pipeline çŠ¶æ€: ${state.whisperPipeline ? 'å·²åŠ è½½' : 'æœªåŠ è½½'}`);

            try {
                // ç¡®ä¿æ¨¡å‹å·²åŠ è½½
                if (!state.whisperPipeline) {
                    console.log('[LocalASR] æ¨¡å‹æœªåŠ è½½ï¼Œå¼€å§‹åŠ è½½...');
                    await loadWhisperModel();
                    console.log('[LocalASR] æ¨¡å‹åŠ è½½å®Œæˆï¼ŒPipeline:', state.whisperPipeline);
                }

                // å°†éŸ³é¢‘ Blob è½¬æ¢ä¸º AudioBuffer
                console.log('[LocalASR] å¼€å§‹è½¬æ¢éŸ³é¢‘ Blob åˆ° AudioBuffer...');
                const audioBuffer = await blobToAudioBuffer(audioBlob);
                console.log(`[LocalASR] éŸ³é¢‘è½¬æ¢å®Œæˆ:`);
                console.log(`  - æ—¶é•¿: ${audioBuffer.duration.toFixed(2)}s`);
                console.log(`  - é‡‡æ ·ç‡: ${audioBuffer.sampleRate}Hz`);
                console.log(`  - å£°é“æ•°: ${audioBuffer.numberOfChannels}`);
                console.log(`  - æ ·æœ¬æ•°: ${audioBuffer.length}`);

                // é‡é‡‡æ ·åˆ° 16kHz (Whisper è¦æ±‚)
                console.log('[LocalASR] å¼€å§‹é‡é‡‡æ ·åˆ° 16kHz...');
                const resampledAudio = await resampleAudio(audioBuffer, 16000);
                console.log(`[LocalASR] é‡é‡‡æ ·å®Œæˆ: ${resampledAudio.length} samples (${(resampledAudio.length / 16000).toFixed(2)}s)`);

                // æ£€æŸ¥éŸ³é¢‘æ•°æ®æœ‰æ•ˆæ€§
                const audioStats = {
                    min: Math.min(...resampledAudio),
                    max: Math.max(...resampledAudio),
                    mean: resampledAudio.reduce((a, b) => a + b, 0) / resampledAudio.length
                };
                console.log(`[LocalASR] éŸ³é¢‘æ•°æ®ç»Ÿè®¡: min=${audioStats.min.toFixed(4)}, max=${audioStats.max.toFixed(4)}, mean=${audioStats.mean.toFixed(6)}`);

                // è¿è¡Œ Whisper æ¨ç†
                console.log('[LocalASR] å¼€å§‹ Whisper æ¨ç†...');
                const inferenceStart = performance.now();
                const languageMap = {
                    'chinese': 'chinese',
                    'english': 'english',
                    'auto': null
                };
                const language = languageMap[state.whisperLanguage] || null;
                console.log(`[LocalASR] æ¨ç†å‚æ•°: language=${language}, task=transcribe`);

                const result = await state.whisperPipeline(resampledAudio, {
                    language: language,
                    task: 'transcribe',
                    chunk_length_s: 30,
                    stride_length_s: 5
                });

                const inferenceTime = performance.now() - inferenceStart;
                console.log(`[LocalASR] æ¨ç†å®Œæˆ: ${inferenceTime.toFixed(2)}ms`);
                console.log(`[LocalASR] åŸå§‹ç»“æœ:`, result);
                console.log(`[LocalASR] è¯†åˆ«æ–‡æœ¬: "${result.text}"`);

                const totalTime = performance.now() - startTime;
                console.log(`[LocalASR] ========== æ€»è€—æ—¶: ${totalTime.toFixed(2)}ms ==========`);

                return result.text?.trim() || null;
            } catch (err) {
                console.error('[LocalASR] ========== é”™è¯¯è¯¦æƒ… ==========');
                console.error('[LocalASR] é”™è¯¯ç±»å‹:', err.name);
                console.error('[LocalASR] é”™è¯¯æ¶ˆæ¯:', err.message);
                console.error('[LocalASR] é”™è¯¯å †æ ˆ:', err.stack);
                console.error('[LocalASR] å½“å‰çŠ¶æ€:', {
                    asrMode: state.asrMode,
                    whisperModel: state.whisperModel,
                    whisperLanguage: state.whisperLanguage,
                    pipelineLoaded: !!state.whisperPipeline,
                    modelLoading: state.whisperModelLoading,
                    modelLoaded: state.whisperModelLoaded
                });
                throw err;
            }
        }

        // åŠ è½½ Whisper æ¨¡å‹
        async function loadWhisperModel() {
            console.log('[Whisper] ========== å¼€å§‹åŠ è½½ Whisper æ¨¡å‹ ==========');
            console.log(`[Whisper] ç›®æ ‡æ¨¡å‹: ${state.whisperModel}`);
            console.log(`[Whisper] å½“å‰çŠ¶æ€: loading=${state.whisperModelLoading}, loaded=${state.whisperModelLoaded}`);

            if (state.whisperModelLoading) {
                console.log('[Whisper] æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­ï¼Œç­‰å¾…...');
                // ç­‰å¾…å½“å‰åŠ è½½å®Œæˆ
                let waitCount = 0;
                while (state.whisperModelLoading) {
                    await new Promise(resolve => setTimeout(resolve, 100));
                    waitCount++;
                    if (waitCount % 50 === 0) {
                        console.log(`[Whisper] ä»åœ¨ç­‰å¾…åŠ è½½å®Œæˆ... (${waitCount * 100}ms)`);
                    }
                }
                console.log('[Whisper] ç­‰å¾…å®Œæˆ');
                return;
            }

            if (state.whisperPipeline) {
                console.log('[Whisper] æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡');
                return; // å·²åŠ è½½
            }

            state.whisperModelLoading = true;
            updateWhisperModelStatus();

            // æ˜¾ç¤ºè¿›åº¦æ¡
            if (elements.whisperModelProgress) {
                elements.whisperModelProgress.classList.remove('hidden');
                elements.whisperProgressText.textContent = 'æ­£åœ¨åŠ è½½æ¨¡å‹...';
            }

            try {
                console.log(`[Whisper] æ­¥éª¤ 1: åŠ¨æ€å¯¼å…¥ transformers.js...`);
                const importStart = performance.now();

                // åŠ¨æ€å¯¼å…¥ transformers.js
                const transformersModule = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2');
                const { pipeline, env } = transformersModule;

                console.log(`[Whisper] transformers.js å¯¼å…¥æˆåŠŸ (${(performance.now() - importStart).toFixed(0)}ms)`);
                console.log(`[Whisper] å¯¼å…¥çš„æ¨¡å—:`, Object.keys(transformersModule));

                // é…ç½®ç¼“å­˜
                console.log('[Whisper] æ­¥éª¤ 2: é…ç½®ç¯å¢ƒ...');
                env.allowLocalModels = false;
                env.useBrowserCache = true;
                console.log(`[Whisper] env.allowLocalModels = ${env.allowLocalModels}`);
                console.log(`[Whisper] env.useBrowserCache = ${env.useBrowserCache}`);

                // åˆ›å»º pipeline å¹¶è·Ÿè¸ªä¸‹è½½è¿›åº¦
                console.log(`[Whisper] æ­¥éª¤ 3: åˆ›å»º ASR pipeline (æ¨¡å‹: ${state.whisperModel})...`);
                const pipelineStart = performance.now();

                state.whisperPipeline = await pipeline('automatic-speech-recognition', state.whisperModel, {
                    progress_callback: (progress) => {
                        console.log(`[Whisper] è¿›åº¦å›è°ƒ:`, progress);
                        if (progress.status === 'downloading') {
                            const percent = progress.progress ? Math.round(progress.progress) : 0;
                            if (elements.whisperProgressBar) {
                                elements.whisperProgressBar.style.width = `${percent}%`;
                            }
                            const fileName = progress.file || '';
                            if (elements.whisperProgressText) {
                                elements.whisperProgressText.textContent = `ä¸‹è½½ä¸­: ${fileName} (${percent}%)`;
                            }
                            console.log(`[Whisper] ä¸‹è½½è¿›åº¦: ${fileName} - ${percent}%`);
                        } else if (progress.status === 'loading') {
                            if (elements.whisperProgressText) {
                                elements.whisperProgressText.textContent = 'åŠ è½½æ¨¡å‹åˆ°å†…å­˜...';
                            }
                            console.log('[Whisper] æ­£åœ¨åŠ è½½æ¨¡å‹åˆ°å†…å­˜...');
                        } else if (progress.status === 'ready') {
                            if (elements.whisperProgressBar) {
                                elements.whisperProgressBar.style.width = '100%';
                            }
                            if (elements.whisperProgressText) {
                                elements.whisperProgressText.textContent = 'æ¨¡å‹å·²å°±ç»ª';
                            }
                            console.log('[Whisper] æ¨¡å‹å·²å°±ç»ª');
                        } else if (progress.status === 'initiate') {
                            console.log(`[Whisper] å¼€å§‹ä¸‹è½½: ${progress.file}`);
                        } else if (progress.status === 'done') {
                            console.log(`[Whisper] ä¸‹è½½å®Œæˆ: ${progress.file}`);
                        }
                    }
                });

                console.log(`[Whisper] Pipeline åˆ›å»ºæˆåŠŸ (${(performance.now() - pipelineStart).toFixed(0)}ms)`);
                console.log('[Whisper] Pipeline å¯¹è±¡:', state.whisperPipeline);

                state.whisperModelLoaded = true;
                console.log('[Whisper] ========== æ¨¡å‹åŠ è½½æˆåŠŸ ==========');
            } catch (err) {
                console.error('[Whisper] ========== æ¨¡å‹åŠ è½½å¤±è´¥ ==========');
                console.error('[Whisper] é”™è¯¯ç±»å‹:', err.name);
                console.error('[Whisper] é”™è¯¯æ¶ˆæ¯:', err.message);
                console.error('[Whisper] é”™è¯¯å †æ ˆ:', err.stack);
                state.whisperPipeline = null;
                if (elements.whisperProgressText) {
                    elements.whisperProgressText.textContent = 'åŠ è½½å¤±è´¥: ' + err.message;
                }
                throw err;
            } finally {
                state.whisperModelLoading = false;
                updateWhisperModelStatus();
            }
        }

        // å°† Blob è½¬æ¢ä¸º AudioBuffer
        async function blobToAudioBuffer(blob) {
            console.log('[AudioConvert] å¼€å§‹è½¬æ¢ Blob åˆ° AudioBuffer...');
            console.log(`[AudioConvert] Blob ç±»å‹: ${blob.type}, å¤§å°: ${blob.size} bytes`);

            try {
                const arrayBuffer = await blob.arrayBuffer();
                console.log(`[AudioConvert] ArrayBuffer å¤§å°: ${arrayBuffer.byteLength} bytes`);

                const audioContext = getAudioContext();
                console.log(`[AudioConvert] AudioContext çŠ¶æ€: ${audioContext.state}, é‡‡æ ·ç‡: ${audioContext.sampleRate}Hz`);

                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                console.log('[AudioConvert] è§£ç æˆåŠŸ');
                return audioBuffer;
            } catch (err) {
                console.error('[AudioConvert] è§£ç å¤±è´¥:', err);
                console.error('[AudioConvert] è¿™å¯èƒ½æ˜¯å› ä¸ºæµè§ˆå™¨ä¸æ”¯æŒè¯¥éŸ³é¢‘æ ¼å¼');
                throw err;
            }
        }

        // é‡é‡‡æ ·éŸ³é¢‘åˆ°ç›®æ ‡é‡‡æ ·ç‡
        async function resampleAudio(audioBuffer, targetSampleRate) {
            console.log('[Resample] å¼€å§‹é‡é‡‡æ ·...');
            const numChannels = audioBuffer.numberOfChannels;
            const length = audioBuffer.length;
            const sampleRate = audioBuffer.sampleRate;
            console.log(`[Resample] è¾“å…¥: ${numChannels}å£°é“, ${length}æ ·æœ¬, ${sampleRate}Hz`);
            console.log(`[Resample] ç›®æ ‡é‡‡æ ·ç‡: ${targetSampleRate}Hz`);

            // è·å–éŸ³é¢‘æ•°æ®ï¼ˆå¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬æ¢ä¸ºå•å£°é“ï¼‰
            let audioData;
            if (numChannels === 1) {
                audioData = audioBuffer.getChannelData(0);
                console.log('[Resample] å•å£°é“ï¼Œç›´æ¥ä½¿ç”¨');
            } else {
                // æ··åˆå¤šå£°é“ä¸ºå•å£°é“
                console.log(`[Resample] ${numChannels}å£°é“ï¼Œæ··åˆä¸ºå•å£°é“`);
                audioData = new Float32Array(length);
                for (let ch = 0; ch < numChannels; ch++) {
                    const channelData = audioBuffer.getChannelData(ch);
                    for (let i = 0; i < length; i++) {
                        audioData[i] += channelData[i] / numChannels;
                    }
                }
            }

            // å¦‚æœé‡‡æ ·ç‡å·²ç»æ˜¯ç›®æ ‡é‡‡æ ·ç‡ï¼Œç›´æ¥è¿”å›
            if (sampleRate === targetSampleRate) {
                console.log('[Resample] é‡‡æ ·ç‡å·²åŒ¹é…ï¼Œæ— éœ€é‡é‡‡æ ·');
                return audioData;
            }

            // ä½¿ç”¨ OfflineAudioContext è¿›è¡Œé«˜è´¨é‡é‡é‡‡æ ·
            const duration = length / sampleRate;
            const newLength = Math.round(duration * targetSampleRate);
            console.log(`[Resample] é‡é‡‡æ ·: ${length} -> ${newLength} æ ·æœ¬`);

            const offlineCtx = new OfflineAudioContext(1, newLength, targetSampleRate);

            // åˆ›å»ºæºç¼“å†²åŒº
            const sourceBuffer = offlineCtx.createBuffer(1, length, sampleRate);
            sourceBuffer.getChannelData(0).set(audioData);

            // åˆ›å»ºæºèŠ‚ç‚¹
            const sourceNode = offlineCtx.createBufferSource();
            sourceNode.buffer = sourceBuffer;
            sourceNode.connect(offlineCtx.destination);
            sourceNode.start();

            // æ¸²æŸ“
            const renderedBuffer = await offlineCtx.startRendering();
            console.log('[Resample] é‡é‡‡æ ·å®Œæˆ');
            return renderedBuffer.getChannelData(0);
        }

        async function performLLMChat(userMessage) {
            const role = state.roles.find(r => r.id === state.currentRoleId);
            if (!role) return null;

            // Add to chat history
            if (!state.chatHistory[state.currentRoleId]) {
                state.chatHistory[state.currentRoleId] = [];
            }
            state.chatHistory[state.currentRoleId].push({ role: 'user', content: userMessage });

            // Prepare messages for API
            const formatInstruction = '\n\nã€æ ¼å¼è¦æ±‚ã€‘è¯·ä½¿ç”¨çº¯æ–‡æœ¬å›å¤ï¼Œç¦æ­¢ä½¿ç”¨ä»»ä½• markdown æ ¼å¼ã€‚å›å¤è¦ç®€æ´é€‚åˆè¯­éŸ³å¯¹è¯ã€‚';
            const historyMessages = state.chatHistory[state.currentRoleId].filter(m => m.content !== '...');
            const compressedSummary = historyMessages.find(m => m.isCompressed && m.role === 'system');
            const regularMessages = historyMessages.filter(m => !m.isCompressed);

            let systemPrompt = role.prompt + formatInstruction;
            if (compressedSummary) {
                systemPrompt += '\n\nã€ä¹‹å‰å¯¹è¯æ‘˜è¦ã€‘\n' + compressedSummary.content;
            }

            const apiMessages = [
                { role: 'system', content: systemPrompt },
                ...regularMessages.map(m => ({ role: m.role, content: m.content }))
            ];

            const response = await fetch('/api/proxy-llm', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    apiKey: state.apiKey,
                    model: state.chatModel,
                    messages: apiMessages
                })
            });

            if (!response.ok) {
                throw new Error('LLM API è¯·æ±‚å¤±è´¥');
            }

            const data = await response.json();
            const assistantMessage = data.choices?.[0]?.message?.content || null;

            if (assistantMessage) {
                state.chatHistory[state.currentRoleId].push({ role: 'assistant', content: assistantMessage });
                saveChatHistory();
                renderMessages();
            }

            return assistantMessage;
        }

        async function performTTS(text) {
            const voiceType = state.volcTtsVoice || 'zh_female_vv_uranus_bigtts';
            const cleanedText = cleanTextForTts(text);

            return new Promise(async (resolve, reject) => {
                try {
                    if (state.volcTtsMode === 'stream') {
                        // Use streaming TTS
                        await playVoiceChatTtsStream(cleanedText, voiceType, resolve);
                    } else {
                        // Use normal TTS
                        await playVoiceChatTtsNormal(cleanedText, voiceType, resolve);
                    }
                } catch (err) {
                    console.error('TTS error:', err);
                    resolve(); // Continue even if TTS fails
                }
            });
        }

        async function playVoiceChatTtsNormal(text, voiceType, onComplete) {
            const cacheKey = text + '_' + voiceType;

            // Check cache
            if (state.ttsCache[cacheKey]) {
                const cachedData = state.ttsCache[cacheKey];
                await playAudioFromCache(cachedData, onComplete);
                return;
            }

            // Fetch TTS
            const response = await fetch('/api/tts', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    text: text,
                    appid: state.volcAppId,
                    token: state.volcTtsToken,
                    cluster: state.volcTtsCluster,
                    voice_type: voiceType
                })
            });

            const data = await response.json();
            if (data.audio) {
                state.ttsCache[cacheKey] = { data: data.audio, format: 'mp3' };
                await playAudioFromCache({ data: data.audio, format: 'mp3' }, onComplete);
            } else {
                onComplete();
            }
        }

        async function playVoiceChatTtsStream(text, voiceType, onComplete) {
            const audioContext = getAudioContext();
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            // æ„å»º GET è¯·æ±‚ URLï¼ˆæœåŠ¡å™¨ç«¯ä½¿ç”¨ GET æ–¹æ³•ï¼‰
            const params = new URLSearchParams({
                text: text,
                appid: state.volcAppId,
                access_key: state.volcTtsAccessKey,
                resource_id: state.volcTtsCluster, // æœåŠ¡å™¨ä½¿ç”¨ resource_id å‚æ•°å
                voice_type: voiceType
            });
            const url = `/api/tts-stream?${params.toString()}`;

            const response = await fetch(url);

            if (!response.ok) {
                throw new Error('TTS stream request failed');
            }

            const sampleRate = 24000;
            let audioQueue = [];
            let isPlaying = false;
            let nextPlayTime = audioContext.currentTime;
            let allReceived = false;

            async function playNextChunk() {
                if (audioQueue.length === 0) {
                    if (allReceived) {
                        onComplete();
                    }
                    return;
                }

                isPlaying = true;
                const chunk = audioQueue.shift();

                const audioBuffer = audioContext.createBuffer(1, chunk.length, sampleRate);
                audioBuffer.getChannelData(0).set(chunk);

                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                if (nextPlayTime < audioContext.currentTime) {
                    nextPlayTime = audioContext.currentTime;
                }

                source.start(nextPlayTime);
                nextPlayTime += audioBuffer.duration;

                source.onended = () => {
                    if (audioQueue.length > 0) {
                        playNextChunk();
                    } else if (allReceived) {
                        onComplete();
                    } else {
                        isPlaying = false;
                    }
                };
            }

            // ä½¿ç”¨ EventSource è§£æ SSE æ ¼å¼çš„å“åº”
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let sseBuffer = '';

            // å¤„ç† SSE è¡Œçš„è¾…åŠ©å‡½æ•°
            function processSSELine(line) {
                if (line.startsWith('data: ')) {
                    try {
                        const jsonStr = line.slice(6); // å»æ‰ 'data: ' å‰ç¼€
                        const data = JSON.parse(jsonStr);

                        if (data.type === 'audio' && data.data) {
                            // è§£ç  base64 éŸ³é¢‘æ•°æ®
                            const binaryString = atob(data.data);
                            const bytes = new Uint8Array(binaryString.length);
                            for (let i = 0; i < binaryString.length; i++) {
                                bytes[i] = binaryString.charCodeAt(i);
                            }

                            // è½¬æ¢ 16-bit PCM åˆ° Float32
                            const int16Array = new Int16Array(bytes.buffer);
                            const float32Array = new Float32Array(int16Array.length);
                            for (let i = 0; i < int16Array.length; i++) {
                                float32Array[i] = int16Array[i] / 32768;
                            }

                            audioQueue.push(float32Array);

                            if (!isPlaying) {
                                playNextChunk();
                            }
                        } else if (data.type === 'end') {
                            console.log('[TTS Stream] æ¥æ”¶å®Œæˆ, æ€»å—æ•°:', data.totalChunks);
                            allReceived = true;
                        } else if (data.type === 'error') {
                            console.error('[TTS Stream] é”™è¯¯:', data.message);
                        }
                    } catch (e) {
                        console.error('[TTS Stream] è§£æé”™è¯¯:', e);
                    }
                }
            }

            while (true) {
                const { done, value } = await reader.read();
                if (done) {
                    // æµç»“æŸæ—¶ï¼Œåˆ·æ–°è§£ç å™¨å¹¶å¤„ç† sseBuffer ä¸­å¯èƒ½æ®‹ç•™çš„æ•°æ®
                    sseBuffer += decoder.decode(); // åˆ·æ–°è§£ç å™¨
                    if (sseBuffer.trim()) {
                        // å¤„ç†æ®‹ç•™çš„è¡Œ
                        const remainingLines = sseBuffer.split('\n');
                        for (const line of remainingLines) {
                            processSSELine(line);
                        }
                    }
                    allReceived = true;
                    if (!isPlaying && audioQueue.length === 0) {
                        onComplete();
                    }
                    break;
                }

                // è§£æ SSE æ ¼å¼
                sseBuffer += decoder.decode(value, { stream: true });
                const lines = sseBuffer.split('\n');
                sseBuffer = lines.pop(); // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ

                for (const line of lines) {
                    processSSELine(line);
                }
            }
        }

        async function playAudioFromCache(cachedData, onComplete) {
            const audioContext = getAudioContext();
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            const arrayBuffer = base64ToArrayBuffer(cachedData.data);
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.onended = () => onComplete();
            source.start(0);

            state.currentAudio = source;
        }

        init();
    </script>
</body>
</html>
