const express = require('express');
const bodyParser = require('body-parser');
const path = require('path');
const multer = require('multer');
const axios = require('axios');
const fs = require('fs');
const crypto = require('crypto');
const WebSocket = require('ws');
const zlib = require('zlib');
const { execFile } = require('child_process');
const ffmpegPath = require('ffmpeg-static');
const https = require('https');

const app = express();
const upload = multer({ dest: 'uploads/' });
const PORT = 3000;
const HTTPS_PORT = 443;

// Ê£ÄÊµãÊñáÊú¨ÊòØÂê¶ÂåÖÂê´‰∏≠ÊñáÂ≠óÁ¨¶
function containsChinese(text) {
    return /[\u4e00-\u9fa5]/.test(text);
}

// ‰ΩøÁî® LLM Â∞Ü‰∏≠ÊñáÊèêÁ§∫ËØçÁøªËØëÊàêËã±Êñá
async function translateToEnglish(text, apiKey, model) {
    try {
        const response = await axios.post('https://openrouter.ai/api/v1/chat/completions', {
            model: model || 'google/gemini-2.0-flash-001',
            messages: [{
                role: 'user',
                content: `Translate the following image generation prompt to English. Output ONLY the English translation, nothing else. Keep the same level of detail and artistic style descriptions.

Text to translate:
${text}`
            }]
        }, {
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json'
            }
        });

        const translatedText = response.data.choices?.[0]?.message?.content;
        if (translatedText && !containsChinese(translatedText)) {
            console.log('Successfully translated prompt to English');
            return translatedText.trim();
        }
        return text; // Â¶ÇÊûúÁøªËØëÂ§±Ë¥•ÔºåËøîÂõûÂéüÊñá
    } catch (error) {
        console.error('Translation error:', error.message);
        return text; // ÁøªËØëÂ§±Ë¥•Êó∂ËøîÂõûÂéüÊñá
    }
}

// SSL ËØÅ‰π¶ÈÖçÁΩÆ
const SSL_KEY_PATH = path.join(__dirname, 'ssl', 'webroleplay.xyz.key');
const SSL_CERT_PATH = path.join(__dirname, 'ssl', 'webroleplay.xyz.pem');

app.use(bodyParser.json());
app.use(express.static(path.join(__dirname, 'public')));

// ÊúçÂä°‰∏ªÈ°µÈù¢
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'index.html'));
});

// ÂÆö‰πâÊñáÁîüÂõæÂ∑•ÂÖ∑Ôºà‰æõ LLM Ë∞ÉÁî®Ôºâ
const TEXT_TO_IMAGE_TOOL = {
    type: 'function',
    function: {
        name: 'generate_image',
        description: 'Ê†πÊçÆÊñáÊú¨ÊèèËø∞ÁîüÊàêÂõæÁâá„ÄÇÂΩìÁî®Êà∑Ë¶ÅÊ±ÇÁîüÊàê„ÄÅÂàõÂª∫„ÄÅÁîªÂõæÁâáÊó∂‰ΩøÁî®Ê≠§Â∑•ÂÖ∑„ÄÇ**ÈáçË¶ÅÔºöprompt ÂøÖÈ°ª‰ΩøÁî®Ëã±ÊñáÊèèËø∞ÔºåÂ¶ÇÊûúÁî®Êà∑Êèê‰æõ‰∏≠ÊñáÊèèËø∞Ôºå‰Ω†ÈúÄË¶ÅÂÖàÂ∞ÜÂÖ∂ÁøªËØëÊàêËØ¶ÁªÜÁöÑËã±ÊñáÊèêÁ§∫ËØç„ÄÇ**',
        parameters: {
            type: 'object',
            properties: {
                prompt: {
                    type: 'string',
                    description: 'ÂõæÁâáÊèèËø∞ÊñáÊú¨ÔºàÂøÖÈ°ª‰ΩøÁî®Ëã±ÊñáÔºâ„ÄÇËØ¶ÁªÜÊèèËø∞ÊÉ≥Ë¶ÅÁîüÊàêÁöÑÂõæÁâáÂÜÖÂÆπÔºåÂåÖÊã¨‰∏ª‰Ωì„ÄÅÈ£éÊ†ºÁ≠â„ÄÇ‰æãÂ¶ÇÔºö"A cute cat sitting on clouds"„ÄÇÂ¶ÇÊûúÁî®Êà∑Êèê‰æõ‰∏≠ÊñáÊèèËø∞ÔºåËØ∑ÂÖàÁøªËØëÊàêËã±Êñá„ÄÇ'
                },
                negative_prompt: {
                    type: 'string',
                    description: 'Ë¥üÈù¢ÊèêÁ§∫ËØçÔºàËã±ÊñáÔºâÔºåÂ§ßÈÉ®ÂàÜÊÉÖÂÜµ‰∏ã‰∏çÈúÄË¶ÅÊåáÂÆö„ÄÇ',
                    default: ''
                },
                width: {
                    type: 'number',
                    description: 'ÂõæÁâáÂÆΩÂ∫¶ÔºàÂÉèÁ¥†ÔºâÔºåÈªòËÆ§ 512',
                    default: 512,
                    enum: [512, 768, 1024]
                },
                height: {
                    type: 'number',
                    description: 'ÂõæÁâáÈ´òÂ∫¶ÔºàÂÉèÁ¥†ÔºâÔºåÈªòËÆ§ 728',
                    default: 728,
                    enum: [512, 728, 768, 1024]
                }
            },
            required: ['prompt']
        }
    }
};

// ÂõæÁâáÁîüÊàêÊ®°ÂûãÈÖçÁΩÆ
const IMAGE_MODELS = {
    'realistic-vision-v5.1': {
        version: 'lucataco/realistic-vision-v5.1:2c8e954decbf70b7607a4414e5785ef9e4de4b8c51d50fb8b8b349160e0ef6bb',
        defaultWidth: 512,
        defaultHeight: 512,
        steps: 20,
        guidance: 5,
        scheduler: 'EulerA'
    },
    'realvisxl-v3.0-turbo': {
        version: 'adirik/realvisxl-v3.0-turbo:3dc73c805b11b4b01a60555e532fd3ab3f0e60d26f6584d9b8ba7e1b95858243',
        defaultWidth: 768,
        defaultHeight: 768,
        steps: 25,
        guidance: 2,
        scheduler: 'DPM++_SDE_Karras'
    },
    'dreamshaper-xl-turbo': {
        version: 'lucataco/dreamshaper-xl-turbo:0a1710e0187b01a255302738ca0158ff02a22f4638679533e111082f9dd1b615',
        defaultWidth: 1024,
        defaultHeight: 1024,
        steps: 7,           // Turbo Ê®°ÂûãÂè™ÈúÄË¶Å 7 Ê≠•
        guidance: 2,        // ‰Ωé guidance ÊïàÊûúÊõ¥Â•Ω
        scheduler: 'K_EULER'  // ÂøÖÈ°ªÊåáÂÆöË∞ÉÂ∫¶Âô®
    },
    'qwen-image-fast': {
        version: 'prunaai/qwen-image-fast:01b324d214eb4870ff424dc4215c067759c4c01a8751e327a434e2b16054db2f',
        defaultAspectRatio: '1:1',
        creativity: 0.62,
        disable_safety_checker: true,
        useAspectRatio: true  // Ê†áËÆ∞‰ΩøÁî® aspect_ratio ËÄåÈùû width/height
    },
    'p-image': {
        modelEndpoint: 'prunaai/p-image',  // ‰ΩøÁî® model endpoint ËÄåÈùû version
        defaultAspectRatio: '16:9',
        promptUpsampling: false,
        useAspectRatio: true,
        disable_safety_checker: true,
        useModelEndpoint: true  // Ê†áËÆ∞‰ΩøÁî® model endpoint
    },
    'flux-fast': {
        modelEndpoint: 'prunaai/flux-fast',  // ‰ΩøÁî® model endpoint
        defaultImageSize: 1024,
        defaultAspectRatio: '1:1',
        guidance: 3.5,
        speedMode: 'Extra Juiced üî• (more speed)',
        outputFormat: 'jpg',
        outputQuality: 80,
        numInferenceSteps: 28,
        useModelEndpoint: true,
        isFluxFast: true  // Ê†áËÆ∞‰∏∫ flux-fast Ê®°Âûã
    },
    'z-image-turbo': {
        modelEndpoint: 'prunaai/z-image-turbo',  // ‰ΩøÁî® model endpoint
        defaultWidth: 1024,
        defaultHeight: 768,
        guidanceScale: 0,
        outputFormat: 'jpg',
        outputQuality: 80,
        numInferenceSteps: 8,
        useModelEndpoint: true,
        isZImageTurbo: true  // Ê†áËÆ∞‰∏∫ z-image-turbo Ê®°Âûã
    },
    'flux-2-pro': {
        modelEndpoint: 'black-forest-labs/flux-2-pro',  // ‰ΩøÁî® model endpoint
        defaultResolution: '1 MP',
        defaultAspectRatio: '1:1',
        outputFormat: 'webp',
        outputQuality: 80,
        safetyTolerance: 5,
        useModelEndpoint: true,
        isFlux2Pro: true  // Ê†áËÆ∞‰∏∫ flux-2-pro Ê®°Âûã
    },
    'nano-banana-pro': {
        modelEndpoint: 'google/nano-banana-pro',  // ‰ΩøÁî® model endpoint
        defaultResolution: '2K',
        defaultAspectRatio: '4:3',
        outputFormat: 'png',
        safetyFilterLevel: 'block_only_high',
        useModelEndpoint: true,
        isNanoBananaPro: true  // Ê†áËÆ∞‰∏∫ nano-banana-pro Ê®°Âûã
    },
    'gpt-image-1.5': {
        modelEndpoint: 'openai/gpt-image-1.5',  // ‰ΩøÁî® model endpoint
        defaultAspectRatio: '1:1',
        quality: 'high',
        background: 'auto',
        moderation: 'auto',
        outputFormat: 'webp',
        outputCompression: 90,
        inputFidelity: 'low',
        numberOfImages: 1,
        disableSafetyChecker: true,
        useModelEndpoint: true,
        isGptImage15: true  // Ê†áËÆ∞‰∏∫ gpt-image-1.5 Ê®°Âûã
    },
    'qwen-image': {
        modelEndpoint: 'qwen/qwen-image',  // ‰ΩøÁî® model endpoint
        defaultAspectRatio: '16:9',
        goFast: true,
        guidance: 4,
        strength: 0.9,
        imageSize: 'optimize_for_quality',
        loraScale: 1,
        outputFormat: 'webp',
        enhancePrompt: false,
        outputQuality: 80,
        negativePrompt: ' ',
        disableSafetyChecker: true,
        numInferenceSteps: 50,
        useModelEndpoint: true,
        isQwenImage: true  // Ê†áËÆ∞‰∏∫ qwen-image Ê®°Âûã
    }
};

// LLM ‰ª£ÁêÜÊé•Âè£ - Ëß£ÂÜ≥ÂâçÁ´ØÁõ¥Êé•Ë∞ÉÁî® OpenRouter ÁöÑ CORS ÂíåË∫´‰ªΩÈ™åËØÅÈóÆÈ¢ò
// ÊîØÊåÅ function callingÔºàÂ∑•ÂÖ∑Ë∞ÉÁî®Ôºâ
app.post('/api/proxy-llm', async (req, res) => {
    const { apiKey, model, messages, response_format, tools, tool_choice, replicateToken, replicateModel } = req.body;
    if (!apiKey || !model || !messages) {
        return res.status(400).json({ success: false, message: 'Áº∫Â∞ëÂøÖË¶ÅÂèÇÊï∞' });
    }

    // Ëé∑ÂèñÂõæÁâáÊ®°ÂûãÈÖçÁΩÆ
    const imageModelConfig = IMAGE_MODELS[replicateModel] || IMAGE_MODELS['realistic-vision-v5.1'];

    try {
        // ÊûÑÂª∫ËØ∑Ê±ÇÂèÇÊï∞
        const requestBody = {
            model,
            messages,
            response_format
        };

        // Â¶ÇÊûúÊèê‰æõ‰∫ÜÂ∑•ÂÖ∑ÔºåÊ∑ªÂä†Âà∞ËØ∑Ê±Ç‰∏≠
        if (tools && tools.length > 0) {
            requestBody.tools = tools;
            if (tool_choice) {
                requestBody.tool_choice = tool_choice;
            }
        }

        const response = await axios.post('https://openrouter.ai/api/v1/chat/completions', requestBody, {
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json',
                'HTTP-Referer': 'https://github.com/Roo-Code/Roo-Code',
                'X-Title': 'RolePlay Chat'
            }
        });

        const data = response.data;

        // Ê£ÄÊü•ÊòØÂê¶ÊúâÂ∑•ÂÖ∑Ë∞ÉÁî®
        if (data.choices && data.choices[0].message.tool_calls) {
            const toolCalls = data.choices[0].message.tool_calls;
            const toolResults = [];

            // Â§ÑÁêÜÊØè‰∏™Â∑•ÂÖ∑Ë∞ÉÁî®
            for (const toolCall of toolCalls) {
                if (toolCall.function.name === 'generate_image') {
                    try {
                        const args = JSON.parse(toolCall.function.arguments);

                        if (!replicateToken) {
                            toolResults.push({
                                tool_call_id: toolCall.id,
                                role: 'tool',
                                name: 'generate_image',
                                content: JSON.stringify({
                                    error: 'Êú™ÈÖçÁΩÆ Replicate API TokenÔºåËØ∑Âú®ËÆæÁΩÆ‰∏≠ÈÖçÁΩÆ'
                                })
                            });
                            continue;
                        }

                        // ÊûÑÂª∫ÂõæÁâáÁîüÊàêËØ∑Ê±ÇÂèÇÊï∞
                        let imageInput;
                        let apiEndpoint;
                        let requestBody;

                        if (imageModelConfig.isFluxFast) {
                            // Flux Fast Ê®°Âûã
                            imageInput = {
                                seed: -1,
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                guidance: imageModelConfig.guidance,
                                image_size: imageModelConfig.defaultImageSize,
                                speed_mode: imageModelConfig.speedMode,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                output_quality: imageModelConfig.outputQuality,
                                num_inference_steps: imageModelConfig.numInferenceSteps
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isZImageTurbo) {
                            // Z-Image Turbo Ê®°Âûã
                            imageInput = {
                                width: args.width || imageModelConfig.defaultWidth,
                                height: args.height || imageModelConfig.defaultHeight,
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                output_format: imageModelConfig.outputFormat,
                                guidance_scale: imageModelConfig.guidanceScale,
                                output_quality: imageModelConfig.outputQuality,
                                num_inference_steps: imageModelConfig.numInferenceSteps
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isFlux2Pro) {
                            // FLUX.2 [pro] Ê®°Âûã
                            imageInput = {
                                prompt: args.prompt,
                                resolution: args.resolution || imageModelConfig.defaultResolution,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                input_images: [],
                                output_format: imageModelConfig.outputFormat,
                                output_quality: imageModelConfig.outputQuality,
                                safety_tolerance: imageModelConfig.safetyTolerance
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isNanoBananaPro) {
                            // Nano Banana Pro Ê®°Âûã
                            imageInput = {
                                prompt: args.prompt,
                                resolution: args.resolution || imageModelConfig.defaultResolution,
                                image_input: [],
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                safety_filter_level: imageModelConfig.safetyFilterLevel
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isGptImage15) {
                            // GPT Image 1.5 Ê®°Âûã (OpenAI on Replicate)
                            imageInput = {
                                prompt: args.prompt,
                                quality: imageModelConfig.quality,
                                background: imageModelConfig.background,
                                moderation: imageModelConfig.moderation,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                input_fidelity: imageModelConfig.inputFidelity,
                                number_of_images: imageModelConfig.numberOfImages,
                                disable_safety_checker: imageModelConfig.disableSafetyChecker ? 1 : 0,
                                output_compression: imageModelConfig.outputCompression
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isQwenImage) {
                            // Qwen Image Ê®°Âûã (ÈÄö‰πâ‰∏áË±°)
                            imageInput = {
                                prompt: args.prompt,
                                go_fast: imageModelConfig.goFast,
                                guidance: imageModelConfig.guidance,
                                strength: imageModelConfig.strength,
                                image_size: imageModelConfig.imageSize,
                                lora_scale: imageModelConfig.loraScale,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                enhance_prompt: imageModelConfig.enhancePrompt,
                                output_quality: imageModelConfig.outputQuality,
                                negative_prompt: args.negative_prompt || imageModelConfig.negativePrompt,
                                disable_safety_checker: imageModelConfig.disableSafetyChecker,
                                num_inference_steps: imageModelConfig.numInferenceSteps
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.useAspectRatio) {
                            // Êñ∞Ê®°Âûã‰ΩøÁî® aspect_ratio ÂèÇÊï∞ (Â¶Ç qwen-image-fast, p-image)
                            imageInput = {
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio
                            };

                            if (imageModelConfig.creativity !== undefined) {
                                imageInput.creativity = args.creativity || imageModelConfig.creativity;
                            }
                            if (imageModelConfig.promptUpsampling !== undefined) {
                                imageInput.prompt_upsampling = imageModelConfig.promptUpsampling;
                            }

                            if (imageModelConfig.useModelEndpoint) {
                                // p-image ‰ΩøÁî® model endpoint
                                apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                                requestBody = { input: imageInput };
                            } else {
                                // qwen-image-fast ‰ΩøÁî® version endpoint
                                apiEndpoint = 'https://api.replicate.com/v1/predictions';
                                requestBody = {
                                    version: imageModelConfig.version,
                                    input: imageInput
                                };
                            }
                        } else {
                            // ‰º†ÁªüÊ®°Âûã‰ΩøÁî® width/height ÂèÇÊï∞
                            imageInput = {
                                seed: Math.floor(Math.random() * 10000),
                                steps: imageModelConfig.steps,
                                width: args.width || imageModelConfig.defaultWidth,
                                height: args.height || imageModelConfig.defaultHeight,
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                negative_prompt: args.negative_prompt || '(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck'
                            };

                            // Ê∑ªÂä†Ê®°ÂûãÁâπÂÆöÂèÇÊï∞
                            if (imageModelConfig.guidance) {
                                imageInput.guidance = imageModelConfig.guidance;
                            }
                            if (imageModelConfig.scheduler) {
                                imageInput.scheduler = imageModelConfig.scheduler;
                            }

                            apiEndpoint = 'https://api.replicate.com/v1/predictions';
                            requestBody = {
                                version: imageModelConfig.version,
                                input: imageInput
                            };
                        }

                        console.log(`‰ΩøÁî®ÂõæÁâáÊ®°Âûã: ${replicateModel || 'realistic-vision-v5.1'}`);
                        console.log(`API Á´ØÁÇπ: ${apiEndpoint}`);

                        // Ë∞ÉÁî® Replicate API ÁîüÊàêÂõæÁâá
                        const imageResponse = await axios.post(
                            apiEndpoint,
                            requestBody,
                            {
                                headers: {
                                    'Authorization': `Bearer ${replicateToken}`,
                                    'Content-Type': 'application/json',
                                    'Prefer': 'wait'
                                },
                                timeout: 120000
                            }
                        );

                        // Ë∞ÉËØïÊó•ÂøóÔºöÊü•Áúã Replicate API ÁöÑÂìçÂ∫î
                        console.log('Replicate API response:', JSON.stringify(imageResponse.data, null, 2));

                        // Â§ÑÁêÜ‰∏çÂêåÁöÑËæìÂá∫Ê†ºÂºè
                        let imageUrl = null;
                        const output = imageResponse.data.output;
                        if (Array.isArray(output) && output.length > 0) {
                            imageUrl = output[0];
                        } else if (typeof output === 'string') {
                            imageUrl = output;
                        }

                        console.log('Extracted imageUrl:', imageUrl);

                        if (!imageUrl) {
                            throw new Error('No image URL in response');
                        }

                        toolResults.push({
                            tool_call_id: toolCall.id,
                            role: 'tool',
                            name: 'generate_image',
                            content: JSON.stringify({
                                success: true,
                                imageUrl: imageUrl,
                                prompt: args.prompt
                            })
                        });

                    } catch (error) {
                        console.error('Image generation error:', error.response?.data || error.message);
                        toolResults.push({
                            tool_call_id: toolCall.id,
                            role: 'tool',
                            name: 'generate_image',
                            content: JSON.stringify({
                                error: `ÂõæÁâáÁîüÊàêÂ§±Ë¥•: ${error.response?.data?.detail || error.message}`
                            })
                        });
                    }
                }
            }

            // ËøîÂõûÂ∑•ÂÖ∑Ë∞ÉÁî®ÁªìÊûúÔºåËÆ©ÂâçÁ´ØÁªßÁª≠ÂØπËØù
            data.tool_results = toolResults;
        }

        res.json(data);
    } catch (error) {
        console.error('LLM Proxy Error:', error.response?.data || error.message);
        res.status(error.response?.status || 500).json(error.response?.data || { message: error.message });
    }
});

// ÁÅ´Â±±ÂºïÊìéËØ≠Èü≥ÂêàÊàêÊé•Âè£ (TTS) - ÊôÆÈÄöÊ®°Âºè (v1 API)
app.post('/api/tts', async (req, res) => {
    let { text, appid, token, cluster, voice_type } = req.body;
    if (!text || !appid || !token) {
        return res.status(400).json({ success: false, message: 'Áº∫Â∞ëÂèÇÊï∞' });
    }

    // ÂéªÈô§ÂèØËÉΩÂ≠òÂú®ÁöÑÁ©∫Ê†º
    appid = appid.trim();
    token = token.trim();
    if (cluster) cluster = cluster.trim();
    if (voice_type) voice_type = voice_type.trim();

    try {
        const tts_url = 'https://openspeech.bytedance.com/api/v1/tts';
        const requestData = {
            app: { appid, token, cluster: cluster || 'volcano_tts' },
            user: { uid: 'roleplay_user' },
            audio: {
                voice_type: voice_type || 'zh_female_vv_uranus_bigtts',
                encoding: 'mp3',
                speed_ratio: 1.0,
                volume_ratio: 1.0,
                pitch_ratio: 1.0,
            },
            request: {
                reqid: crypto.randomUUID(),
                text: text,
                text_type: 'plain',
                operation: 'query',
            }
        };

        console.log('Submitting TTS request to Volcengine (v1)...');
        console.log('AppID:', appid);
        console.log('Cluster:', cluster || 'volcano_tts');
        console.log('Voice Type:', voice_type || 'zh_female_vv_uranus_bigtts');

        const response = await axios.post(tts_url, requestData, {
            headers: {
                'Authorization': `Bearer;${token}`,
                'Content-Type': 'application/json'
            }
        });

        if (response.data && response.data.data) {
            res.json({ success: true, audio: response.data.data });
        } else {
            console.error('TTS API Error Response:', response.data);
            let msg = response.data.message || `TTS ËΩ¨Êç¢Â§±Ë¥• (Code: ${response.data.code})`;
            if (msg.includes('requested resource not granted')) {
                msg = `ËµÑÊ∫êÊú™ÊéàÊùÉ: ËØ∑Ê£ÄÊü•ÊÇ®ÁöÑ AppID ÊòØÂê¶Â∑≤Âú®ÁÅ´Â±±ÂºïÊìéÊéßÂà∂Âè∞ÂºÄÈÄöÂπ∂ÊéàÊùÉ‰∫Ü Resource ID ‰∏∫ "${cluster || 'volcano_tts'}" ÁöÑÊúçÂä°„ÄÇ`;
            }
            throw new Error(msg);
        }
    } catch (error) {
        const errorDetail = error.response?.data || error.message;
        console.error('TTS Error:', errorDetail);
        res.status(500).json({
            success: false,
            message: typeof errorDetail === 'string' ? errorDetail : (errorDetail.message || 'TTS ËØ∑Ê±ÇÂ§±Ë¥•'),
            detail: errorDetail
        });
    }
});

// ÁÅ´Â±±ÂºïÊìéËØ≠Èü≥ÂêàÊàêÊé•Âè£ (TTS) - ÂçïÂêëÊµÅÂºèÊ®°Âºè (v3 API) - SSE ÂÆûÊó∂Êé®ÈÄÅ
app.get('/api/tts-stream', async (req, res) => {
    let { text, appid, access_key, resource_id, voice_type } = req.query;
    if (!text || !appid || !access_key || !resource_id) {
        return res.status(400).json({ success: false, message: 'Áº∫Â∞ëÂèÇÊï∞: ÈúÄË¶Å appid, access_key, resource_id' });
    }

    // URL Ëß£Á†ÅÂπ∂ÂéªÈô§Á©∫Ê†º
    text = decodeURIComponent(text);
    appid = appid.trim();
    access_key = access_key.trim();
    resource_id = resource_id.trim();
    if (voice_type) voice_type = voice_type.trim();

    // ËÆæÁΩÆ SSE ÂìçÂ∫îÂ§¥
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.flushHeaders();

    try {
        const tts_url = 'https://openspeech.bytedance.com/api/v3/tts/unidirectional';
        const requestData = {
            user: { uid: 'roleplay_user' },
            req_params: {
                text: text,
                speaker: voice_type || 'zh_female_cancan_mars_bigtts',
                audio_params: {
                    format: 'pcm',      // ‰ΩøÁî® PCM Ê†ºÂºè‰æø‰∫éÊµÅÂºèÊí≠Êîæ
                    sample_rate: 24000,
                    enable_timestamp: false
                },
                additions: JSON.stringify({
                    explicit_language: 'zh',
                    disable_markdown_filter: true
                })
            }
        };

        console.log('Submitting TTS stream request to Volcengine (v3 SSE)...');
        console.log('AppID:', appid);
        console.log('Resource ID:', resource_id);
        console.log('Voice Type:', voice_type || 'zh_female_cancan_mars_bigtts');

        const response = await axios.post(tts_url, requestData, {
            headers: {
                'X-Api-App-Id': appid,
                'X-Api-Access-Key': access_key,
                'X-Api-Resource-Id': resource_id,
                'Content-Type': 'application/json',
                'Connection': 'keep-alive'
            },
            responseType: 'stream'
        });

        console.log('TTS Stream Response Status:', response.status);
        console.log('TTS Stream X-Tt-Logid:', response.headers['x-tt-logid']);

        let lineBuffer = '';
        let chunkIndex = 0;

        response.data.on('data', (chunk) => {
            lineBuffer += chunk.toString('utf-8');
            const lines = lineBuffer.split('\n');
            lineBuffer = lines.pop(); // ‰øùÁïôÊúÄÂêé‰∏Ä‰∏™‰∏çÂÆåÊï¥ÁöÑË°å

            for (const line of lines) {
                if (!line.trim()) continue;
                try {
                    const data = JSON.parse(line);
                    if (data.code === 0 && data.data) {
                        // ÂÆûÊó∂Êé®ÈÄÅÈü≥È¢ëÂùóÁªôÂâçÁ´Ø
                        res.write(`data: ${JSON.stringify({ type: 'audio', data: data.data, index: chunkIndex++ })}\n\n`);
                    } else if (data.code === 20000000) {
                        // ÂêàÊàêÂÆåÊàê
                        console.log('TTS Stream completed, total chunks:', chunkIndex);
                        if (data.usage) {
                            console.log('TTS Usage:', data.usage);
                        }
                    } else if (data.code > 0 && data.code !== 20000000) {
                        console.error('TTS Stream error:', data);
                        res.write(`data: ${JSON.stringify({ type: 'error', message: data.message || 'TTS error' })}\n\n`);
                    }
                } catch (e) {
                    console.error('Parse line error:', e.message);
                }
            }
        });

        response.data.on('end', () => {
            // Â§ÑÁêÜÊúÄÂêé‰∏ÄË°å
            if (lineBuffer.trim()) {
                try {
                    const data = JSON.parse(lineBuffer);
                    if (data.code === 0 && data.data) {
                        res.write(`data: ${JSON.stringify({ type: 'audio', data: data.data, index: chunkIndex++ })}\n\n`);
                    }
                } catch (e) {
                    // ignore
                }
            }
            // ÂèëÈÄÅÁªìÊùü‰ø°Âè∑
            res.write(`data: ${JSON.stringify({ type: 'end', totalChunks: chunkIndex })}\n\n`);
            res.end();
        });

        response.data.on('error', (err) => {
            console.error('TTS Stream error:', err);
            res.write(`data: ${JSON.stringify({ type: 'error', message: err.message })}\n\n`);
            res.end();
        });

        // ÂÆ¢Êà∑Á´ØÊñ≠ÂºÄËøûÊé•Êó∂Ê∏ÖÁêÜ
        req.on('close', () => {
            console.log('Client closed SSE connection');
            response.data.destroy();
        });

    } catch (error) {
        const errorDetail = error.response?.data || error.message;
        console.error('TTS Stream Error:', errorDetail);
        res.write(`data: ${JSON.stringify({ type: 'error', message: typeof errorDetail === 'string' ? errorDetail : 'TTS ÊµÅÂºèËØ∑Ê±ÇÂ§±Ë¥•' })}\n\n`);
        res.end();
    }
});

// Volcengine ASR Streaming Protocol Constants
const PROTOCOL_VERSION = 0b0001;
const HEADER_SIZE = 1;
const MESSAGE_TYPE = {
    FULL_CLIENT_REQUEST: 0b0001,
    AUDIO_ONLY_REQUEST: 0b0010,
    FULL_SERVER_RESPONSE: 0b1001,
    SERVER_ERROR_RESPONSE: 0b1111
};
const MESSAGE_FLAGS = {
    NO_SEQUENCE: 0b0000,
    POS_SEQUENCE: 0b0001,
    NEG_SEQUENCE: 0b0010,
    NEG_WITH_SEQUENCE: 0b0011
};
const SERIALIZATION = {
    NO: 0b0000,
    JSON: 0b0001
};
const COMPRESSION = {
    NO: 0b0000,
    GZIP: 0b0001
};

// Protocol Helpers
function constructHeader(msgType, msgFlags, serialization, compression) {
    const header = Buffer.alloc(4);
    header[0] = (PROTOCOL_VERSION << 4) | HEADER_SIZE;
    header[1] = (msgType << 4) | msgFlags;
    header[2] = (serialization << 4) | compression;
    header[3] = 0x00;
    return header;
}

function constructFullRequest(seq, payload) {
    const header = constructHeader(
        MESSAGE_TYPE.FULL_CLIENT_REQUEST,
        MESSAGE_FLAGS.NO_SEQUENCE,
        SERIALIZATION.JSON,
        COMPRESSION.GZIP
    );
    const payloadBytes = Buffer.from(JSON.stringify(payload));
    const compressedPayload = zlib.gzipSync(payloadBytes);
    
    // NO sequence buffer for NO_SEQUENCE flag (matches Python demo)
    
    const sizeBuf = Buffer.alloc(4);
    sizeBuf.writeUInt32BE(compressedPayload.length);
    
    return Buffer.concat([header, sizeBuf, compressedPayload]);
}

function constructAudioRequest(seq, audioData, isLast) {
    const header = constructHeader(
        MESSAGE_TYPE.AUDIO_ONLY_REQUEST,
        isLast ? MESSAGE_FLAGS.NEG_SEQUENCE : MESSAGE_FLAGS.NO_SEQUENCE,
        SERIALIZATION.JSON, // Python demo uses JSON serialization flag even for audio
        COMPRESSION.GZIP
    );
    
    // NO sequence buffer for NO_SEQUENCE or NEG_SEQUENCE flag (matches Python demo)
    
    const compressedAudio = zlib.gzipSync(audioData);
    const sizeBuf = Buffer.alloc(4);
    sizeBuf.writeUInt32BE(compressedAudio.length);
    
    return Buffer.concat([header, sizeBuf, compressedAudio]);
}

function parseResponse(data) {
    if (data.length < 4) return null;
    const headerSize = data[0] & 0x0f;
    const msgType = data[1] >> 4;
    const msgFlags = data[1] & 0x0f;
    const serialization = data[2] >> 4;
    const compression = data[2] & 0x0f;
    
    let offset = headerSize * 4;
    
    // Skip sequence if present
    if ((msgFlags & 0x01) || (msgFlags & 0x03) === 0x03) { // POS_SEQUENCE or NEG_WITH_SEQUENCE
        offset += 4;
    }
    
    // Skip event if present (server implementation detail, usually not present in simple response)
    
    let payloadMsg = null;
    let payloadSize = 0;
    let errorCode = 0;
    
    if (msgType === MESSAGE_TYPE.FULL_SERVER_RESPONSE) {
        payloadSize = data.readUInt32BE(offset);
        offset += 4;
    } else if (msgType === MESSAGE_TYPE.SERVER_ERROR_RESPONSE) {
        errorCode = data.readInt32BE(offset);
        offset += 4;
        payloadSize = data.readUInt32BE(offset);
        offset += 4;
    }
    
    if (payloadSize > 0 && offset + payloadSize <= data.length) {
        let payload = data.subarray(offset, offset + payloadSize);
        try {
            if (compression === COMPRESSION.GZIP) {
                payload = zlib.gunzipSync(payload);
            }
            if (serialization === SERIALIZATION.JSON) {
                payloadMsg = JSON.parse(payload.toString());
            }
        } catch (e) {
            console.error('Payload parse error:', e);
        }
    }
    
    return { msgType, errorCode, payloadMsg };
}

function convertToPcm(inputPath) {
    return new Promise((resolve, reject) => {
        const args = [
            '-i', inputPath,
            '-acodec', 'pcm_s16le',
            '-ac', '1',
            '-ar', '16000',
            '-f', 's16le',
            '-'
        ];
        
        execFile(ffmpegPath, args, { encoding: 'buffer', maxBuffer: 50 * 1024 * 1024 }, (error, stdout, stderr) => {
            if (error) {
                console.error('FFmpeg error:', stderr.toString());
                reject(error);
            } else {
                resolve(stdout);
            }
        });
    });
}

// ÁÅ´Â±±ÂºïÊìéËØ≠Èü≥ËØÜÂà´Êé•Âè£ (ASR) - Streaming WebSocket Implementation
// ÊåâÁÖßÂÆòÊñπ Python Á§∫‰æã (streaming_asr_demo.py) ÂÆûÁé∞
app.post('/api/asr', upload.single('audio'), async (req, res) => {
    const { appid, token, cluster } = req.body;
    const audioFile = req.file;
    const SUCCESS_CODE = 1000;

    if (!audioFile || !appid || !token) {
        return res.status(400).json({ success: false, message: 'Áº∫Â∞ëÂèÇÊï∞' });
    }

    let ws = null;
    try {
        // 1. Convert audio to required format (PCM s16le, 16k, 1ch)
        const pcmBuffer = await convertToPcm(audioFile.path);

        // 2. Setup WebSocket Connection
        let targetResource = cluster || 'volcengine_streaming_common';
        if (targetResource === 'volc_auc_common') {
            targetResource = 'volcengine_streaming_common';
        }

        const wsUrl = `wss://openspeech.bytedance.com/api/v2/asr`;
        const reqId = crypto.randomUUID();

        const headers = {
            "Authorization": `Bearer; ${token.trim()}`
        };

        ws = new WebSocket(wsUrl, { headers });

        // ËæÖÂä©ÂáΩÊï∞ÔºöÁ≠âÂæÖÂπ∂Ëß£Êûê‰∏ÄÊù°Ê∂àÊÅØ
        function waitForMessage(ws, timeoutMs = 10000) {
            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    reject(new Error('Á≠âÂæÖÊúçÂä°Âô®ÂìçÂ∫îË∂ÖÊó∂'));
                }, timeoutMs);

                const onMessage = (data) => {
                    clearTimeout(timeout);
                    ws.off('message', onMessage);
                    ws.off('error', onError);
                    const response = parseResponse(data);
                    resolve(response);
                };

                const onError = (err) => {
                    clearTimeout(timeout);
                    ws.off('message', onMessage);
                    ws.off('error', onError);
                    reject(err);
                };

                ws.on('message', onMessage);
                ws.on('error', onError);
            });
        }

        await new Promise((resolve, reject) => {
            ws.on('open', resolve);
            ws.on('error', reject);
        });

        // 3. Send Full Client Request
        const requestPayload = {
            app: {
                appid: appid.trim(),
                cluster: targetResource,
                token: token.trim()
            },
            user: {
                uid: "roleplay_chat_user"
            },
            request: {
                reqid: reqId,
                nbest: 1,
                workflow: "audio_in,resample,partition,vad,fe,decode,itn,nlu_punctuate",
                show_language: false,
                show_utterances: true,
                result_type: "full",
                sequence: 1
            },
            audio: {
                format: "raw",
                rate: 16000,
                language: "zh-CN",
                bits: 16,
                channel: 1,
                codec: "raw"
            }
        };

        const fullRequest = constructFullRequest(1, requestPayload);
        ws.send(fullRequest);

        // Á≠âÂæÖ Full Request ÁöÑÂìçÂ∫î
        const fullResponse = await waitForMessage(ws);
        if (fullResponse?.payloadMsg?.code !== SUCCESS_CODE) {
            throw new Error(`Full Request failed: code=${fullResponse?.payloadMsg?.code}, message=${fullResponse?.payloadMsg?.message}`);
        }

        // 4. Send Audio Chunks
        const CHUNK_SIZE = 16000 * 2 * 0.1; // 100ms chunks
        let offset = 0;
        let finalResultText = '';
        let seq = 1;

        // ÂàáÂàÜÈü≥È¢ëÊï∞ÊçÆ
        const chunks = [];
        while (offset < pcmBuffer.length) {
            const end = Math.min(offset + CHUNK_SIZE, pcmBuffer.length);
            chunks.push(pcmBuffer.subarray(offset, end));
            offset += CHUNK_SIZE;
        }

        // ÂèëÈÄÅÊØè‰∏™Èü≥È¢ëÂùóÂπ∂Á≠âÂæÖÂìçÂ∫î
        for (let i = 0; i < chunks.length; i++) {
            const chunk = chunks[i];
            const isLast = (i === chunks.length - 1);

            const audioRequest = constructAudioRequest(seq++, chunk, isLast);
            ws.send(audioRequest);

            const audioResponse = await waitForMessage(ws);

            if (audioResponse?.msgType === MESSAGE_TYPE.SERVER_ERROR_RESPONSE) {
                throw new Error(`ASR Server Error: ${audioResponse.errorCode}`);
            }

            if (audioResponse?.payloadMsg) {
                const result = audioResponse.payloadMsg;

                if (result.code !== SUCCESS_CODE) {
                    throw new Error(`Audio chunk failed: code=${result.code}, message=${result.message}`);
                }

                // Êõ¥Êñ∞ÊúÄÁªàÁªìÊûú - result ÊòØÊï∞ÁªÑÊ†ºÂºè
                if (result.result && Array.isArray(result.result) && result.result.length > 0) {
                    const firstResult = result.result[0];
                    if (firstResult.text) {
                        finalResultText = firstResult.text;
                    }
                } else if (result.result && result.result.text) {
                    finalResultText = result.result.text;
                }

                if (result.text && !finalResultText) {
                    finalResultText = result.text;
                }
            }
        }

        // Á≠âÂæÖÊúÄÁªàËØÜÂà´ÁªìÊûú
        let waitCount = 0;
        const MAX_WAIT = 10;

        while (waitCount < MAX_WAIT) {
            try {
                const finalResponse = await waitForMessage(ws, 5000);
                waitCount++;

                if (finalResponse?.payloadMsg) {
                    const result = finalResponse.payloadMsg;

                    if (result.result && Array.isArray(result.result) && result.result.length > 0) {
                        finalResultText = result.result[0].text || finalResultText;
                    }

                    if (result.sequence < 0) {
                        break;
                    }
                }
            } catch (timeoutErr) {
                break;
            }
        }

        ws.close();
        if (fs.existsSync(audioFile.path)) fs.unlinkSync(audioFile.path);

        if (finalResultText) {
            res.json({ success: true, text: finalResultText });
        } else {
            res.status(200).json({ success: true, text: "(Êú™ËØÜÂà´Âà∞ÊúâÊïàËØ≠Èü≥)" });
        }

    } catch (error) {
        console.error('ASR Streaming Error:', error);
        if (ws) {
            try { ws.close(); } catch(e) {}
        }
        if (audioFile && fs.existsSync(audioFile.path)) fs.unlinkSync(audioFile.path);

        res.status(500).json({
            success: false,
            message: 'ËØ≠Èü≥ËØÜÂà´Â§±Ë¥•',
            detail: error.message
        });
    }
});

// ============================================
// MCP ÂçèËÆÆÁ´ØÁÇπ (ÈõÜÊàêÂú®‰∏ªÊúçÂä°Âô®‰∏≠)
// ============================================

// MCP ÊúçÂä°Âô®‰ø°ÊÅØ
const MCP_SERVER_INFO = {
    name: 'text-to-image-server',
    version: '1.0.0',
    protocolVersion: '2024-11-05',
    capabilities: {
        tools: {}
    }
};

// MCP Â∑•ÂÖ∑ÂÆö‰πâ
const MCP_TOOLS = [
    {
        name: 'generate_image',
        description: 'Ê†πÊçÆÊñáÊú¨ÊèèËø∞ÁîüÊàêÂõæÁâá„ÄÇ‰ΩøÁî® Replicate ÁöÑ Realistic Vision v5.1 Ê®°ÂûãÁîüÊàêÈ´òË¥®ÈáèÂÜôÂÆûÈ£éÊ†ºÂõæÂÉè„ÄÇ**ÈáçË¶ÅÔºöprompt ÂøÖÈ°ª‰ΩøÁî®Ëã±ÊñáÊèèËø∞„ÄÇ**',
        inputSchema: {
            type: 'object',
            properties: {
                prompt: {
                    type: 'string',
                    description: 'ÂõæÁâáÊèèËø∞ÊñáÊú¨ÔºàÂøÖÈ°ª‰ΩøÁî®Ëã±ÊñáÔºâ„ÄÇËØ¶ÁªÜÊèèËø∞ÊÉ≥Ë¶ÅÁîüÊàêÁöÑÂõæÁâáÂÜÖÂÆπÔºåÂåÖÊã¨‰∏ª‰Ωì„ÄÅÈ£éÊ†º„ÄÅË¥®ÈáèÁ≠â„ÄÇ'
                },
                negative_prompt: {
                    type: 'string',
                    description: 'Ë¥üÈù¢ÊèêÁ§∫ËØçÔºàËã±ÊñáÔºâÔºåÊèèËø∞‰∏çÊÉ≥Âú®ÂõæÁâá‰∏≠Âá∫Áé∞ÁöÑÂÜÖÂÆπ',
                    default: '(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck'
                },
                width: {
                    type: 'number',
                    description: 'ÂõæÁâáÂÆΩÂ∫¶ÔºàÂÉèÁ¥†Ôºâ',
                    default: 512
                },
                height: {
                    type: 'number',
                    description: 'ÂõæÁâáÈ´òÂ∫¶ÔºàÂÉèÁ¥†Ôºâ',
                    default: 728
                },
                steps: {
                    type: 'number',
                    description: 'Êé®ÁêÜÊ≠•Êï∞ÔºåË∂äÈ´òË¥®ÈáèË∂äÂ•Ω‰ΩÜÈÄüÂ∫¶Ë∂äÊÖ¢',
                    default: 20
                },
                guidance: {
                    type: 'number',
                    description: 'ÂºïÂØºÂº∫Â∫¶ÔºåÊéßÂà∂ÁîüÊàêÂõæÁâá‰∏éÊèêÁ§∫ËØçÁöÑÂåπÈÖçÁ®ãÂ∫¶',
                    default: 5
                }
            },
            required: ['prompt']
        }
    }
];

// MCP ÂçèËÆÆÁ´ØÁÇπÔºöÂàùÂßãÂåñ
app.post('/mcp/initialize', (req, res) => {
    console.log('MCP Initialize request:', req.body);
    res.json({
        protocolVersion: MCP_SERVER_INFO.protocolVersion,
        capabilities: MCP_SERVER_INFO.capabilities,
        serverInfo: {
            name: MCP_SERVER_INFO.name,
            version: MCP_SERVER_INFO.version
        }
    });
});

// MCP ÂçèËÆÆÁ´ØÁÇπÔºöÂàóÂá∫Â∑•ÂÖ∑
app.post('/mcp/tools/list', (req, res) => {
    console.log('MCP Tools list request');
    res.json({
        tools: MCP_TOOLS
    });
});

// MCP ÂçèËÆÆÁ´ØÁÇπÔºöË∞ÉÁî®Â∑•ÂÖ∑
app.post('/mcp/tools/call', async (req, res) => {
    const { name, arguments: args } = req.body.params || req.body;

    console.log('MCP Tool call:', name, args);

    if (name !== 'generate_image') {
        return res.status(400).json({
            error: {
                code: -32601,
                message: `Unknown tool: ${name}`
            }
        });
    }

    try {
        // ‰ªéËØ∑Ê±ÇÂ§¥ÊàñÂèÇÊï∞‰∏≠Ëé∑Âèñ API Token
        const apiToken = req.headers['x-replicate-token'] || args.api_token;

        if (!apiToken) {
            return res.status(400).json({
                error: {
                    code: -32602,
                    message: 'Missing Replicate API token. Please configure it in settings.'
                }
            });
        }

        // Ëé∑ÂèñÊ®°ÂûãÈÖçÁΩÆÔºàMCP ÈªòËÆ§‰ΩøÁî® realistic-vision-v5.1Ôºâ
        const mcpModelConfig = IMAGE_MODELS[args.model] || IMAGE_MODELS['realistic-vision-v5.1'];

        // ÊûÑÂª∫ÂõæÁâáÁîüÊàêËØ∑Ê±ÇÂèÇÊï∞
        let mcpImageInput;
        let mcpApiEndpoint;
        let mcpRequestBody;

        if (mcpModelConfig.useAspectRatio) {
            // Êñ∞Ê®°Âûã‰ΩøÁî® aspect_ratio ÂèÇÊï∞
            mcpImageInput = {
                prompt: args.prompt,
                aspect_ratio: args.aspect_ratio || mcpModelConfig.defaultAspectRatio
            };

            if (mcpModelConfig.creativity !== undefined) {
                mcpImageInput.creativity = args.creativity || mcpModelConfig.creativity;
            }
            if (mcpModelConfig.promptUpsampling !== undefined) {
                mcpImageInput.prompt_upsampling = mcpModelConfig.promptUpsampling;
            }

            if (mcpModelConfig.useModelEndpoint) {
                // p-image ‰ΩøÁî® model endpoint
                mcpApiEndpoint = `https://api.replicate.com/v1/models/${mcpModelConfig.modelEndpoint}/predictions`;
                mcpRequestBody = { input: mcpImageInput };
            } else {
                // qwen-image-fast ‰ΩøÁî® version endpoint
                mcpApiEndpoint = 'https://api.replicate.com/v1/predictions';
                mcpRequestBody = {
                    version: mcpModelConfig.version,
                    input: mcpImageInput
                };
            }
        } else {
            // ‰º†ÁªüÊ®°Âûã‰ΩøÁî® width/height ÂèÇÊï∞
            mcpImageInput = {
                seed: Math.floor(Math.random() * 10000),
                steps: args.steps || mcpModelConfig.steps,
                width: args.width || mcpModelConfig.defaultWidth,
                height: args.height || mcpModelConfig.defaultHeight,
                prompt: args.prompt,
                disable_safety_checker: true,
                negative_prompt: args.negative_prompt || '(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck'
            };

            // Ê∑ªÂä†Ê®°ÂûãÁâπÂÆöÂèÇÊï∞
            if (mcpModelConfig.guidance) {
                mcpImageInput.guidance = args.guidance || mcpModelConfig.guidance;
            }
            if (mcpModelConfig.scheduler) {
                mcpImageInput.scheduler = mcpModelConfig.scheduler;
            }

            mcpApiEndpoint = 'https://api.replicate.com/v1/predictions';
            mcpRequestBody = {
                version: mcpModelConfig.version,
                input: mcpImageInput
            };
        }

        console.log(`MCP ‰ΩøÁî®ÂõæÁâáÊ®°Âûã: ${args.model || 'realistic-vision-v5.1'}`);
        console.log(`MCP API Á´ØÁÇπ: ${mcpApiEndpoint}`);

        // Ë∞ÉÁî® Replicate API
        const response = await axios.post(
            mcpApiEndpoint,
            mcpRequestBody,
            {
                headers: {
                    'Authorization': `Bearer ${apiToken}`,
                    'Content-Type': 'application/json',
                    'Prefer': 'wait'
                },
                timeout: 120000
            }
        );

        const result = response.data;
        console.log('MCP Replicate API response:', JSON.stringify(result, null, 2));

        // Â§ÑÁêÜ‰∏çÂêåÁöÑËæìÂá∫Ê†ºÂºè
        let imageUrl = null;
        if (Array.isArray(result.output) && result.output.length > 0) {
            imageUrl = result.output[0];
        } else if (typeof result.output === 'string') {
            imageUrl = result.output;
        }

        console.log('MCP Extracted imageUrl:', imageUrl);

        if (!imageUrl) {
            throw new Error('No image URL in response');
        }

        res.json({
            content: [
                {
                    type: 'text',
                    text: `ÂõæÁâáÁîüÊàêÊàêÂäüÔºÅ\n\nÊèêÁ§∫ËØç: ${args.prompt}\nÂõæÁâáURL: ${imageUrl}`
                },
                {
                    type: 'image',
                    data: imageUrl,
                    mimeType: 'image/png'
                }
            ]
        });

    } catch (error) {
        console.error('Error generating image:', error.response?.data || error.message);
        res.status(500).json({
            error: {
                code: -32603,
                message: `Failed to generate image: ${error.response?.data?.detail || error.message}`
            }
        });
    }
});

// ============================================
// ÊñáÁîüÂõæ REST API Á´ØÁÇπ
// ============================================

// ÊñáÁîüÂõæÊé•Âè£ (Text-to-Image) - ‰ΩøÁî® Replicate API
app.post('/api/text-to-image', async (req, res) => {
    const { apiToken, prompt, negative_prompt, width, height, num_inference_steps, guidance_scale, model, aspect_ratio, creativity, openrouterApiKey } = req.body;

    if (!apiToken || !prompt) {
        return res.status(400).json({ success: false, message: 'Áº∫Â∞ëÂøÖË¶ÅÂèÇÊï∞ÔºöapiToken Âíå prompt' });
    }

    try {
        // Ê£ÄÊµãÂπ∂ÁøªËØë‰∏≠ÊñáÊèêÁ§∫ËØç
        let finalPrompt = prompt;
        if (containsChinese(prompt)) {
            console.log('Ê£ÄÊµãÂà∞‰∏≠ÊñáÊèêÁ§∫ËØçÔºåÊ≠£Âú®ÁøªËØë‰∏∫Ëã±Êñá...');
            if (openrouterApiKey) {
                finalPrompt = await translateToEnglish(prompt, openrouterApiKey);
                console.log('ÁøªËØëÂêéÁöÑÊèêÁ§∫ËØç:', finalPrompt);
            } else {
                console.warn('Êú™Êèê‰æõ OpenRouter API KeyÔºåÊó†Ê≥ïÁøªËØë‰∏≠ÊñáÊèêÁ§∫ËØç');
            }
        }

        // Ëé∑ÂèñÊ®°ÂûãÈÖçÁΩÆ
        const restModelConfig = IMAGE_MODELS[model] || IMAGE_MODELS['realistic-vision-v5.1'];

        console.log('Submitting text-to-image request to Replicate...');
        console.log('Model:', model || 'realistic-vision-v5.1');
        console.log('Prompt:', finalPrompt);

        // ÊûÑÂª∫ËØ∑Ê±ÇÂèÇÊï∞
        let restImageInput;
        let restApiEndpoint;
        let restRequestBody;

        if (restModelConfig.isFluxFast) {
            // Flux Fast Ê®°Âûã
            restImageInput = {
                seed: -1,
                prompt: finalPrompt,
                disable_safety_checker: true,
                guidance: restModelConfig.guidance,
                image_size: restModelConfig.defaultImageSize,
                speed_mode: restModelConfig.speedMode,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                output_quality: restModelConfig.outputQuality,
                num_inference_steps: num_inference_steps || restModelConfig.numInferenceSteps
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isZImageTurbo) {
            // Z-Image Turbo Ê®°Âûã
            restImageInput = {
                width: width || restModelConfig.defaultWidth,
                height: height || restModelConfig.defaultHeight,
                prompt: finalPrompt,
                disable_safety_checker: true,
                output_format: restModelConfig.outputFormat,
                guidance_scale: restModelConfig.guidanceScale,
                output_quality: restModelConfig.outputQuality,
                num_inference_steps: num_inference_steps || restModelConfig.numInferenceSteps
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isFlux2Pro) {
            // FLUX.2 [pro] Ê®°Âûã
            restImageInput = {
                prompt: finalPrompt,
                resolution: req.body.resolution || restModelConfig.defaultResolution,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                input_images: [],
                output_format: restModelConfig.outputFormat,
                output_quality: restModelConfig.outputQuality,
                safety_tolerance: restModelConfig.safetyTolerance
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isNanoBananaPro) {
            // Nano Banana Pro Ê®°Âûã
            restImageInput = {
                prompt: finalPrompt,
                resolution: req.body.resolution || restModelConfig.defaultResolution,
                image_input: [],
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                safety_filter_level: restModelConfig.safetyFilterLevel
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isGptImage15) {
            // GPT Image 1.5 Ê®°Âûã (OpenAI on Replicate)
            restImageInput = {
                prompt: finalPrompt,
                quality: restModelConfig.quality,
                background: restModelConfig.background,
                moderation: restModelConfig.moderation,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                input_fidelity: restModelConfig.inputFidelity,
                number_of_images: restModelConfig.numberOfImages,
                disable_safety_checker: restModelConfig.disableSafetyChecker ? 1 : 0,
                output_compression: restModelConfig.outputCompression
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isQwenImage) {
            // Qwen Image Ê®°Âûã (ÈÄö‰πâ‰∏áË±°)
            restImageInput = {
                prompt: finalPrompt,
                go_fast: restModelConfig.goFast,
                guidance: restModelConfig.guidance,
                strength: restModelConfig.strength,
                image_size: restModelConfig.imageSize,
                lora_scale: restModelConfig.loraScale,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                enhance_prompt: restModelConfig.enhancePrompt,
                output_quality: restModelConfig.outputQuality,
                negative_prompt: negative_prompt || restModelConfig.negativePrompt,
                disable_safety_checker: restModelConfig.disableSafetyChecker,
                num_inference_steps: num_inference_steps || restModelConfig.numInferenceSteps
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.useAspectRatio) {
            // Êñ∞Ê®°Âûã‰ΩøÁî® aspect_ratio ÂèÇÊï∞ (Â¶Ç qwen-image-fast, p-image)
            restImageInput = {
                prompt: finalPrompt,
                disable_safety_checker: true,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio
            };

            if (restModelConfig.creativity !== undefined) {
                restImageInput.creativity = creativity || restModelConfig.creativity;
            }
            if (restModelConfig.promptUpsampling !== undefined) {
                restImageInput.prompt_upsampling = restModelConfig.promptUpsampling;
            }

            if (restModelConfig.useModelEndpoint) {
                // p-image ‰ΩøÁî® model endpoint
                restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
                restRequestBody = { input: restImageInput };
            } else {
                // qwen-image-fast ‰ΩøÁî® version endpoint
                restApiEndpoint = 'https://api.replicate.com/v1/predictions';
                restRequestBody = {
                    version: restModelConfig.version,
                    input: restImageInput
                };
            }
        } else {
            // ‰º†ÁªüÊ®°Âûã‰ΩøÁî® width/height ÂèÇÊï∞
            restImageInput = {
                seed: Math.floor(Math.random() * 10000),
                steps: num_inference_steps || restModelConfig.steps,
                width: width || restModelConfig.defaultWidth,
                height: height || restModelConfig.defaultHeight,
                prompt: finalPrompt,
                negative_prompt: negative_prompt || '(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck',
                disable_safety_checker: true
            };

            // Ê∑ªÂä†Ê®°ÂûãÁâπÂÆöÂèÇÊï∞
            if (restModelConfig.guidance) {
                restImageInput.guidance = guidance_scale || restModelConfig.guidance;
            }
            if (restModelConfig.scheduler) {
                restImageInput.scheduler = restModelConfig.scheduler;
            }

            restApiEndpoint = 'https://api.replicate.com/v1/predictions';
            restRequestBody = {
                version: restModelConfig.version,
                input: restImageInput
            };
        }

        console.log(`API Á´ØÁÇπ: ${restApiEndpoint}`);

        const response = await axios.post(
            restApiEndpoint,
            restRequestBody,
            {
                headers: {
                    'Authorization': `Bearer ${apiToken}`,
                    'Content-Type': 'application/json',
                    'Prefer': 'wait'
                },
                timeout: 240000 // 240ÁßíË∂ÖÊó∂
            }
        );

        const result = response.data;
        console.log('Replicate response status:', result.status);

        if (result.status === 'succeeded' && result.output) {
            // output ÂèØËÉΩÊòØÊï∞ÁªÑÊàñÂçï‰∏™Â≠óÁ¨¶‰∏≤
            const imageUrl = Array.isArray(result.output) ? result.output[0] : result.output;
            console.log('Extracted imageUrl:', imageUrl);
            res.json({
                success: true,
                imageUrl: imageUrl,
                prompt: finalPrompt,
                originalPrompt: prompt // ‰øùÁïôÂéüÂßãÊèêÁ§∫ËØç‰æõÂèÇËÄÉ
            });
        } else if (result.status === 'processing') {
            // Â¶ÇÊûúËøòÂú®Â§ÑÁêÜ‰∏≠ÔºåËøîÂõûÈ¢ÑÊµãID‰æõËΩÆËØ¢
            res.json({
                success: false,
                processing: true,
                predictionId: result.id,
                message: 'ÂõæÁâáÁîüÊàê‰∏≠ÔºåËØ∑Á®çÂêéÊü•ËØ¢ÁªìÊûú'
            });
        } else {
            throw new Error(`Image generation failed with status: ${result.status}`);
        }

    } catch (error) {
        const errorDetail = error.response?.data || error.message;
        console.error('Text-to-Image Error:', errorDetail);
        res.status(500).json({
            success: false,
            message: 'ÂõæÁâáÁîüÊàêÂ§±Ë¥•',
            detail: typeof errorDetail === 'string' ? errorDetail : JSON.stringify(errorDetail)
        });
    }
});

// ÂêØÂä® HTTP ÊúçÂä°Âô®
app.listen(PORT, () => {
    console.log(`HTTP ÊúçÂä°Âô®ËøêË°åÂú® http://localhost:${PORT}`);
});

// ÂêØÂä® HTTPS ÊúçÂä°Âô®ÔºàÂ¶ÇÊûúÂ≠òÂú® SSL ËØÅ‰π¶Ôºâ
if (fs.existsSync(SSL_KEY_PATH) && fs.existsSync(SSL_CERT_PATH)) {
    try {
        const sslOptions = {
            key: fs.readFileSync(SSL_KEY_PATH),
            cert: fs.readFileSync(SSL_CERT_PATH)
        };

        https.createServer(sslOptions, app).listen(HTTPS_PORT, () => {
            console.log(`HTTPS ÊúçÂä°Âô®ËøêË°åÂú® https://0.0.0.0:${HTTPS_PORT}`);
        });
    } catch (error) {
        console.error('ÂêØÂä® HTTPS ÊúçÂä°Âô®Â§±Ë¥•:', error.message);
        console.log('ËØ∑Á°Æ‰øù SSL ËØÅ‰π¶Êñá‰ª∂Ê†ºÂºèÊ≠£Á°Æ');
    }
} else {
    console.log('Êú™ÊâæÂà∞ SSL ËØÅ‰π¶Êñá‰ª∂ÔºåHTTPS ÊúçÂä°Âô®Êú™ÂêØÂä®');
    console.log(`ËØ∑Â∞ÜËØÅ‰π¶Êñá‰ª∂ÊîæÁΩÆÂà∞Ôºö`);
    console.log(`  - ÁßÅÈí•: ${SSL_KEY_PATH}`);
    console.log(`  - ËØÅ‰π¶: ${SSL_CERT_PATH}`);
}
