const express = require('express');
const bodyParser = require('body-parser');
const path = require('path');
const multer = require('multer');
const axios = require('axios');
const fs = require('fs');
const crypto = require('crypto');
const WebSocket = require('ws');
const zlib = require('zlib');
const { execFile } = require('child_process');
const ffmpegPath = require('ffmpeg-static');
const https = require('https');

const app = express();
const upload = multer({ dest: 'uploads/' });
const PORT = 3000;
const HTTPS_PORT = 443;

// æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
function containsChinese(text) {
    return /[\u4e00-\u9fa5]/.test(text);
}

// ä½¿ç”¨ LLM å°†ä¸­æ–‡æç¤ºè¯ç¿»è¯‘æˆè‹±æ–‡
async function translateToEnglish(text, apiKey, model) {
    try {
        const response = await axios.post('https://openrouter.ai/api/v1/chat/completions', {
            model: model || 'google/gemini-2.0-flash-001',
            messages: [{
                role: 'user',
                content: `Translate the following image generation prompt to English. Output ONLY the English translation, nothing else. Keep the same level of detail and artistic style descriptions.

Text to translate:
${text}`
            }]
        }, {
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json'
            }
        });

        const translatedText = response.data.choices?.[0]?.message?.content;
        if (translatedText && !containsChinese(translatedText)) {
            console.log('Successfully translated prompt to English');
            return translatedText.trim();
        }
        return text; // å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œè¿”å›åŸæ–‡
    } catch (error) {
        console.error('Translation error:', error.message);
        return text; // ç¿»è¯‘å¤±è´¥æ—¶è¿”å›åŸæ–‡
    }
}

// SSL è¯ä¹¦é…ç½®
const SSL_KEY_PATH = path.join(__dirname, 'ssl', 'webroleplay.xyz.key');
const SSL_CERT_PATH = path.join(__dirname, 'ssl', 'webroleplay.xyz.pem');

app.use(bodyParser.json());
app.use(express.static(path.join(__dirname, 'public')));

// æä¾› Whisper æ¨¡å‹æ–‡ä»¶ (æœ¬åœ° ASR)
app.use('/models', express.static(path.join(__dirname, 'models'), {
    setHeaders: (res, path) => {
        // å…è®¸è·¨åŸŸè®¿é—®
        res.set('Access-Control-Allow-Origin', '*');
        // ONNX æ–‡ä»¶éœ€è¦æ­£ç¡®çš„ MIME ç±»å‹
        if (path.endsWith('.onnx')) {
            res.set('Content-Type', 'application/octet-stream');
        }
    }
}));

// æœåŠ¡ä¸»é¡µé¢
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'index.html'));
});

// å®šä¹‰æ–‡ç”Ÿå›¾å·¥å…·ï¼ˆä¾› LLM è°ƒç”¨ï¼‰
const TEXT_TO_IMAGE_TOOL = {
    type: 'function',
    function: {
        name: 'generate_image',
        description: 'æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾ç‰‡ã€‚å½“ç”¨æˆ·è¦æ±‚ç”Ÿæˆã€åˆ›å»ºã€ç”»å›¾ç‰‡æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚**é‡è¦ï¼šprompt å¿…é¡»ä½¿ç”¨è‹±æ–‡æè¿°ï¼Œå¦‚æœç”¨æˆ·æä¾›ä¸­æ–‡æè¿°ï¼Œä½ éœ€è¦å…ˆå°†å…¶ç¿»è¯‘æˆè¯¦ç»†çš„è‹±æ–‡æç¤ºè¯ã€‚**',
        parameters: {
            type: 'object',
            properties: {
                prompt: {
                    type: 'string',
                    description: 'å›¾ç‰‡æè¿°æ–‡æœ¬ï¼ˆå¿…é¡»ä½¿ç”¨è‹±æ–‡ï¼‰ã€‚è¯¦ç»†æè¿°æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€é£æ ¼ç­‰ã€‚ä¾‹å¦‚ï¼š"A cute cat sitting on clouds"ã€‚å¦‚æœç”¨æˆ·æä¾›ä¸­æ–‡æè¿°ï¼Œè¯·å…ˆç¿»è¯‘æˆè‹±æ–‡ã€‚'
                },
                negative_prompt: {
                    type: 'string',
                    description: 'ä¸éœ€è¦ç»™è´Ÿé¢æè¿°è¯ã€‚',
                    default: ''
                },
                width: {
                    type: 'number',
                    description: 'å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤ 512',
                    default: 512,
                    enum: [512, 768, 1024]
                },
                height: {
                    type: 'number',
                    description: 'å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤ 728',
                    default: 728,
                    enum: [512, 728, 768, 1024]
                }
            },
            required: ['prompt']
        }
    }
};

// å›¾ç‰‡ç”Ÿæˆæ¨¡å‹é…ç½®
const IMAGE_MODELS = {
    'realistic-vision-v5.1': {
        version: 'lucataco/realistic-vision-v5.1:2c8e954decbf70b7607a4414e5785ef9e4de4b8c51d50fb8b8b349160e0ef6bb',
        defaultWidth: 512,
        defaultHeight: 512,
        steps: 20,
        guidance: 5,
        scheduler: 'EulerA'
    },
    'realvisxl-v3.0-turbo': {
        version: 'adirik/realvisxl-v3.0-turbo:3dc73c805b11b4b01a60555e532fd3ab3f0e60d26f6584d9b8ba7e1b95858243',
        defaultWidth: 768,
        defaultHeight: 768,
        steps: 25,
        guidance: 2,
        scheduler: 'DPM++_SDE_Karras'
    },
    'dreamshaper-xl-turbo': {
        version: 'lucataco/dreamshaper-xl-turbo:0a1710e0187b01a255302738ca0158ff02a22f4638679533e111082f9dd1b615',
        defaultWidth: 1024,
        defaultHeight: 1024,
        steps: 7,           // Turbo æ¨¡å‹åªéœ€è¦ 7 æ­¥
        guidance: 2,        // ä½ guidance æ•ˆæœæ›´å¥½
        scheduler: 'K_EULER'  // å¿…é¡»æŒ‡å®šè°ƒåº¦å™¨
    },
    'qwen-image-fast': {
        version: 'prunaai/qwen-image-fast:01b324d214eb4870ff424dc4215c067759c4c01a8751e327a434e2b16054db2f',
        defaultAspectRatio: '1:1',
        creativity: 0.62,
        disable_safety_checker: true,
        useAspectRatio: true  // æ ‡è®°ä½¿ç”¨ aspect_ratio è€Œé width/height
    },
    'p-image': {
        modelEndpoint: 'prunaai/p-image',  // ä½¿ç”¨ model endpoint è€Œé version
        defaultAspectRatio: '16:9',
        promptUpsampling: false,
        useAspectRatio: true,
        disable_safety_checker: true,
        useModelEndpoint: true  // æ ‡è®°ä½¿ç”¨ model endpoint
    },
    'flux-fast': {
        modelEndpoint: 'prunaai/flux-fast',  // ä½¿ç”¨ model endpoint
        defaultImageSize: 1024,
        defaultAspectRatio: '1:1',
        guidance: 3.5,
        speedMode: 'Extra Juiced ğŸ”¥ (more speed)',
        outputFormat: 'jpg',
        outputQuality: 80,
        numInferenceSteps: 28,
        useModelEndpoint: true,
        isFluxFast: true  // æ ‡è®°ä¸º flux-fast æ¨¡å‹
    },
    'z-image-turbo': {
        modelEndpoint: 'prunaai/z-image-turbo',  // ä½¿ç”¨ model endpoint
        defaultWidth: 1024,
        defaultHeight: 768,
        guidanceScale: 0,
        outputFormat: 'jpg',
        outputQuality: 80,
        numInferenceSteps: 8,
        useModelEndpoint: true,
        isZImageTurbo: true  // æ ‡è®°ä¸º z-image-turbo æ¨¡å‹
    },
    'flux-2-pro': {
        modelEndpoint: 'black-forest-labs/flux-2-pro',  // ä½¿ç”¨ model endpoint
        defaultResolution: '1 MP',
        defaultAspectRatio: '1:1',
        outputFormat: 'webp',
        outputQuality: 80,
        safetyTolerance: 5,
        useModelEndpoint: true,
        isFlux2Pro: true  // æ ‡è®°ä¸º flux-2-pro æ¨¡å‹
    },
    'nano-banana-pro': {
        modelEndpoint: 'google/nano-banana-pro',  // ä½¿ç”¨ model endpoint
        defaultResolution: '2K',
        defaultAspectRatio: '4:3',
        outputFormat: 'png',
        safetyFilterLevel: 'block_only_high',
        useModelEndpoint: true,
        isNanoBananaPro: true  // æ ‡è®°ä¸º nano-banana-pro æ¨¡å‹
    },
    'gpt-image-1.5': {
        modelEndpoint: 'openai/gpt-image-1.5',  // ä½¿ç”¨ model endpoint
        defaultAspectRatio: '1:1',
        quality: 'high',
        background: 'auto',
        moderation: 'auto',
        outputFormat: 'webp',
        outputCompression: 90,
        inputFidelity: 'low',
        numberOfImages: 1,
        disableSafetyChecker: true,
        useModelEndpoint: true,
        isGptImage15: true  // æ ‡è®°ä¸º gpt-image-1.5 æ¨¡å‹
    },
    'qwen-image': {
        modelEndpoint: 'qwen/qwen-image',  // ä½¿ç”¨ model endpoint
        defaultAspectRatio: '16:9',
        goFast: true,
        guidance: 4,
        strength: 0.9,
        imageSize: 'optimize_for_quality',
        loraScale: 1,
        outputFormat: 'webp',
        enhancePrompt: false,
        outputQuality: 80,
        negativePrompt: ' ',
        disableSafetyChecker: true,
        numInferenceSteps: 50,
        useModelEndpoint: true,
        isQwenImage: true  // æ ‡è®°ä¸º qwen-image æ¨¡å‹
    }
};

// LLM ä»£ç†æ¥å£ - è§£å†³å‰ç«¯ç›´æ¥è°ƒç”¨ OpenRouter çš„ CORS å’Œèº«ä»½éªŒè¯é—®é¢˜
// æ”¯æŒ function callingï¼ˆå·¥å…·è°ƒç”¨ï¼‰
app.post('/api/proxy-llm', async (req, res) => {
    const { apiKey, model, messages, response_format, tools, tool_choice, replicateToken, replicateModel } = req.body;
    if (!apiKey || !model || !messages) {
        return res.status(400).json({ success: false, message: 'ç¼ºå°‘å¿…è¦å‚æ•°' });
    }

    // è·å–å›¾ç‰‡æ¨¡å‹é…ç½®
    const imageModelConfig = IMAGE_MODELS[replicateModel] || IMAGE_MODELS['realistic-vision-v5.1'];

    try {
        // æ„å»ºè¯·æ±‚å‚æ•°
        const requestBody = {
            model,
            messages,
            response_format
        };

        // å¦‚æœæä¾›äº†å·¥å…·ï¼Œæ·»åŠ åˆ°è¯·æ±‚ä¸­
        if (tools && tools.length > 0) {
            requestBody.tools = tools;
            if (tool_choice) {
                requestBody.tool_choice = tool_choice;
            }
        }

        const response = await axios.post('https://openrouter.ai/api/v1/chat/completions', requestBody, {
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json',
                'HTTP-Referer': 'https://github.com/Roo-Code/Roo-Code',
                'X-Title': 'RolePlay Chat'
            }
        });

        const data = response.data;

        // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if (data.choices && data.choices[0].message.tool_calls) {
            const toolCalls = data.choices[0].message.tool_calls;
            const toolResults = [];

            // å¤„ç†æ¯ä¸ªå·¥å…·è°ƒç”¨
            for (const toolCall of toolCalls) {
                if (toolCall.function.name === 'generate_image') {
                    try {
                        const args = JSON.parse(toolCall.function.arguments);

                        if (!replicateToken) {
                            toolResults.push({
                                tool_call_id: toolCall.id,
                                role: 'tool',
                                name: 'generate_image',
                                content: JSON.stringify({
                                    error: 'æœªé…ç½® Replicate API Tokenï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®'
                                })
                            });
                            continue;
                        }

                        // æ„å»ºå›¾ç‰‡ç”Ÿæˆè¯·æ±‚å‚æ•°
                        let imageInput;
                        let apiEndpoint;
                        let requestBody;

                        if (imageModelConfig.isFluxFast) {
                            // Flux Fast æ¨¡å‹
                            imageInput = {
                                seed: -1,
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                guidance: imageModelConfig.guidance,
                                image_size: imageModelConfig.defaultImageSize,
                                speed_mode: imageModelConfig.speedMode,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                output_quality: imageModelConfig.outputQuality,
                                num_inference_steps: imageModelConfig.numInferenceSteps
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isZImageTurbo) {
                            // Z-Image Turbo æ¨¡å‹
                            imageInput = {
                                width: args.width || imageModelConfig.defaultWidth,
                                height: args.height || imageModelConfig.defaultHeight,
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                output_format: imageModelConfig.outputFormat,
                                guidance_scale: imageModelConfig.guidanceScale,
                                output_quality: imageModelConfig.outputQuality,
                                num_inference_steps: imageModelConfig.numInferenceSteps
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isFlux2Pro) {
                            // FLUX.2 [pro] æ¨¡å‹
                            imageInput = {
                                prompt: args.prompt,
                                resolution: args.resolution || imageModelConfig.defaultResolution,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                input_images: [],
                                output_format: imageModelConfig.outputFormat,
                                output_quality: imageModelConfig.outputQuality,
                                safety_tolerance: imageModelConfig.safetyTolerance
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isNanoBananaPro) {
                            // Nano Banana Pro æ¨¡å‹
                            imageInput = {
                                prompt: args.prompt,
                                resolution: args.resolution || imageModelConfig.defaultResolution,
                                image_input: [],
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                safety_filter_level: imageModelConfig.safetyFilterLevel
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isGptImage15) {
                            // GPT Image 1.5 æ¨¡å‹ (OpenAI on Replicate)
                            imageInput = {
                                prompt: args.prompt,
                                quality: imageModelConfig.quality,
                                background: imageModelConfig.background,
                                moderation: imageModelConfig.moderation,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                input_fidelity: imageModelConfig.inputFidelity,
                                number_of_images: imageModelConfig.numberOfImages,
                                disable_safety_checker: imageModelConfig.disableSafetyChecker ? 1 : 0,
                                output_compression: imageModelConfig.outputCompression
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.isQwenImage) {
                            // Qwen Image æ¨¡å‹ (é€šä¹‰ä¸‡è±¡)
                            imageInput = {
                                prompt: args.prompt,
                                go_fast: imageModelConfig.goFast,
                                guidance: imageModelConfig.guidance,
                                strength: imageModelConfig.strength,
                                image_size: imageModelConfig.imageSize,
                                lora_scale: imageModelConfig.loraScale,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio,
                                output_format: imageModelConfig.outputFormat,
                                enhance_prompt: imageModelConfig.enhancePrompt,
                                output_quality: imageModelConfig.outputQuality,
                                disable_safety_checker: imageModelConfig.disableSafetyChecker,
                                num_inference_steps: imageModelConfig.numInferenceSteps
                            };
                            apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                            requestBody = { input: imageInput };
                        } else if (imageModelConfig.useAspectRatio) {
                            // æ–°æ¨¡å‹ä½¿ç”¨ aspect_ratio å‚æ•° (å¦‚ qwen-image-fast, p-image)
                            imageInput = {
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                aspect_ratio: args.aspect_ratio || imageModelConfig.defaultAspectRatio
                            };

                            if (imageModelConfig.creativity !== undefined) {
                                imageInput.creativity = args.creativity || imageModelConfig.creativity;
                            }
                            if (imageModelConfig.promptUpsampling !== undefined) {
                                imageInput.prompt_upsampling = imageModelConfig.promptUpsampling;
                            }

                            if (imageModelConfig.useModelEndpoint) {
                                // p-image ä½¿ç”¨ model endpoint
                                apiEndpoint = `https://api.replicate.com/v1/models/${imageModelConfig.modelEndpoint}/predictions`;
                                requestBody = { input: imageInput };
                            } else {
                                // qwen-image-fast ä½¿ç”¨ version endpoint
                                apiEndpoint = 'https://api.replicate.com/v1/predictions';
                                requestBody = {
                                    version: imageModelConfig.version,
                                    input: imageInput
                                };
                            }
                        } else {
                            // ä¼ ç»Ÿæ¨¡å‹ä½¿ç”¨ width/height å‚æ•°
                            imageInput = {
                                seed: Math.floor(Math.random() * 10000),
                                steps: imageModelConfig.steps,
                                width: args.width || imageModelConfig.defaultWidth,
                                height: args.height || imageModelConfig.defaultHeight,
                                prompt: args.prompt,
                                disable_safety_checker: true,
                                negative_prompt: args.negative_prompt || '(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck'
                            };

                            // æ·»åŠ æ¨¡å‹ç‰¹å®šå‚æ•°
                            if (imageModelConfig.guidance) {
                                imageInput.guidance = imageModelConfig.guidance;
                            }
                            if (imageModelConfig.scheduler) {
                                imageInput.scheduler = imageModelConfig.scheduler;
                            }

                            apiEndpoint = 'https://api.replicate.com/v1/predictions';
                            requestBody = {
                                version: imageModelConfig.version,
                                input: imageInput
                            };
                        }

                        console.log(`ä½¿ç”¨å›¾ç‰‡æ¨¡å‹: ${replicateModel || 'realistic-vision-v5.1'}`);
                        console.log(`API ç«¯ç‚¹: ${apiEndpoint}`);

                        // è°ƒç”¨ Replicate API ç”Ÿæˆå›¾ç‰‡
                        const imageResponse = await axios.post(
                            apiEndpoint,
                            requestBody,
                            {
                                headers: {
                                    'Authorization': `Bearer ${replicateToken}`,
                                    'Content-Type': 'application/json',
                                    'Prefer': 'wait'
                                },
                                timeout: 120000
                            }
                        );

                        // è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹ Replicate API çš„å“åº”
                        console.log('Replicate API response:', JSON.stringify(imageResponse.data, null, 2));

                        // å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼
                        let imageUrl = null;
                        const output = imageResponse.data.output;
                        if (Array.isArray(output) && output.length > 0) {
                            imageUrl = output[0];
                        } else if (typeof output === 'string') {
                            imageUrl = output;
                        }

                        console.log('Extracted imageUrl:', imageUrl);

                        if (!imageUrl) {
                            throw new Error('No image URL in response');
                        }

                        toolResults.push({
                            tool_call_id: toolCall.id,
                            role: 'tool',
                            name: 'generate_image',
                            content: JSON.stringify({
                                success: true,
                                imageUrl: imageUrl,
                                prompt: args.prompt
                            })
                        });

                    } catch (error) {
                        console.error('Image generation error:', error.response?.data || error.message);
                        toolResults.push({
                            tool_call_id: toolCall.id,
                            role: 'tool',
                            name: 'generate_image',
                            content: JSON.stringify({
                                error: `å›¾ç‰‡ç”Ÿæˆå¤±è´¥: ${error.response?.data?.detail || error.message}`
                            })
                        });
                    }
                }
            }

            // è¿”å›å·¥å…·è°ƒç”¨ç»“æœï¼Œè®©å‰ç«¯ç»§ç»­å¯¹è¯
            data.tool_results = toolResults;
        }

        res.json(data);
    } catch (error) {
        console.error('LLM Proxy Error:', error.response?.data || error.message);
        res.status(error.response?.status || 500).json(error.response?.data || { message: error.message });
    }
});

// ç«å±±å¼•æ“è¯­éŸ³åˆæˆæ¥å£ (TTS) - æ™®é€šæ¨¡å¼ (v1 API)
app.post('/api/tts', async (req, res) => {
    let { text, appid, token, cluster, voice_type } = req.body;
    if (!text || !appid || !token) {
        return res.status(400).json({ success: false, message: 'ç¼ºå°‘å‚æ•°' });
    }

    // å»é™¤å¯èƒ½å­˜åœ¨çš„ç©ºæ ¼
    appid = appid.trim();
    token = token.trim();
    if (cluster) cluster = cluster.trim();
    if (voice_type) voice_type = voice_type.trim();

    try {
        const tts_url = 'https://openspeech.bytedance.com/api/v1/tts';
        const requestData = {
            app: { appid, token, cluster: cluster || 'volcano_tts' },
            user: { uid: 'roleplay_user' },
            audio: {
                voice_type: voice_type || 'zh_female_vv_uranus_bigtts',
                encoding: 'mp3',
                speed_ratio: 1.0,
                volume_ratio: 1.0,
                pitch_ratio: 1.0,
            },
            request: {
                reqid: crypto.randomUUID(),
                text: text,
                text_type: 'plain',
                operation: 'query',
            }
        };

        console.log('Submitting TTS request to Volcengine (v1)...');
        console.log('AppID:', appid);
        console.log('Cluster:', cluster || 'volcano_tts');
        console.log('Voice Type:', voice_type || 'zh_female_vv_uranus_bigtts');

        const response = await axios.post(tts_url, requestData, {
            headers: {
                'Authorization': `Bearer;${token}`,
                'Content-Type': 'application/json'
            }
        });

        if (response.data && response.data.data) {
            res.json({ success: true, audio: response.data.data });
        } else {
            console.error('TTS API Error Response:', response.data);
            let msg = response.data.message || `TTS è½¬æ¢å¤±è´¥ (Code: ${response.data.code})`;
            if (msg.includes('requested resource not granted')) {
                msg = `èµ„æºæœªæˆæƒ: è¯·æ£€æŸ¥æ‚¨çš„ AppID æ˜¯å¦å·²åœ¨ç«å±±å¼•æ“æ§åˆ¶å°å¼€é€šå¹¶æˆæƒäº† Resource ID ä¸º "${cluster || 'volcano_tts'}" çš„æœåŠ¡ã€‚`;
            }
            throw new Error(msg);
        }
    } catch (error) {
        const errorDetail = error.response?.data || error.message;
        console.error('TTS Error:', errorDetail);
        res.status(500).json({
            success: false,
            message: typeof errorDetail === 'string' ? errorDetail : (errorDetail.message || 'TTS è¯·æ±‚å¤±è´¥'),
            detail: errorDetail
        });
    }
});

// ç«å±±å¼•æ“è¯­éŸ³åˆæˆæ¥å£ (TTS) - å•å‘æµå¼æ¨¡å¼ (v3 API) - SSE å®æ—¶æ¨é€
app.get('/api/tts-stream', async (req, res) => {
    let { text, appid, access_key, resource_id, voice_type } = req.query;
    if (!text || !appid || !access_key || !resource_id) {
        return res.status(400).json({ success: false, message: 'ç¼ºå°‘å‚æ•°: éœ€è¦ appid, access_key, resource_id' });
    }

    // URL è§£ç å¹¶å»é™¤ç©ºæ ¼
    text = decodeURIComponent(text);
    appid = appid.trim();
    access_key = access_key.trim();
    resource_id = resource_id.trim();
    if (voice_type) voice_type = voice_type.trim();

    // è®¾ç½® SSE å“åº”å¤´
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.flushHeaders();

    try {
        const tts_url = 'https://openspeech.bytedance.com/api/v3/tts/unidirectional';
        const requestData = {
            user: { uid: 'roleplay_user' },
            req_params: {
                text: text,
                speaker: voice_type || 'zh_female_cancan_mars_bigtts',
                audio_params: {
                    format: 'pcm',      // ä½¿ç”¨ PCM æ ¼å¼ä¾¿äºæµå¼æ’­æ”¾
                    sample_rate: 24000,
                    enable_timestamp: false
                },
                additions: JSON.stringify({
                    explicit_language: 'zh',
                    disable_markdown_filter: true
                })
            }
        };

        console.log('Submitting TTS stream request to Volcengine (v3 SSE)...');
        console.log('AppID:', appid);
        console.log('Resource ID:', resource_id);
        console.log('Voice Type:', voice_type || 'zh_female_cancan_mars_bigtts');

        const response = await axios.post(tts_url, requestData, {
            headers: {
                'X-Api-App-Id': appid,
                'X-Api-Access-Key': access_key,
                'X-Api-Resource-Id': resource_id,
                'Content-Type': 'application/json',
                'Connection': 'keep-alive'
            },
            responseType: 'stream'
        });

        console.log('TTS Stream Response Status:', response.status);
        console.log('TTS Stream X-Tt-Logid:', response.headers['x-tt-logid']);

        let lineBuffer = '';
        let chunkIndex = 0;

        response.data.on('data', (chunk) => {
            lineBuffer += chunk.toString('utf-8');
            const lines = lineBuffer.split('\n');
            lineBuffer = lines.pop(); // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ

            for (const line of lines) {
                if (!line.trim()) continue;
                try {
                    const data = JSON.parse(line);
                    if (data.code === 0 && data.data) {
                        // å®æ—¶æ¨é€éŸ³é¢‘å—ç»™å‰ç«¯
                        res.write(`data: ${JSON.stringify({ type: 'audio', data: data.data, index: chunkIndex++ })}\n\n`);
                    } else if (data.code === 20000000) {
                        // åˆæˆå®Œæˆ
                        console.log('TTS Stream completed, total chunks:', chunkIndex);
                        if (data.usage) {
                            console.log('TTS Usage:', data.usage);
                        }
                    } else if (data.code > 0 && data.code !== 20000000) {
                        console.error('TTS Stream error:', data);
                        res.write(`data: ${JSON.stringify({ type: 'error', message: data.message || 'TTS error' })}\n\n`);
                    }
                } catch (e) {
                    console.error('Parse line error:', e.message);
                }
            }
        });

        response.data.on('end', () => {
            // å¤„ç†æœ€åä¸€è¡Œ
            if (lineBuffer.trim()) {
                try {
                    const data = JSON.parse(lineBuffer);
                    if (data.code === 0 && data.data) {
                        res.write(`data: ${JSON.stringify({ type: 'audio', data: data.data, index: chunkIndex++ })}\n\n`);
                    }
                } catch (e) {
                    // ignore
                }
            }
            // å‘é€ç»“æŸä¿¡å·
            res.write(`data: ${JSON.stringify({ type: 'end', totalChunks: chunkIndex })}\n\n`);
            res.end();
        });

        response.data.on('error', (err) => {
            console.error('TTS Stream error:', err);
            res.write(`data: ${JSON.stringify({ type: 'error', message: err.message })}\n\n`);
            res.end();
        });

        // å®¢æˆ·ç«¯æ–­å¼€è¿æ¥æ—¶æ¸…ç†
        req.on('close', () => {
            console.log('Client closed SSE connection');
            response.data.destroy();
        });

    } catch (error) {
        const errorDetail = error.response?.data || error.message;
        console.error('TTS Stream Error:', errorDetail);
        res.write(`data: ${JSON.stringify({ type: 'error', message: typeof errorDetail === 'string' ? errorDetail : 'TTS æµå¼è¯·æ±‚å¤±è´¥' })}\n\n`);
        res.end();
    }
});

// Volcengine ASR Streaming Protocol Constants
const PROTOCOL_VERSION = 0b0001;
const HEADER_SIZE = 1;
const MESSAGE_TYPE = {
    FULL_CLIENT_REQUEST: 0b0001,
    AUDIO_ONLY_REQUEST: 0b0010,
    FULL_SERVER_RESPONSE: 0b1001,
    SERVER_ERROR_RESPONSE: 0b1111
};
const MESSAGE_FLAGS = {
    NO_SEQUENCE: 0b0000,
    POS_SEQUENCE: 0b0001,
    NEG_SEQUENCE: 0b0010,
    NEG_WITH_SEQUENCE: 0b0011
};
const SERIALIZATION = {
    NO: 0b0000,
    JSON: 0b0001
};
const COMPRESSION = {
    NO: 0b0000,
    GZIP: 0b0001
};

// Protocol Helpers
function constructHeader(msgType, msgFlags, serialization, compression) {
    const header = Buffer.alloc(4);
    header[0] = (PROTOCOL_VERSION << 4) | HEADER_SIZE;
    header[1] = (msgType << 4) | msgFlags;
    header[2] = (serialization << 4) | compression;
    header[3] = 0x00;
    return header;
}

function constructFullRequest(seq, payload) {
    const header = constructHeader(
        MESSAGE_TYPE.FULL_CLIENT_REQUEST,
        MESSAGE_FLAGS.NO_SEQUENCE,
        SERIALIZATION.JSON,
        COMPRESSION.GZIP
    );
    const payloadBytes = Buffer.from(JSON.stringify(payload));
    const compressedPayload = zlib.gzipSync(payloadBytes);
    
    // NO sequence buffer for NO_SEQUENCE flag (matches Python demo)
    
    const sizeBuf = Buffer.alloc(4);
    sizeBuf.writeUInt32BE(compressedPayload.length);
    
    return Buffer.concat([header, sizeBuf, compressedPayload]);
}

function constructAudioRequest(seq, audioData, isLast) {
    const header = constructHeader(
        MESSAGE_TYPE.AUDIO_ONLY_REQUEST,
        isLast ? MESSAGE_FLAGS.NEG_SEQUENCE : MESSAGE_FLAGS.NO_SEQUENCE,
        SERIALIZATION.JSON, // Python demo uses JSON serialization flag even for audio
        COMPRESSION.GZIP
    );
    
    // NO sequence buffer for NO_SEQUENCE or NEG_SEQUENCE flag (matches Python demo)
    
    const compressedAudio = zlib.gzipSync(audioData);
    const sizeBuf = Buffer.alloc(4);
    sizeBuf.writeUInt32BE(compressedAudio.length);
    
    return Buffer.concat([header, sizeBuf, compressedAudio]);
}

function parseResponse(data) {
    if (data.length < 4) return null;
    const headerSize = data[0] & 0x0f;
    const msgType = data[1] >> 4;
    const msgFlags = data[1] & 0x0f;
    const serialization = data[2] >> 4;
    const compression = data[2] & 0x0f;
    
    let offset = headerSize * 4;
    
    // Skip sequence if present
    if ((msgFlags & 0x01) || (msgFlags & 0x03) === 0x03) { // POS_SEQUENCE or NEG_WITH_SEQUENCE
        offset += 4;
    }
    
    // Skip event if present (server implementation detail, usually not present in simple response)
    
    let payloadMsg = null;
    let payloadSize = 0;
    let errorCode = 0;
    
    if (msgType === MESSAGE_TYPE.FULL_SERVER_RESPONSE) {
        payloadSize = data.readUInt32BE(offset);
        offset += 4;
    } else if (msgType === MESSAGE_TYPE.SERVER_ERROR_RESPONSE) {
        errorCode = data.readInt32BE(offset);
        offset += 4;
        payloadSize = data.readUInt32BE(offset);
        offset += 4;
    }
    
    if (payloadSize > 0 && offset + payloadSize <= data.length) {
        let payload = data.subarray(offset, offset + payloadSize);
        try {
            if (compression === COMPRESSION.GZIP) {
                payload = zlib.gunzipSync(payload);
            }
            if (serialization === SERIALIZATION.JSON) {
                payloadMsg = JSON.parse(payload.toString());
            }
        } catch (e) {
            console.error('Payload parse error:', e);
        }
    }
    
    return { msgType, errorCode, payloadMsg };
}

function convertToPcm(inputPath, originalName) {
    return new Promise((resolve, reject) => {
        // æ ¹æ®åŸå§‹æ–‡ä»¶åç¡®å®šè¾“å…¥æ ¼å¼
        let inputFormat = null;
        if (originalName) {
            if (originalName.includes('webm')) {
                inputFormat = 'webm';
            } else if (originalName.includes('mp4') || originalName.includes('m4a')) {
                inputFormat = 'mp4';
            } else if (originalName.includes('ogg')) {
                inputFormat = 'ogg';
            }
        }

        const args = [];
        // å¦‚æœèƒ½ç¡®å®šæ ¼å¼ï¼Œæ˜ç¡®å‘Šè¯‰ FFmpeg
        if (inputFormat) {
            args.push('-f', inputFormat);
        }
        args.push(
            '-i', inputPath,
            '-acodec', 'pcm_s16le',
            '-ac', '1',
            '-ar', '16000',
            '-f', 's16le',
            '-'
        );

        execFile(ffmpegPath, args, { encoding: 'buffer', maxBuffer: 50 * 1024 * 1024 }, (error, stdout, stderr) => {
            if (error) {
                console.error('FFmpeg error:', stderr.toString());
                reject(error);
            } else {
                resolve(stdout);
            }
        });
    });
}

// ç«å±±å¼•æ“è¯­éŸ³è¯†åˆ«æ¥å£ (ASR) - Streaming WebSocket Implementation
// æŒ‰ç…§å®˜æ–¹ Python ç¤ºä¾‹ (streaming_asr_demo.py) å®ç°
app.post('/api/asr', upload.single('audio'), async (req, res) => {
    const { appid, token, cluster } = req.body;
    const audioFile = req.file;
    const SUCCESS_CODE = 1000;

    // è®¡æ—¶å¯¹è±¡
    const timing = {};
    const totalStartTime = Date.now();

    if (!audioFile || !appid || !token) {
        return res.status(400).json({ success: false, message: 'ç¼ºå°‘å‚æ•°' });
    }

    console.log(`[ASR-Server] ========== å¼€å§‹ASRå¤„ç† ==========`);
    console.log(`[ASR-Server] æ¥æ”¶æ–‡ä»¶å¤§å°: ${(audioFile.size / 1024).toFixed(2)} KB`);
    console.log(`[ASR-Server] åŸå§‹æ–‡ä»¶å: ${audioFile.originalname}`);

    let ws = null;
    try {
        // 1. Convert audio to required format (PCM s16le, 16k, 1ch)
        const ffmpegStartTime = Date.now();
        const pcmBuffer = await convertToPcm(audioFile.path, audioFile.originalname);
        timing.ffmpegConvert = Date.now() - ffmpegStartTime;
        console.log(`[ASR-Server] FFmpegè½¬æ¢è€—æ—¶: ${timing.ffmpegConvert} ms, PCMå¤§å°: ${(pcmBuffer.length / 1024).toFixed(2)} KB`);

        // 2. Setup WebSocket Connection
        let targetResource = cluster || 'volcengine_streaming_common';
        // è¿ç§»æ—§çš„ ASR Resource ID å€¼
        if (targetResource === 'volc_auc_common' || targetResource === 'volc.bigasr.auc') {
            targetResource = 'volcengine_streaming_common';
        }

        const wsUrl = `wss://openspeech.bytedance.com/api/v2/asr`;
        const reqId = crypto.randomUUID();

        const headers = {
            "Authorization": `Bearer; ${token.trim()}`
        };

        const wsConnectStartTime = Date.now();
        ws = new WebSocket(wsUrl, { headers });

        // è¾…åŠ©å‡½æ•°ï¼šç­‰å¾…å¹¶è§£æä¸€æ¡æ¶ˆæ¯
        function waitForMessage(ws, timeoutMs = 10000) {
            return new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    reject(new Error('ç­‰å¾…æœåŠ¡å™¨å“åº”è¶…æ—¶'));
                }, timeoutMs);

                const onMessage = (data) => {
                    clearTimeout(timeout);
                    ws.off('message', onMessage);
                    ws.off('error', onError);
                    const response = parseResponse(data);
                    resolve(response);
                };

                const onError = (err) => {
                    clearTimeout(timeout);
                    ws.off('message', onMessage);
                    ws.off('error', onError);
                    reject(err);
                };

                ws.on('message', onMessage);
                ws.on('error', onError);
            });
        }

        await new Promise((resolve, reject) => {
            ws.on('open', resolve);
            ws.on('error', reject);
        });
        timing.wsConnect = Date.now() - wsConnectStartTime;
        console.log(`[ASR-Server] WebSocketè¿æ¥è€—æ—¶: ${timing.wsConnect} ms`);

        // 3. Send Full Client Request
        const fullRequestStartTime = Date.now();
        const requestPayload = {
            app: {
                appid: appid.trim(),
                cluster: targetResource,
                token: token.trim()
            },
            user: {
                uid: "roleplay_chat_user"
            },
            request: {
                reqid: reqId,
                nbest: 1,
                workflow: "audio_in,resample,partition,vad,fe,decode,itn,nlu_punctuate",
                show_language: false,
                show_utterances: true,
                result_type: "full",
                sequence: 1
            },
            audio: {
                format: "raw",
                rate: 16000,
                language: "zh-CN",
                bits: 16,
                channel: 1,
                codec: "raw"
            }
        };

        const fullRequest = constructFullRequest(1, requestPayload);
        ws.send(fullRequest);

        // ç­‰å¾… Full Request çš„å“åº”
        const fullResponse = await waitForMessage(ws);
        timing.fullRequest = Date.now() - fullRequestStartTime;
        console.log(`[ASR-Server] Full Requestè€—æ—¶: ${timing.fullRequest} ms`);

        if (fullResponse?.payloadMsg?.code !== SUCCESS_CODE) {
            throw new Error(`Full Request failed: code=${fullResponse?.payloadMsg?.code}, message=${fullResponse?.payloadMsg?.message}`);
        }

        // 4. Send Audio Chunks
        const audioChunksStartTime = Date.now();
        const CHUNK_SIZE = 16000 * 2 * 0.1; // 100ms chunks
        let offset = 0;
        let finalResultText = '';
        let seq = 1;
        let receivedFinalResult = false;  // æ ‡è®°æ˜¯å¦å·²æ”¶åˆ°æœ€ç»ˆç»“æœ

        // åˆ‡åˆ†éŸ³é¢‘æ•°æ®
        const chunks = [];
        while (offset < pcmBuffer.length) {
            const end = Math.min(offset + CHUNK_SIZE, pcmBuffer.length);
            chunks.push(pcmBuffer.subarray(offset, end));
            offset += CHUNK_SIZE;
        }
        console.log(`[ASR-Server] éŸ³é¢‘åˆ†å—æ•°: ${chunks.length}, æ¯å— ${CHUNK_SIZE} bytes`);

        // å‘é€æ¯ä¸ªéŸ³é¢‘å—å¹¶ç­‰å¾…å“åº”
        for (let i = 0; i < chunks.length; i++) {
            const chunk = chunks[i];
            const isLast = (i === chunks.length - 1);

            const audioRequest = constructAudioRequest(seq++, chunk, isLast);
            ws.send(audioRequest);

            const audioResponse = await waitForMessage(ws);

            if (audioResponse?.msgType === MESSAGE_TYPE.SERVER_ERROR_RESPONSE) {
                throw new Error(`ASR Server Error: ${audioResponse.errorCode}`);
            }

            if (audioResponse?.payloadMsg) {
                const result = audioResponse.payloadMsg;

                if (result.code !== SUCCESS_CODE) {
                    throw new Error(`Audio chunk failed: code=${result.code}, message=${result.message}`);
                }

                // æ›´æ–°æœ€ç»ˆç»“æœ - result æ˜¯æ•°ç»„æ ¼å¼
                if (result.result && Array.isArray(result.result) && result.result.length > 0) {
                    const firstResult = result.result[0];
                    if (firstResult.text) {
                        finalResultText = firstResult.text;
                    }
                } else if (result.result && result.result.text) {
                    finalResultText = result.result.text;
                }

                if (result.text && !finalResultText) {
                    finalResultText = result.text;
                }

                // æ£€æŸ¥æ˜¯å¦å·²æ”¶åˆ°æœ€ç»ˆç»“æœ (sequence < 0 è¡¨ç¤ºæœ€åä¸€ä¸ªå“åº”)
                if (result.sequence < 0) {
                    receivedFinalResult = true;
                    console.log(`[ASR-Server] åœ¨éŸ³é¢‘å—é˜¶æ®µå·²æ”¶åˆ°æœ€ç»ˆç»“æœ`);
                    break;
                }
            }
        }
        timing.audioChunksSend = Date.now() - audioChunksStartTime;
        console.log(`[ASR-Server] éŸ³é¢‘å—å‘é€+å“åº”è€—æ—¶: ${timing.audioChunksSend} ms`);

        // åªæœ‰åœ¨æœªæ”¶åˆ°æœ€ç»ˆç»“æœæ—¶æ‰ç­‰å¾…
        const finalWaitStartTime = Date.now();
        let waitCount = 0;
        const MAX_WAIT = 10;

        if (!receivedFinalResult) {
            while (waitCount < MAX_WAIT) {
                try {
                    const finalResponse = await waitForMessage(ws, 5000);
                    waitCount++;

                    if (finalResponse?.payloadMsg) {
                        const result = finalResponse.payloadMsg;

                        if (result.result && Array.isArray(result.result) && result.result.length > 0) {
                            finalResultText = result.result[0].text || finalResultText;
                        }

                        if (result.sequence < 0) {
                            break;
                        }
                    }
                } catch (timeoutErr) {
                    break;
                }
            }
        }
        timing.finalWait = Date.now() - finalWaitStartTime;
        console.log(`[ASR-Server] ç­‰å¾…æœ€ç»ˆç»“æœè€—æ—¶: ${timing.finalWait} ms, ç­‰å¾…æ¬¡æ•°: ${waitCount}, å·²åœ¨éŸ³é¢‘é˜¶æ®µå®Œæˆ: ${receivedFinalResult}`);

        ws.close();
        if (fs.existsSync(audioFile.path)) fs.unlinkSync(audioFile.path);

        timing.total = Date.now() - totalStartTime;
        console.log(`[ASR-Server] ========== ASRæ€»è€—æ—¶: ${timing.total} ms ==========`);

        if (finalResultText) {
            res.json({ success: true, text: finalResultText, timing });
        } else {
            res.status(200).json({ success: true, text: "(æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³)", timing });
        }

    } catch (error) {
        console.error('ASR Streaming Error:', error);
        if (ws) {
            try { ws.close(); } catch(e) {}
        }
        if (audioFile && fs.existsSync(audioFile.path)) fs.unlinkSync(audioFile.path);

        timing.total = Date.now() - totalStartTime;
        res.status(500).json({
            success: false,
            message: 'è¯­éŸ³è¯†åˆ«å¤±è´¥',
            detail: error.message,
            timing
        });
    }
});

// ============================================
// å¤§æ¨¡å‹ ASR æ¥å£ (ç«å±±å¼•æ“ BigModel SAUC)
// å‚è€ƒå®˜æ–¹ Python ç¤ºä¾‹ (sauc_websocket_demo.py) å®ç°
// ============================================
app.post('/api/asr-bigmodel', upload.single('audio'), async (req, res) => {
    const { appKey, accessKey } = req.body;
    const audioFile = req.file;

    // è®¡æ—¶å¯¹è±¡
    const timing = {};
    const totalStartTime = Date.now();

    if (!audioFile || !appKey || !accessKey) {
        return res.status(400).json({ success: false, message: 'ç¼ºå°‘å‚æ•° (appKey, accessKey, audio)' });
    }

    console.log(`[BigModel-ASR] ========== å¼€å§‹å¤§æ¨¡å‹ASRå¤„ç† ==========`);
    console.log(`[BigModel-ASR] æ¥æ”¶æ–‡ä»¶å¤§å°: ${(audioFile.size / 1024).toFixed(2)} KB`);
    console.log(`[BigModel-ASR] åŸå§‹æ–‡ä»¶å: ${audioFile.originalname}`);

    let ws = null;
    try {
        // 1. è½¬æ¢éŸ³é¢‘ä¸º WAV æ ¼å¼ (PCM s16le, 16k, 1ch)
        const ffmpegStartTime = Date.now();
        const wavBuffer = await convertToWav(audioFile.path, audioFile.originalname);
        timing.ffmpegConvert = Date.now() - ffmpegStartTime;
        console.log(`[BigModel-ASR] FFmpegè½¬æ¢è€—æ—¶: ${timing.ffmpegConvert} ms, WAVå¤§å°: ${(wavBuffer.length / 1024).toFixed(2)} KB`);

        // 2. å»ºç«‹ WebSocket è¿æ¥
        // æ”¯æŒä¸‰ç§æ¨¡å¼: bigmodel (æµå¼), bigmodel_async (å¼‚æ­¥), bigmodel_nostream (éæµå¼)
        const wsUrl = 'wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_nostream';
        const reqId = crypto.randomUUID();

        // æŒ‰ç…§Python SDKçš„headeré¡ºåºæ„å»º
        const headers = {
            "X-Api-Resource-Id": "volc.bigasr.sauc.duration",
            "X-Api-Request-Id": reqId,
            "X-Api-Access-Key": accessKey.trim(),
            "X-Api-App-Key": appKey.trim()
        };

        console.log(`[BigModel-ASR] è¿æ¥ WebSocket: ${wsUrl}`);
        console.log(`[BigModel-ASR] Request-Id: ${reqId}`);
        console.log(`[BigModel-ASR] App-Key: ${appKey.trim().substring(0, 8)}...`);
        console.log(`[BigModel-ASR] Access-Key: ${accessKey.trim().substring(0, 8)}...`);
        const wsConnectStartTime = Date.now();
        ws = new WebSocket(wsUrl, { headers });

        await new Promise((resolve, reject) => {
            ws.on('open', resolve);
            ws.on('error', (err) => {
                reject(err);
            });
            // æ•è· 403 ç­‰ HTTP é”™è¯¯çš„è¯¦ç»†ä¿¡æ¯
            ws.on('unexpected-response', (request, response) => {
                let body = '';
                response.on('data', chunk => body += chunk.toString());
                response.on('end', () => {
                    console.error(`[BigModel-ASR] HTTP Error ${response.statusCode}: ${body}`);
                    reject(new Error(`HTTP ${response.statusCode}: ${body || response.statusMessage}`));
                });
            });
        });
        timing.wsConnect = Date.now() - wsConnectStartTime;
        console.log(`[BigModel-ASR] WebSocketè¿æ¥è€—æ—¶: ${timing.wsConnect} ms`);

        // 3. å‘é€ Full Client Request
        const fullRequestStartTime = Date.now();
        const fullRequest = constructBigmodelFullRequest(1);
        ws.send(fullRequest);

        // ç­‰å¾… Full Request å“åº”
        const fullResponse = await waitForBigmodelMessage(ws);
        timing.fullRequest = Date.now() - fullRequestStartTime;
        console.log(`[BigModel-ASR] Full Requestè€—æ—¶: ${timing.fullRequest} ms`);

        if (fullResponse?.payloadMsg?.code !== 0) {
            throw new Error(`Full Request failed: code=${fullResponse?.payloadMsg?.code}, message=${JSON.stringify(fullResponse?.payloadMsg)}`);
        }

        // 4. åˆ†æ®µå‘é€éŸ³é¢‘æ•°æ®
        const audioChunksStartTime = Date.now();
        const SEGMENT_DURATION_MS = 200; // æ¯æ®µ 200ms
        const BYTES_PER_SECOND = 16000 * 2 * 1; // 16kHz, 16bit, 1ch
        const SEGMENT_SIZE = Math.floor(BYTES_PER_SECOND * SEGMENT_DURATION_MS / 1000);

        let offset = 0;
        let seq = 1;
        let finalResultText = '';
        const chunks = [];

        // è·³è¿‡ WAV å¤´éƒ¨ (44 bytes)
        const audioData = wavBuffer.slice(44);

        while (offset < audioData.length) {
            const end = Math.min(offset + SEGMENT_SIZE, audioData.length);
            chunks.push(audioData.subarray(offset, end));
            offset += SEGMENT_SIZE;
        }
        console.log(`[BigModel-ASR] éŸ³é¢‘åˆ†å—æ•°: ${chunks.length}, æ¯å— ${SEGMENT_SIZE} bytes`);

        // å‘é€éŸ³é¢‘å—
        for (let i = 0; i < chunks.length; i++) {
            const chunk = chunks[i];
            const isLast = (i === chunks.length - 1);
            seq++;

            const audioRequest = constructBigmodelAudioRequest(seq, chunk, isLast);
            ws.send(audioRequest);

            // æ¨¡æ‹Ÿå®æ—¶æµï¼ŒæŒ‰ç…§éŸ³é¢‘æ—¶é•¿å‘é€
            if (!isLast) {
                await new Promise(resolve => setTimeout(resolve, SEGMENT_DURATION_MS / 2));
            }
        }
        timing.audioChunks = Date.now() - audioChunksStartTime;
        console.log(`[BigModel-ASR] éŸ³é¢‘å‘é€è€—æ—¶: ${timing.audioChunks} ms`);

        // 5. ç­‰å¾…æœ€ç»ˆç»“æœ
        const finalWaitStartTime = Date.now();
        while (true) {
            const response = await waitForBigmodelMessage(ws, 15000);

            if (response?.payloadMsg) {
                const payload = response.payloadMsg;
                if (payload.result) {
                    finalResultText = payload.result;
                    console.log(`[BigModel-ASR] è¯†åˆ«ç»“æœ: "${finalResultText}"`);
                }
            }

            if (response?.isLastPackage) {
                console.log(`[BigModel-ASR] æ”¶åˆ°æœ€ç»ˆåŒ…`);
                break;
            }
        }
        timing.finalWait = Date.now() - finalWaitStartTime;

        ws.close();
        if (fs.existsSync(audioFile.path)) fs.unlinkSync(audioFile.path);

        timing.total = Date.now() - totalStartTime;
        console.log(`[BigModel-ASR] ========== æ€»è€—æ—¶: ${timing.total} ms ==========`);

        if (finalResultText) {
            res.json({ success: true, text: finalResultText, timing });
        } else {
            res.status(200).json({ success: true, text: "(æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³)", timing });
        }

    } catch (error) {
        console.error('[BigModel-ASR] Error:', error);
        if (ws) {
            try { ws.close(); } catch(e) {}
        }
        if (audioFile && fs.existsSync(audioFile.path)) fs.unlinkSync(audioFile.path);

        timing.total = Date.now() - totalStartTime;
        res.status(500).json({
            success: false,
            message: 'å¤§æ¨¡å‹è¯­éŸ³è¯†åˆ«å¤±è´¥',
            detail: error.message,
            timing
        });
    }
});

// è½¬æ¢éŸ³é¢‘ä¸º WAV æ ¼å¼
function convertToWav(inputPath, originalName) {
    return new Promise((resolve, reject) => {
        let inputFormat = null;
        if (originalName) {
            if (originalName.includes('webm')) {
                inputFormat = 'webm';
            } else if (originalName.includes('mp4') || originalName.includes('m4a')) {
                inputFormat = 'mp4';
            } else if (originalName.includes('ogg')) {
                inputFormat = 'ogg';
            }
        }

        const args = [];
        if (inputFormat) {
            args.push('-f', inputFormat);
        }
        args.push(
            '-i', inputPath,
            '-acodec', 'pcm_s16le',
            '-ac', '1',
            '-ar', '16000',
            '-f', 'wav',
            '-'
        );

        execFile(ffmpegPath, args, { encoding: 'buffer', maxBuffer: 50 * 1024 * 1024 }, (error, stdout, stderr) => {
            if (error) {
                console.error('FFmpeg error:', stderr.toString());
                reject(error);
            } else {
                resolve(stdout);
            }
        });
    });
}

// BigModel åè®®æ„é€ å‡½æ•°
function constructBigmodelFullRequest(seq) {
    const payload = {
        user: {
            uid: "demo_uid"
        },
        audio: {
            format: "wav",
            codec: "raw",
            rate: 16000,
            bits: 16,
            channel: 1
        },
        request: {
            model_name: "bigmodel",
            enable_itn: true,
            enable_punc: true,
            enable_ddc: true,
            show_utterances: true,
            enable_nonstream: false
        }
    };

    const payloadBytes = Buffer.from(JSON.stringify(payload), 'utf8');
    const compressedPayload = zlib.gzipSync(payloadBytes);

    // æ„å»º header (4 bytes)
    const header = Buffer.alloc(4);
    header[0] = (0x01 << 4) | 0x01; // version=1, header_size=1
    header[1] = (0x01 << 4) | 0x01; // message_type=FULL_REQUEST, flags=POS_SEQUENCE
    header[2] = (0x01 << 4) | 0x01; // serialization=JSON, compression=GZIP
    header[3] = 0x00; // reserved

    // æ„å»ºè¯·æ±‚
    const seqBuffer = Buffer.alloc(4);
    seqBuffer.writeInt32BE(seq);

    const sizeBuffer = Buffer.alloc(4);
    sizeBuffer.writeUInt32BE(compressedPayload.length);

    return Buffer.concat([header, seqBuffer, sizeBuffer, compressedPayload]);
}

function constructBigmodelAudioRequest(seq, audioData, isLast) {
    const compressedAudio = zlib.gzipSync(audioData);

    // æ„å»º header
    const header = Buffer.alloc(4);
    header[0] = (0x01 << 4) | 0x01; // version=1, header_size=1
    if (isLast) {
        header[1] = (0x02 << 4) | 0x03; // message_type=AUDIO_ONLY, flags=NEG_WITH_SEQUENCE
        seq = -seq; // æœ€åä¸€ä¸ªåŒ…ä½¿ç”¨è´Ÿåºå·
    } else {
        header[1] = (0x02 << 4) | 0x01; // message_type=AUDIO_ONLY, flags=POS_SEQUENCE
    }
    header[2] = (0x00 << 4) | 0x01; // serialization=NONE, compression=GZIP
    header[3] = 0x00; // reserved

    const seqBuffer = Buffer.alloc(4);
    seqBuffer.writeInt32BE(seq);

    const sizeBuffer = Buffer.alloc(4);
    sizeBuffer.writeUInt32BE(compressedAudio.length);

    return Buffer.concat([header, seqBuffer, sizeBuffer, compressedAudio]);
}

function waitForBigmodelMessage(ws, timeoutMs = 10000) {
    return new Promise((resolve, reject) => {
        const timeout = setTimeout(() => {
            reject(new Error('ç­‰å¾…æœåŠ¡å™¨å“åº”è¶…æ—¶'));
        }, timeoutMs);

        const onMessage = (data) => {
            clearTimeout(timeout);
            ws.off('message', onMessage);
            ws.off('error', onError);
            const response = parseBigmodelResponse(data);
            resolve(response);
        };

        const onError = (err) => {
            clearTimeout(timeout);
            ws.off('message', onMessage);
            ws.off('error', onError);
            reject(err);
        };

        ws.on('message', onMessage);
        ws.on('error', onError);
    });
}

function parseBigmodelResponse(msg) {
    const response = {
        code: 0,
        event: 0,
        isLastPackage: false,
        payloadSequence: 0,
        payloadSize: 0,
        payloadMsg: null
    };

    const headerSize = msg[0] & 0x0f;
    const messageType = msg[1] >> 4;
    const messageTypeSpecificFlags = msg[1] & 0x0f;
    const serializationMethod = msg[2] >> 4;
    const messageCompression = msg[2] & 0x0f;

    let payload = msg.slice(headerSize * 4);

    // è§£æ flags
    if (messageTypeSpecificFlags & 0x01) {
        response.payloadSequence = payload.readInt32BE(0);
        payload = payload.slice(4);
    }
    if (messageTypeSpecificFlags & 0x02) {
        response.isLastPackage = true;
    }
    if (messageTypeSpecificFlags & 0x04) {
        response.event = payload.readInt32BE(0);
        payload = payload.slice(4);
    }

    // è§£æ message type
    if (messageType === 0x09) { // SERVER_FULL_RESPONSE
        response.payloadSize = payload.readUInt32BE(0);
        payload = payload.slice(4);
    } else if (messageType === 0x0f) { // SERVER_ERROR_RESPONSE
        response.code = payload.readInt32BE(0);
        response.payloadSize = payload.readUInt32BE(4);
        payload = payload.slice(8);
    }

    if (payload.length === 0) {
        return response;
    }

    // è§£å‹
    if (messageCompression === 0x01) { // GZIP
        try {
            payload = zlib.gunzipSync(payload);
        } catch (e) {
            console.error('[BigModel-ASR] Failed to decompress:', e);
            return response;
        }
    }

    // è§£æ payload
    if (serializationMethod === 0x01) { // JSON
        try {
            response.payloadMsg = JSON.parse(payload.toString('utf8'));
        } catch (e) {
            console.error('[BigModel-ASR] Failed to parse JSON:', e);
        }
    }

    return response;
}

// ============================================
// MCP åè®®ç«¯ç‚¹ (é›†æˆåœ¨ä¸»æœåŠ¡å™¨ä¸­)
// ============================================

// MCP æœåŠ¡å™¨ä¿¡æ¯
const MCP_SERVER_INFO = {
    name: 'text-to-image-server',
    version: '1.0.0',
    protocolVersion: '2024-11-05',
    capabilities: {
        tools: {}
    }
};

// MCP å·¥å…·å®šä¹‰
const MCP_TOOLS = [
    {
        name: 'generate_image',
        description: 'æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾ç‰‡ã€‚ä½¿ç”¨ Replicate çš„ Realistic Vision v5.1 æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡å†™å®é£æ ¼å›¾åƒã€‚**é‡è¦ï¼šprompt å¿…é¡»ä½¿ç”¨è‹±æ–‡æè¿°ã€‚**',
        inputSchema: {
            type: 'object',
            properties: {
                prompt: {
                    type: 'string',
                    description: 'å›¾ç‰‡æè¿°æ–‡æœ¬ï¼ˆå¿…é¡»ä½¿ç”¨è‹±æ–‡ï¼‰ã€‚è¯¦ç»†æè¿°æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€é£æ ¼ã€è´¨é‡ç­‰ã€‚'
                },
                negative_prompt: {
                    type: 'string',
                    description: 'ä¸éœ€è¦æä¾›è´Ÿé¢æè¿°è¯',
                    default: ''
                },
                width: {
                    type: 'number',
                    description: 'å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰',
                    default: 512
                },
                height: {
                    type: 'number',
                    description: 'å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰',
                    default: 728
                },
                steps: {
                    type: 'number',
                    description: 'æ¨ç†æ­¥æ•°ï¼Œè¶Šé«˜è´¨é‡è¶Šå¥½ä½†é€Ÿåº¦è¶Šæ…¢',
                    default: 20
                },
                guidance: {
                    type: 'number',
                    description: 'å¼•å¯¼å¼ºåº¦ï¼Œæ§åˆ¶ç”Ÿæˆå›¾ç‰‡ä¸æç¤ºè¯çš„åŒ¹é…ç¨‹åº¦',
                    default: 5
                }
            },
            required: ['prompt']
        }
    }
];

// MCP åè®®ç«¯ç‚¹ï¼šåˆå§‹åŒ–
app.post('/mcp/initialize', (req, res) => {
    console.log('MCP Initialize request:', req.body);
    res.json({
        protocolVersion: MCP_SERVER_INFO.protocolVersion,
        capabilities: MCP_SERVER_INFO.capabilities,
        serverInfo: {
            name: MCP_SERVER_INFO.name,
            version: MCP_SERVER_INFO.version
        }
    });
});

// MCP åè®®ç«¯ç‚¹ï¼šåˆ—å‡ºå·¥å…·
app.post('/mcp/tools/list', (req, res) => {
    console.log('MCP Tools list request');
    res.json({
        tools: MCP_TOOLS
    });
});

// MCP åè®®ç«¯ç‚¹ï¼šè°ƒç”¨å·¥å…·
app.post('/mcp/tools/call', async (req, res) => {
    const { name, arguments: args } = req.body.params || req.body;

    console.log('MCP Tool call:', name, args);

    if (name !== 'generate_image') {
        return res.status(400).json({
            error: {
                code: -32601,
                message: `Unknown tool: ${name}`
            }
        });
    }

    try {
        // ä»è¯·æ±‚å¤´æˆ–å‚æ•°ä¸­è·å– API Token
        const apiToken = req.headers['x-replicate-token'] || args.api_token;

        if (!apiToken) {
            return res.status(400).json({
                error: {
                    code: -32602,
                    message: 'Missing Replicate API token. Please configure it in settings.'
                }
            });
        }

        // è·å–æ¨¡å‹é…ç½®ï¼ˆMCP é»˜è®¤ä½¿ç”¨ realistic-vision-v5.1ï¼‰
        const mcpModelConfig = IMAGE_MODELS[args.model] || IMAGE_MODELS['realistic-vision-v5.1'];

        // æ„å»ºå›¾ç‰‡ç”Ÿæˆè¯·æ±‚å‚æ•°
        let mcpImageInput;
        let mcpApiEndpoint;
        let mcpRequestBody;

        if (mcpModelConfig.useAspectRatio) {
            // æ–°æ¨¡å‹ä½¿ç”¨ aspect_ratio å‚æ•°
            mcpImageInput = {
                prompt: args.prompt,
                aspect_ratio: args.aspect_ratio || mcpModelConfig.defaultAspectRatio
            };

            if (mcpModelConfig.creativity !== undefined) {
                mcpImageInput.creativity = args.creativity || mcpModelConfig.creativity;
            }
            if (mcpModelConfig.promptUpsampling !== undefined) {
                mcpImageInput.prompt_upsampling = mcpModelConfig.promptUpsampling;
            }

            if (mcpModelConfig.useModelEndpoint) {
                // p-image ä½¿ç”¨ model endpoint
                mcpApiEndpoint = `https://api.replicate.com/v1/models/${mcpModelConfig.modelEndpoint}/predictions`;
                mcpRequestBody = { input: mcpImageInput };
            } else {
                // qwen-image-fast ä½¿ç”¨ version endpoint
                mcpApiEndpoint = 'https://api.replicate.com/v1/predictions';
                mcpRequestBody = {
                    version: mcpModelConfig.version,
                    input: mcpImageInput
                };
            }
        } else {
            // ä¼ ç»Ÿæ¨¡å‹ä½¿ç”¨ width/height å‚æ•°
            mcpImageInput = {
                seed: Math.floor(Math.random() * 10000),
                steps: args.steps || mcpModelConfig.steps,
                width: args.width || mcpModelConfig.defaultWidth,
                height: args.height || mcpModelConfig.defaultHeight,
                prompt: args.prompt,
                disable_safety_checker: true,
            };

            // æ·»åŠ æ¨¡å‹ç‰¹å®šå‚æ•°
            if (mcpModelConfig.guidance) {
                mcpImageInput.guidance = args.guidance || mcpModelConfig.guidance;
            }
            if (mcpModelConfig.scheduler) {
                mcpImageInput.scheduler = mcpModelConfig.scheduler;
            }

            mcpApiEndpoint = 'https://api.replicate.com/v1/predictions';
            mcpRequestBody = {
                version: mcpModelConfig.version,
                input: mcpImageInput
            };
        }

        console.log(`MCP ä½¿ç”¨å›¾ç‰‡æ¨¡å‹: ${args.model || 'realistic-vision-v5.1'}`);
        console.log(`MCP API ç«¯ç‚¹: ${mcpApiEndpoint}`);

        // è°ƒç”¨ Replicate API
        const response = await axios.post(
            mcpApiEndpoint,
            mcpRequestBody,
            {
                headers: {
                    'Authorization': `Bearer ${apiToken}`,
                    'Content-Type': 'application/json',
                    'Prefer': 'wait'
                },
                timeout: 120000
            }
        );

        const result = response.data;
        console.log('MCP Replicate API response:', JSON.stringify(result, null, 2));

        // å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼
        let imageUrl = null;
        if (Array.isArray(result.output) && result.output.length > 0) {
            imageUrl = result.output[0];
        } else if (typeof result.output === 'string') {
            imageUrl = result.output;
        }

        console.log('MCP Extracted imageUrl:', imageUrl);

        if (!imageUrl) {
            throw new Error('No image URL in response');
        }

        res.json({
            content: [
                {
                    type: 'text',
                    text: `å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼\n\næç¤ºè¯: ${args.prompt}\nå›¾ç‰‡URL: ${imageUrl}`
                },
                {
                    type: 'image',
                    data: imageUrl,
                    mimeType: 'image/png'
                }
            ]
        });

    } catch (error) {
        console.error('Error generating image:', error.response?.data || error.message);
        res.status(500).json({
            error: {
                code: -32603,
                message: `Failed to generate image: ${error.response?.data?.detail || error.message}`
            }
        });
    }
});

// ============================================
// æ–‡ç”Ÿå›¾ REST API ç«¯ç‚¹
// ============================================

// æ–‡ç”Ÿå›¾æ¥å£ (Text-to-Image) - ä½¿ç”¨ Replicate API
app.post('/api/text-to-image', async (req, res) => {
    const { apiToken, prompt, negative_prompt, width, height, num_inference_steps, guidance_scale, model, aspect_ratio, creativity, openrouterApiKey } = req.body;

    if (!apiToken || !prompt) {
        return res.status(400).json({ success: false, message: 'ç¼ºå°‘å¿…è¦å‚æ•°ï¼šapiToken å’Œ prompt' });
    }

    try {
        // æ£€æµ‹å¹¶ç¿»è¯‘ä¸­æ–‡æç¤ºè¯
        let finalPrompt = prompt;
        if (containsChinese(prompt)) {
            console.log('æ£€æµ‹åˆ°ä¸­æ–‡æç¤ºè¯ï¼Œæ­£åœ¨ç¿»è¯‘ä¸ºè‹±æ–‡...');
            if (openrouterApiKey) {
                finalPrompt = await translateToEnglish(prompt, openrouterApiKey);
                console.log('ç¿»è¯‘åçš„æç¤ºè¯:', finalPrompt);
            } else {
                console.warn('æœªæä¾› OpenRouter API Keyï¼Œæ— æ³•ç¿»è¯‘ä¸­æ–‡æç¤ºè¯');
            }
        }

        // è·å–æ¨¡å‹é…ç½®
        const restModelConfig = IMAGE_MODELS[model] || IMAGE_MODELS['realistic-vision-v5.1'];

        console.log('Submitting text-to-image request to Replicate...');
        console.log('Model:', model || 'realistic-vision-v5.1');
        console.log('Prompt:', finalPrompt);

        // æ„å»ºè¯·æ±‚å‚æ•°
        let restImageInput;
        let restApiEndpoint;
        let restRequestBody;

        if (restModelConfig.isFluxFast) {
            // Flux Fast æ¨¡å‹
            restImageInput = {
                seed: -1,
                prompt: finalPrompt,
                disable_safety_checker: true,
                guidance: restModelConfig.guidance,
                image_size: restModelConfig.defaultImageSize,
                speed_mode: restModelConfig.speedMode,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                output_quality: restModelConfig.outputQuality,
                num_inference_steps: num_inference_steps || restModelConfig.numInferenceSteps
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isZImageTurbo) {
            // Z-Image Turbo æ¨¡å‹
            restImageInput = {
                width: width || restModelConfig.defaultWidth,
                height: height || restModelConfig.defaultHeight,
                prompt: finalPrompt,
                disable_safety_checker: true,
                output_format: restModelConfig.outputFormat,
                guidance_scale: restModelConfig.guidanceScale,
                output_quality: restModelConfig.outputQuality,
                num_inference_steps: num_inference_steps || restModelConfig.numInferenceSteps
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isFlux2Pro) {
            // FLUX.2 [pro] æ¨¡å‹
            restImageInput = {
                prompt: finalPrompt,
                resolution: req.body.resolution || restModelConfig.defaultResolution,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                input_images: [],
                output_format: restModelConfig.outputFormat,
                output_quality: restModelConfig.outputQuality,
                safety_tolerance: restModelConfig.safetyTolerance
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isNanoBananaPro) {
            // Nano Banana Pro æ¨¡å‹
            restImageInput = {
                prompt: finalPrompt,
                resolution: req.body.resolution || restModelConfig.defaultResolution,
                image_input: [],
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                safety_filter_level: restModelConfig.safetyFilterLevel
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isGptImage15) {
            // GPT Image 1.5 æ¨¡å‹ (OpenAI on Replicate)
            restImageInput = {
                prompt: finalPrompt,
                quality: restModelConfig.quality,
                background: restModelConfig.background,
                moderation: restModelConfig.moderation,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                input_fidelity: restModelConfig.inputFidelity,
                number_of_images: restModelConfig.numberOfImages,
                disable_safety_checker: restModelConfig.disableSafetyChecker ? 1 : 0,
                output_compression: restModelConfig.outputCompression
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.isQwenImage) {
            // Qwen Image æ¨¡å‹ (é€šä¹‰ä¸‡è±¡)
            restImageInput = {
                prompt: finalPrompt,
                go_fast: restModelConfig.goFast,
                guidance: restModelConfig.guidance,
                strength: restModelConfig.strength,
                image_size: restModelConfig.imageSize,
                lora_scale: restModelConfig.loraScale,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio,
                output_format: restModelConfig.outputFormat,
                enhance_prompt: restModelConfig.enhancePrompt,
                output_quality: restModelConfig.outputQuality,
                disable_safety_checker: restModelConfig.disableSafetyChecker,
                num_inference_steps: num_inference_steps || restModelConfig.numInferenceSteps
            };
            restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
            restRequestBody = { input: restImageInput };
        } else if (restModelConfig.useAspectRatio) {
            // æ–°æ¨¡å‹ä½¿ç”¨ aspect_ratio å‚æ•° (å¦‚ qwen-image-fast, p-image)
            restImageInput = {
                prompt: finalPrompt,
                disable_safety_checker: true,
                aspect_ratio: aspect_ratio || restModelConfig.defaultAspectRatio
            };

            if (restModelConfig.creativity !== undefined) {
                restImageInput.creativity = creativity || restModelConfig.creativity;
            }
            if (restModelConfig.promptUpsampling !== undefined) {
                restImageInput.prompt_upsampling = restModelConfig.promptUpsampling;
            }

            if (restModelConfig.useModelEndpoint) {
                // p-image ä½¿ç”¨ model endpoint
                restApiEndpoint = `https://api.replicate.com/v1/models/${restModelConfig.modelEndpoint}/predictions`;
                restRequestBody = { input: restImageInput };
            } else {
                // qwen-image-fast ä½¿ç”¨ version endpoint
                restApiEndpoint = 'https://api.replicate.com/v1/predictions';
                restRequestBody = {
                    version: restModelConfig.version,
                    input: restImageInput
                };
            }
        } else {
            // ä¼ ç»Ÿæ¨¡å‹ä½¿ç”¨ width/height å‚æ•°
            restImageInput = {
                seed: Math.floor(Math.random() * 10000),
                steps: num_inference_steps || restModelConfig.steps,
                width: width || restModelConfig.defaultWidth,
                height: height || restModelConfig.defaultHeight,
                prompt: finalPrompt,
                negative_prompt: negative_prompt || '(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck',
                disable_safety_checker: true
            };

            // æ·»åŠ æ¨¡å‹ç‰¹å®šå‚æ•°
            if (restModelConfig.guidance) {
                restImageInput.guidance = guidance_scale || restModelConfig.guidance;
            }
            if (restModelConfig.scheduler) {
                restImageInput.scheduler = restModelConfig.scheduler;
            }

            restApiEndpoint = 'https://api.replicate.com/v1/predictions';
            restRequestBody = {
                version: restModelConfig.version,
                input: restImageInput
            };
        }

        console.log(`API ç«¯ç‚¹: ${restApiEndpoint}`);

        const response = await axios.post(
            restApiEndpoint,
            restRequestBody,
            {
                headers: {
                    'Authorization': `Bearer ${apiToken}`,
                    'Content-Type': 'application/json',
                    'Prefer': 'wait'
                },
                timeout: 240000 // 240ç§’è¶…æ—¶
            }
        );

        const result = response.data;
        console.log('Replicate response status:', result.status);

        if (result.status === 'succeeded' && result.output) {
            // output å¯èƒ½æ˜¯æ•°ç»„æˆ–å•ä¸ªå­—ç¬¦ä¸²
            const imageUrl = Array.isArray(result.output) ? result.output[0] : result.output;
            console.log('Extracted imageUrl:', imageUrl);
            res.json({
                success: true,
                imageUrl: imageUrl,
                prompt: finalPrompt,
                originalPrompt: prompt // ä¿ç•™åŸå§‹æç¤ºè¯ä¾›å‚è€ƒ
            });
        } else if (result.status === 'processing') {
            // å¦‚æœè¿˜åœ¨å¤„ç†ä¸­ï¼Œè¿”å›é¢„æµ‹IDä¾›è½®è¯¢
            res.json({
                success: false,
                processing: true,
                predictionId: result.id,
                message: 'å›¾ç‰‡ç”Ÿæˆä¸­ï¼Œè¯·ç¨åæŸ¥è¯¢ç»“æœ'
            });
        } else {
            throw new Error(`Image generation failed with status: ${result.status}`);
        }

    } catch (error) {
        const errorDetail = error.response?.data || error.message;
        console.error('Text-to-Image Error:', errorDetail);
        res.status(500).json({
            success: false,
            message: 'å›¾ç‰‡ç”Ÿæˆå¤±è´¥',
            detail: typeof errorDetail === 'string' ? errorDetail : JSON.stringify(errorDetail)
        });
    }
});

// å¯åŠ¨ HTTP æœåŠ¡å™¨
app.listen(PORT, () => {
    console.log(`HTTP æœåŠ¡å™¨è¿è¡Œåœ¨ http://localhost:${PORT}`);
});

// å¯åŠ¨ HTTPS æœåŠ¡å™¨ï¼ˆå¦‚æœå­˜åœ¨ SSL è¯ä¹¦ï¼‰
if (fs.existsSync(SSL_KEY_PATH) && fs.existsSync(SSL_CERT_PATH)) {
    try {
        const sslOptions = {
            key: fs.readFileSync(SSL_KEY_PATH),
            cert: fs.readFileSync(SSL_CERT_PATH)
        };

        https.createServer(sslOptions, app).listen(HTTPS_PORT, () => {
            console.log(`HTTPS æœåŠ¡å™¨è¿è¡Œåœ¨ https://0.0.0.0:${HTTPS_PORT}`);
        });
    } catch (error) {
        console.error('å¯åŠ¨ HTTPS æœåŠ¡å™¨å¤±è´¥:', error.message);
        console.log('è¯·ç¡®ä¿ SSL è¯ä¹¦æ–‡ä»¶æ ¼å¼æ­£ç¡®');
    }
} else {
    console.log('æœªæ‰¾åˆ° SSL è¯ä¹¦æ–‡ä»¶ï¼ŒHTTPS æœåŠ¡å™¨æœªå¯åŠ¨');
    console.log(`è¯·å°†è¯ä¹¦æ–‡ä»¶æ”¾ç½®åˆ°ï¼š`);
    console.log(`  - ç§é’¥: ${SSL_KEY_PATH}`);
    console.log(`  - è¯ä¹¦: ${SSL_CERT_PATH}`);
}
